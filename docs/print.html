<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Solid Book</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Intrp</a></li><li class="chapter-item expanded "><a href="css/index.html"><strong aria-hidden="true">2.</strong> CSS</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">3.</strong> DB</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">3.1.</strong> NoSQL</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="db/nosql/elasticsearch/index.html"><strong aria-hidden="true">3.1.1.</strong> Elasticsearch</a></li><li class="chapter-item expanded "><a href="db/nosql/mongo/index.html"><strong aria-hidden="true">3.1.2.</strong> Mongo</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="db/nosql/mongo/aggregation-pipeline/index.html"><strong aria-hidden="true">3.1.2.1.</strong> Aggregation</a></li><li class="chapter-item expanded "><a href="db/nosql/mongo/debugging/index.html"><strong aria-hidden="true">3.1.2.2.</strong> Debugging</a></li><li class="chapter-item expanded "><a href="db/nosql/mongo/mongoose/index.html"><strong aria-hidden="true">3.1.2.3.</strong> Mongoose</a></li><li class="chapter-item expanded "><a href="db/nosql/mongo/users/index.html"><strong aria-hidden="true">3.1.2.4.</strong> Users</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">3.2.</strong> SQL</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="db/sql/mysql/index.html"><strong aria-hidden="true">3.2.1.</strong> MySQL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="db/sql/mysql/debugging/index.html"><strong aria-hidden="true">3.2.1.1.</strong> Debugging</a></li><li class="chapter-item expanded "><a href="db/sql/mysql/engines/index.html"><strong aria-hidden="true">3.2.1.2.</strong> Engines</a></li><li class="chapter-item expanded "><a href="db/sql/mysql/foreign-keys/index.html"><strong aria-hidden="true">3.2.1.3.</strong> Foreign Keys</a></li><li class="chapter-item expanded "><a href="db/sql/mysql/profiling/index.html"><strong aria-hidden="true">3.2.1.4.</strong> Profiling</a></li><li class="chapter-item expanded "><a href="db/sql/mysql/users/index.html"><strong aria-hidden="true">3.2.1.5.</strong> Users</a></li></ol></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.</strong> Devops</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">4.1.</strong> AWS</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">4.1.1.</strong> EC2</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="devops/aws/ec2/encrypting-ebs/index.html"><strong aria-hidden="true">4.1.1.1.</strong> Encrypting EBS</a></li><li class="chapter-item expanded "><a href="devops/aws/ec2/increasing-instance-size/index.html"><strong aria-hidden="true">4.1.1.2.</strong> Increasing instance size</a></li><li class="chapter-item expanded "><a href="devops/aws/ec2/increasing-volume-size/index.html"><strong aria-hidden="true">4.1.1.3.</strong> Increasing volume size</a></li><li class="chapter-item expanded "><a href="devops/aws/ec2/installing-ntp/index.html"><strong aria-hidden="true">4.1.1.4.</strong> Installing NTP</a></li><li class="chapter-item expanded "><a href="devops/aws/ec2/keys/index.html"><strong aria-hidden="true">4.1.1.5.</strong> Keys</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="devops/deployment/index.html"><strong aria-hidden="true">4.2.</strong> Deployment</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="devops/deployment/gitlab/index.html"><strong aria-hidden="true">4.2.1.</strong> Deploying a project with gitlab</a></li><li class="chapter-item expanded "><a href="devops/deployment/github/index.html"><strong aria-hidden="true">4.2.2.</strong> Deploying a project with github</a></li><li class="chapter-item expanded "><a href="devops/deployment/git/index.html"><strong aria-hidden="true">4.2.3.</strong> Deploying a project with git</a></li><li class="chapter-item expanded "><a href="devops/deployment/build/index.html"><strong aria-hidden="true">4.2.4.</strong> Deployment build script for static webpage</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">4.3.</strong> Scaffolding</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="devops/scaffolding/project-setup/index.html"><strong aria-hidden="true">4.3.1.</strong> Setting up a project</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="devops/scaffolding/project-setup/architecture/index.html"><strong aria-hidden="true">4.3.1.1.</strong> Architecture</a></li><li class="chapter-item expanded "><a href="devops/scaffolding/project-setup/provisioning/index.html"><strong aria-hidden="true">4.3.1.2.</strong> Provisioning</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="devops/scaffolding/project-setup/provisioning/ansible/index.html"><strong aria-hidden="true">4.3.1.2.1.</strong> Ansible Intro</a></li><li class="chapter-item expanded "><a href="devops/scaffolding/project-setup/provisioning/ansible/playbooks/index.html"><strong aria-hidden="true">4.3.1.2.2.</strong> Ansible Playbooks</a></li><li class="chapter-item expanded "><a href="devops/scaffolding/project-setup/provisioning/ansible/roles/index.html"><strong aria-hidden="true">4.3.1.2.3.</strong> Creating Roles</a></li></ol></li></ol></li></ol></li><li class="chapter-item expanded "><a href="devops/vagrant/index.html"><strong aria-hidden="true">4.4.</strong> Vagrant</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">5.</strong> Error</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="error-handling/exponential-backoff/index.html"><strong aria-hidden="true">5.1.</strong> Exponential Back Off</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">6.</strong> HTML</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">6.1.</strong> Forms</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="html/forms/file-upload/index.html"><strong aria-hidden="true">6.1.1.</strong> File Upload</a></li><li class="chapter-item expanded "><a href="html/forms/restrict-file-types/index.html"><strong aria-hidden="true">6.1.2.</strong> Restrict File Types</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="infusionsoft/index.html"><strong aria-hidden="true">7.</strong> Infusionsoft</a></li><li class="chapter-item expanded "><a href="javascript/index.html"><strong aria-hidden="true">8.</strong> JavaScript</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="javascript/error-handling/index.html"><strong aria-hidden="true">8.1.</strong> Error Handling</a></li><li class="chapter-item expanded "><a href="javascript/es6/index.html"><strong aria-hidden="true">8.2.</strong> es6</a></li><li class="chapter-item expanded "><a href="javascript/promises/index.html"><strong aria-hidden="true">8.3.</strong> Promises</a></li><li class="chapter-item expanded "><a href="javascript/node/index.html"><strong aria-hidden="true">8.4.</strong> Node</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="javascript/node/debugging/index.html"><strong aria-hidden="true">8.4.1.</strong> Debugging Node</a></li><li class="chapter-item expanded "><a href="javascript/node/npm/index.html"><strong aria-hidden="true">8.4.2.</strong> npm</a></li><li class="chapter-item expanded "><a href="javascript/node/pm2/index.html"><strong aria-hidden="true">8.4.3.</strong> pm2</a></li></ol></li><li class="chapter-item expanded "><a href="javascript/transpiling/index.html"><strong aria-hidden="true">8.5.</strong> Transpiling</a></li><li class="chapter-item expanded "><a href="javascript/vue/index.html"><strong aria-hidden="true">8.6.</strong> Vue</a></li><li class="chapter-item expanded "><a href="javascript/web/index.html"><strong aria-hidden="true">8.7.</strong> Web</a></li><li class="chapter-item expanded "><a href="javascript/typescript/index.html"><strong aria-hidden="true">8.8.</strong> Typescript</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">9.</strong> Linux</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="linux/cli/index.html"><strong aria-hidden="true">9.1.</strong> CLI</a></li><li class="chapter-item expanded "><a href="linux/commands/index.html"><strong aria-hidden="true">9.2.</strong> Commands</a></li><li class="chapter-item expanded "><a href="linux/reboots/index.html"><strong aria-hidden="true">9.3.</strong> Reboot</a></li><li class="chapter-item expanded "><a href="linux/sftp/index.html"><strong aria-hidden="true">9.4.</strong> SFTP</a></li><li class="chapter-item expanded "><a href="linux/ufw/index.html"><strong aria-hidden="true">9.5.</strong> UFW</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">10.</strong> Media</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="media-streaming/html5/index.html"><strong aria-hidden="true">10.1.</strong> HTML5</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> Mobile</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="mobile/cordova/index.html"><strong aria-hidden="true">11.1.</strong> Cordova</a></li><li class="chapter-item expanded "><a href="mobile/react-native/index.html"><strong aria-hidden="true">11.2.</strong> React native</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="mobile/react-native/libraries/index.html"><strong aria-hidden="true">11.2.1.</strong> Libraries</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">12.</strong> PHP</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="php/debugging/index.html"><strong aria-hidden="true">12.1.</strong> Debugging PHP</a></li><li class="chapter-item expanded "><a href="php/eloquent/index.html"><strong aria-hidden="true">12.2.</strong> Eloquent</a></li><li class="chapter-item expanded "><a href="php/laravel/index.html"><strong aria-hidden="true">12.3.</strong> Laravel</a></li><li class="chapter-item expanded "><a href="php/magento-2/index.html"><strong aria-hidden="true">12.4.</strong> Magento 2</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="php/magento-2/create-page/index.html"><strong aria-hidden="true">12.4.1.</strong> Create Page</a></li><li class="chapter-item expanded "><a href="php/magento-2/customizations/index.html"><strong aria-hidden="true">12.4.2.</strong> Customizations</a></li><li class="chapter-item expanded "><a href="php/magento-2/debugging/index.html"><strong aria-hidden="true">12.4.3.</strong> Debugging</a></li></ol></li><li class="chapter-item expanded "><a href="php/namespaces/index.html"><strong aria-hidden="true">12.5.</strong> Namespaces</a></li><li class="chapter-item expanded "><a href="php/wordpress/index.html"><strong aria-hidden="true">12.6.</strong> Wordpress</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="php/wordpress/elementor/index.html"><strong aria-hidden="true">12.6.1.</strong> Elementor</a></li><li class="chapter-item expanded "><a href="php/wordpress/i18n/index.html"><strong aria-hidden="true">12.6.2.</strong> i18n</a></li><li class="chapter-item expanded "><a href="php/wordpress/wp-engine/index.html"><strong aria-hidden="true">12.6.3.</strong> WP-Engine</a></li></ol></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">13.</strong> Performance</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="profiling/index.html"><strong aria-hidden="true">13.1.</strong> Profiling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="profiling/lighthouse/index.html"><strong aria-hidden="true">13.1.1.</strong> Lighthouse</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="security/index.html"><strong aria-hidden="true">14.</strong> Security</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="security/HTTPS/index.html"><strong aria-hidden="true">14.1.</strong> HTTPS</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">15.</strong> Servers</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="servers/apache/index.html"><strong aria-hidden="true">15.1.</strong> Apache</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="servers/apache/redirects/index.html"><strong aria-hidden="true">15.1.1.</strong> Apache Redirects</a></li></ol></li><li class="chapter-item expanded "><a href="servers/nginx/index.html"><strong aria-hidden="true">15.2.</strong> Nginx</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="servers/nginx/config/index.html"><strong aria-hidden="true">15.2.1.</strong> Config</a></li><li class="chapter-item expanded "><a href="servers/nginx/fastcgi/index.html"><strong aria-hidden="true">15.2.2.</strong> FastCgi</a></li><li class="chapter-item expanded "><a href="servers/nginx/redirects/index.html"><strong aria-hidden="true">15.2.3.</strong> Redirects</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="tv/index.html"><strong aria-hidden="true">16.</strong> TV</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tv/roku/index.html"><strong aria-hidden="true">16.1.</strong> Roku</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="tv/roku/development/index.html"><strong aria-hidden="true">16.1.1.</strong> Development and Deploying</a></li><li class="chapter-item expanded "><a href="tv/roku/debugging/index.html"><strong aria-hidden="true">16.1.2.</strong> Debugging</a></li><li class="chapter-item expanded "><a href="tv/roku/events/index.html"><strong aria-hidden="true">16.1.3.</strong> Events</a></li><li class="chapter-item expanded "><a href="tv/roku/focus/index.html"><strong aria-hidden="true">16.1.4.</strong> Focus</a></li></ol></li><li class="chapter-item expanded "><a href="tv/samsung/index.html"><strong aria-hidden="true">16.2.</strong> Samsung</a></li><li class="chapter-item expanded "><a href="tv/vizio/index.html"><strong aria-hidden="true">16.3.</strong> Vizio</a></li><li class="chapter-item expanded "><a href="tv/yctv/index.html"><strong aria-hidden="true">16.4.</strong> Yahoo Connected TV</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">17.</strong> UWP</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="uwp/web-based/index.html"><strong aria-hidden="true">17.1.</strong> Web-based</a></li></ol></li><li class="chapter-item expanded "><a href="version-control/index.html"><strong aria-hidden="true">18.</strong> Version Control</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="version-control/git/index.html"><strong aria-hidden="true">18.1.</strong> Git</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="version-control/git/gitflow/index.html"><strong aria-hidden="true">18.1.1.</strong> Gitflow</a></li><li class="chapter-item expanded "><a href="version-control/git/hooks/index.html"><strong aria-hidden="true">18.1.2.</strong> Hooks</a></li></ol></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Solid Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#the-big-incomplete-book-of-dev" id="the-big-incomplete-book-of-dev">The Big Incomplete Book of Dev</a></h1>
<p>The latest &quot;published&quot; version can be accessed at http://soliddigital.github.io/solid-book/ .</p>
<h2><a class="header" href="#contributing" id="contributing">Contributing</a></h2>
<p>To edit the book go to https://github.com/soliddigital/solid-book and edit the markdown pages. CI will publish
the new version.</p>
<h2><a class="header" href="#organization" id="organization">Organization</a></h2>
<p>Topics are roughly organized into a hierarchy by subjects. Of course
this organization doesn't always work completely. Sometimes a page could
fit into more than one topic.</p>
<h2><a class="header" href="#local-dev" id="local-dev">Local Dev</a></h2>
<pre><code class="language-shell"># install rust and mdbook
curl https://sh.rustup.rs -sSf | sh
cargo install mdbook

git clone git@github.com:soliddigital/solid-book.git
cd solid-book
mdbook serve
</code></pre>
<p>To deploy push a commit to the <code>main</code> branch.</p>
<p>For links PhpStorm has good auto-completion.</p>
<hr />
<p>Maintained by <a href="https://www.soliddigital.com/">Solid Digital</a></p>
<h1><a class="header" href="#css" id="css">CSS</a></h1>
<p>tags: css</p>
<h2><a class="header" href="#animations" id="animations">Animations</a></h2>
<p>For the best performance in css animations, follow these rules:</p>
<ul>
<li>Use the <a href="https://aerotwist.com/blog/flip-your-animations/">FLIP</a> principle</li>
<li><a href="https://developers.google.com/web/fundamentals/performance/rendering/stick-to-compositor-only-properties-and-manage-layer-count">Manage compositor layers with specific css</a></li>
</ul>
<h1><a class="header" href="#elasticsearch" id="elasticsearch">Elasticsearch</a></h1>
<p>tags: db, elasticsearch, nosql</p>
<h2><a class="header" href="#binding-to-localhost" id="binding-to-localhost">Binding to localhost</a></h2>
<pre><code># /etc/elasticsearch/elasticsearch.yml
network.bind_host: 127.0.0.1
network.publish_host: 127.0.0.1
network.host: 127.0.0.1
</code></pre>
<p>Make sure you add a cluster name to stop other ES instances on the network from joining the cluster automatically</p>
<pre><code>cluster.name: project_production
node.name: project_node_1
network.host: 1.2.3.4
</code></pre>
<h1><a class="header" href="#mongo" id="mongo">Mongo</a></h1>
<p>tags: mongo, nosql</p>
<h2><a class="header" href="#mongodump" id="mongodump"><code>mongodump</code></a></h2>
<pre><code class="language-sh">mongodump --db &lt;db-name&gt; --username &lt;db-user-name&gt;
</code></pre>
<h2><a class="header" href="#mongorestore---restore-from-mongodump-backup" id="mongorestore---restore-from-mongodump-backup"><code>mongorestore</code> - restore from <code>mongodump</code> backup</a></h2>
<pre><code class="language-sh">mongorestore --db &lt;db-name&gt; --drop --dir &lt;dump-dir&gt;
</code></pre>
<h1><a class="header" href="#aggregation-pipeline" id="aggregation-pipeline">Aggregation Pipeline</a></h1>
<p>tags: mongo, aggregation</p>
<p>The <a href="https://docs.mongodb.com/manual/core/aggregation-pipeline/">aggregation pipeline</a> can
be used for doing more complicated operations.</p>
<p>For example, here is how you find duplicates by title, show how many duplicates, and sort
them from most to least duplicated:</p>
<pre><code>db.content.aggregate(
    {&quot;$group&quot; : { &quot;_id&quot;: &quot;$fields.title&quot;, &quot;count&quot;: { &quot;$sum&quot;: 1 } } },
    {&quot;$match&quot;: {&quot;_id&quot; :{ &quot;$ne&quot; : null } , &quot;count&quot; : {&quot;$gt&quot;: 1} } }, 
    {&quot;$sort&quot;: {&quot;count&quot; : -1} },
    {&quot;$project&quot;: {&quot;name&quot; : &quot;$_id&quot;, &quot;count&quot; : &quot;$count&quot;, &quot;_id&quot;: 0 } }
)
</code></pre>
<p>If you want to filter results first and then collect the publication dates to see if they match on duplicates:</p>
<pre><code>db.content.aggregate(
    {&quot;$match&quot;: {&quot;meta.type&quot;:ObjectId(&quot;58f53f6a62b4f0298ca23fd4&quot;)}},
    {&quot;$group&quot; : { &quot;_id&quot;: &quot;$fields.title&quot;, &quot;count&quot;: { &quot;$sum&quot;: 1 }, &quot;date&quot;: { $push : &quot;$fields.publish_date&quot;} } },
    {&quot;$match&quot;: {&quot;_id&quot; :{ &quot;$ne&quot; : null } , &quot;count&quot; : {&quot;$gt&quot;: 1} } }, 
    {&quot;$sort&quot;: {&quot;count&quot; : -1} },
    {&quot;$project&quot;: {&quot;name&quot; : &quot;$_id&quot;, &quot;count&quot; : &quot;$count&quot;, &quot;date&quot;:&quot;$date&quot;, &quot;_id&quot;: 0 } }
)
</code></pre>
<h1><a class="header" href="#mongo-1" id="mongo-1">Mongo</a></h1>
<p>tags: db, mongo, debugging, nosql</p>
<h2><a class="header" href="#debugging" id="debugging">Debugging</a></h2>
<p>If the service doesn't start you can often get useful output trying to manually start or fix mongo</p>
<pre><code>sudo -H -u mongodb mongod --config /etc/mongod.conf
</code></pre>
<p><code>echo $?</code> for the exit code if the above doesn't keep going.</p>
<pre><code>sudo -H -u mongodb mongod --repair
</code></pre>
<p>Things that often seem to be missing are the log file and <code>/data/db</code> dir.
Mongo will not start with a lock file at <code>/var/lib/mongodb/mongodb.lock</code>.</p>
<h1><a class="header" href="#mongoose" id="mongoose">Mongoose</a></h1>
<p>tags: db, mongo, orm, nosql</p>
<p><a href="http://mongoosejs.com/docs/">Docs</a></p>
<h2><a class="header" href="#creating-a-connection" id="creating-a-connection">Creating a connection</a></h2>
<p>Using <a href="http://mongoosejs.com/docs/connections.html#connections"><code>mongoose.connect</code></a> will connect to the default connection. This will throw an error if you try to connect twice.</p>
<p>Using <a href="http://mongoosejs.com/docs/connections.html#multiple_connections"><code>mongoose.createConnection</code></a> will create a new connection. This is useful if you want multiple connections.</p>
<p>To <a href="https://stackoverflow.com/a/19606067/186636">check the state of the default connection</a></p>
<pre><code class="language-javascript">const mongoose = require('mongoose');
console.log(mongoose.connection.readyState);
</code></pre>
<h2><a class="header" href="#debugging-1" id="debugging-1">Debugging</a></h2>
<p>If your commands are just not doing anything, make sure you are connected!</p>
<p>http://mongoosejs.com/docs/api.html#connection_Connection-readyState</p>
<pre><code class="language-javascript">setInterval(() =&gt; {
    // 1 = connected, 2 = connecting
    console.log(mongoose.connection.readyState); 
});
</code></pre>
<h1><a class="header" href="#creating-users-in-mongo" id="creating-users-in-mongo">Creating users in Mongo</a></h1>
<p>tags: mongo, users, nosql, auth</p>
<ol>
<li>Authorize with the admin user, usually on the admin db.</li>
<li>Switch to the db of interest.</li>
<li>Create the user with appropriate roles.</li>
</ol>
<p>A simple example:</p>
<pre><code class="language-shell">$ mongo
&gt; use admin;
&gt; db.auth('admin', 'my-super-secret-password');
&gt; use someDb;
&gt; db.createUser({
    user : &quot;someDbUser&quot;,
    pwd : &quot;a-super-duper-password&quot;,
    roles : [&quot;dbOwner&quot;]
  });
</code></pre>
<p>References:</p>
<ul>
<li>http://docs.mongodb.org/manual/reference/method/db.createUser/</li>
<li>http://docs.mongodb.org/manual/reference/built-in-roles/#built-in-roles</li>
</ul>
<h1><a class="header" href="#mysql" id="mysql">Mysql</a></h1>
<p>tags: mysql, sql, trim</p>
<h2><a class="header" href="#login" id="login">Login</a></h2>
<pre><code class="language-sh"># -p will prompt for password
mysql -h host.name -u db_user_name -p
</code></pre>
<h2><a class="header" href="#mysqldump-export" id="mysqldump-export"><code>mysqldump</code> (Export)</a></h2>
<pre><code class="language-sh">mysqldump -h host.name -u db_user_name -p db_name &gt; db_name_backup.sql
</code></pre>
<h2><a class="header" href="#import" id="import">Import</a></h2>
<pre><code class="language-sh">mysql -h host.name -u db_user_name -p db_name &lt; db_name_backup.sql
</code></pre>
<h2><a class="header" href="#trim" id="trim">Trim</a></h2>
<pre><code class="language-mysql"># search for trailing \n
select * from wp_postmeta where meta_key='company_name' AND meta_value LIKE '%\n';

# test command
select TRIM(TRAILING '\n' FROM meta_value) from wp_postmeta where meta_key='company_name' AND meta_value LIKE '%\n';

# run command
update wp_postmeta SET meta_value = TRIM(TRAILING '\n' FROM meta_value) where meta_key='company_name' AND meta_value LIKE '%\n';
</code></pre>
<h1><a class="header" href="#debugging-mysql" id="debugging-mysql">Debugging MySQL</a></h1>
<p>tags: mysql, errors, debugging</p>
<h2><a class="header" href="#mysql-578---variables-doesnt-exist" id="mysql-578---variables-doesnt-exist">MySQL 5.7.8 - variables doesn't exist</a></h2>
<pre><code>Couldn't execute 'SHOW VARIABLES LIKE 'gtid\_mode'': Table 'performance_schema.session_variables' doesn't exist (1146)
</code></pre>
<p>The error above is explained <a href="https://stackoverflow.com/questions/31967527/table-performance-schema-session-variables-doesnt-exist">here</a>.</p>
<p>Solving the issue takes 3 steps.</p>
<p>You should take backups before upgrading:</p>
<pre><code>mysql -uroot -p
set @@global.show_compatibility_56=ON;
</code></pre>
<p>Now you can run you backups. Turn the flag back off:</p>
<pre><code>set @@global.show_compatibility_56=OFF;
</code></pre>
<p>And upgrade and restart:</p>
<pre><code>sudo mysql_upgrade -u root -p --force
sudo service mysql restart
</code></pre>
<h3><a class="header" href="#error-reading-communication-packets" id="error-reading-communication-packets">Error reading communication packets</a></h3>
<pre><code>2019-05-20T23:26:05.865130Z 362392 [Note] Aborted connection 362392 to 
db: 'example' user: 'example_user' 
host: '1.2.3.4' 
(Got an error reading communication packets)
</code></pre>
<p>Try upping <code>max_allowed_packets</code>... for example to <code>256M</code>: <code>SET GLOBAL max_allowed_packet = 1024 * 1024 * 256</code> and <code>256M</code> for <code>max_allowed_packets</code>.</p>
<p>https://dba.stackexchange.com/a/19139/63946</p>
<h1><a class="header" href="#mysql-engines" id="mysql-engines">MySQL Engines</a></h1>
<p>tags: mysql, innodb, myisam, engines</p>
<p>MySQL has 2 storage engines: MyISAM and InnoDB. InnoDB is newer and generally better (MyISAM can have advantages in specific use cases):</p>
<p>https://kinsta.com/knowledgebase/convert-myisam-to-innodb/</p>
<p>https://dba.stackexchange.com/questions/1/what-are-the-main-differences-between-innodb-and-myisam</p>
<p>InnoDB has:</p>
<ul>
<li>Transaction (so it is <a href="https://en.wikipedia.org/wiki/ACID">ACID</a>)</li>
<li>Row level locking (vs table locking)</li>
<li>Foreign key constraints</li>
<li>Automatic crash recovery</li>
<li>Table compression</li>
</ul>
<p>One thing to watch out for is that InnoDB only has FULLTEXT search indexes starting at v5.6.4</p>
<p>To see which DBs have MyISAM tables:</p>
<pre><code class="language-mysql">SELECT TABLE_SCHEMA
FROM information_schema.TABLES
WHERE ENGINE = 'myISAM'
GROUP BY TABLE_SCHEMA
</code></pre>
<p>To list each table and the DB it's in:</p>
<pre><code class="language-mysql">SELECT TABLE_SCHEMA, TABLE_NAME, ENGINE
FROM information_schema.TABLES
WHERE ENGINE = 'myISAM'
</code></pre>
<p>To convert (back things up first - MySQL 5.6.4+ suggested):</p>
<pre><code class="language-mysql">use my_db;
ALTER TABLE my_table ENGINE=InnoDB;
</code></pre>
<h1><a class="header" href="#foreign-keys" id="foreign-keys">Foreign Keys</a></h1>
<p>tags: mysql, foreign keys, references</p>
<p><a href="https://dev.mysql.com/doc/refman/5.6/en/create-table-foreign-keys.html">Foreign keys</a> allow you to make references from
one entry in a row in a table to another.</p>
<p>You add the foreign key constraints to the child table.</p>
<p>When a parent row containing a reference is deleted or updated you can have the child rows deleted or updated too using <code>CASCADE</code>.</p>
<p>Foreign key errors can be terse and cryptic. To get a more verbose version run the following command:</p>
<pre><code class="language-mysql">SHOW ENGINE INNODB STATUS
</code></pre>
<p>Then look in the <code>status</code> field for <code>LATEST FOREIGN KEY ERROR</code>.</p>
<h2><a class="header" href="#references" id="references">References:</a></h2>
<ul>
<li>https://dev.mysql.com/doc/refman/5.6/en/create-table-foreign-keys.html</li>
<li>https://www.sitepoint.com/mysql-foreign-keys-quicker-database-development/</li>
</ul>
<h1><a class="header" href="#profiling-mysql" id="profiling-mysql">Profiling MySQL</a></h1>
<p>tags: db, sql, mysql, performance, profile</p>
<p>To list queries that take one or more seconds use <code>my.cnf</code>, often located at:
<code>/etc/mysql/my.cnf</code>.</p>
<pre><code>log_slow_queries        = /var/log/mysql/mysql-slow.log
long_query_time = 1
</code></pre>
<p>For mysql 5.6+ use these setting keys in the config file:</p>
<pre><code>slow_query_log = 1
slow_query_log_file = /var/log/mysql/mysql-slow.log
long_query_time = 10 # time in seconds
#log_queries_not_using_indexes = 1
</code></pre>
<ul>
<li>Create the slow log file, and set mysql as the owner (or just match the ownership of the mysql error log file).
<pre><code>sudo touch /var/log/mysql/mysql-slow.log
sudo chown mysql /var/log/mysql/mysql-slow.log
</code></pre>
</li>
<li>restart mysql: <code>sudo service mysql restart</code></li>
</ul>
<h1><a class="header" href="#creating-users" id="creating-users">Creating Users</a></h1>
<p>tags: db, sql, mysql, auth</p>
<pre><code># show all users
select User from mysql.user;
show grants for 'root'@'localhost';

# create user with password and give privileges
create user '[username]'@'localhost' identified by '[the password]';
grant all privileges on [db name].* to `[user name]`@'localhost';
flush privileges;
</code></pre>
<h2><a class="header" href="#references-1" id="references-1">References</a></h2>
<ul>
<li>http://dev.mysql.com/doc/refman/5.1/en/adding-users.html</li>
<li>https://www.digitalocean.com/community/tutorials/how-to-create-a-new-user-and-grant-permissions-in-mysql</li>
<li>http://stackoverflow.com/questions/5016505/mysql-grant-all-privileges-on-database</li>
</ul>
<h1><a class="header" href="#encrypting-ebs" id="encrypting-ebs">Encrypting EBS</a></h1>
<p>tags: aws, ec2, ebs, encryption</p>
<p>The EBS volumes that back EC2 can be encrypted.</p>
<ul>
<li><a href="https://cloudacademy.com/blog/how-to-encrypt-an-ebs-volume-the-new-amazon-ebs-encryption/">EBS Encryption tutorial</a></li>
</ul>
<p>To encrypt and EBS volume, you must <a href="https://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html">create a KMS key</a>.</p>
<h2><a class="header" href="#creating-an-ec2-instance-with-an-encrypted-ebs-volume" id="creating-an-ec2-instance-with-an-encrypted-ebs-volume">Creating an EC2 instance with an encrypted EBS volume</a></h2>
<ul>
<li>Initialize a new instance</li>
<li>Create a KMS key for the encryption</li>
<li>Add a second volumen and make it encrypted via the key</li>
<li>Start the instance</li>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html">Make the volume available for Linux</a> 
<ul>
<li><code>lsblk</code></li>
<li>e.g.: <code>sudo file -s /dev/xvdb</code> </li>
<li>If previous command just showed &quot;data&quot;: e.g.: <code>sudo mkfs -t ext4 /dev/xvdb</code></li>
<li>Create a mount point: <code>sudo mkdir /crypt</code></li>
<li>Moung the volume e.g.: <code>sudo mount /dev/xvdb /crypt</code></li>
</ul>
</li>
</ul>
<p>Upon system reboot, the volume will not be mounted. Add a line to the end of <code>etc/fstab</code> to mount it on reboot.</p>
<p>e.g.:</p>
<pre><code>/dev/xvdb /crypt ext4 defaults,nofail 0 2
</code></pre>
<h1><a class="header" href="#increasing-instance-size" id="increasing-instance-size">Increasing Instance Size</a></h1>
<p>tags: ec2, aws, volumes, resizing</p>
<h2><a class="header" href="#increasing-instance-size-1" id="increasing-instance-size-1">Increasing Instance Size</a></h2>
<p>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-resize.html</p>
<ol>
<li>Create a snapshot just in case</li>
<li>Make sure you have an elastic ip</li>
<li>Stop instance</li>
<li>Increase size</li>
<li>Start Instance</li>
</ol>
<h1><a class="header" href="#increasing-volume-size" id="increasing-volume-size">Increasing Volume Size</a></h1>
<p>tags: ec2, aws, volumes, resizing</p>
<h2><a class="header" href="#increasing-volume-size---the-easy-way" id="increasing-volume-size---the-easy-way">Increasing Volume Size - the easy way</a></h2>
<p>This has no down time (show should still back things up though!)</p>
<p>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html</p>
<ol>
<li>
<p>Identify the EBS volume being used by the EC2 instance (easiest to click through from the EC2 instance and add the appropriate name)</p>
</li>
<li>
<p>Select &quot;modify volume&quot;</p>
</li>
<li>
<p>Increase the size to the desired amount</p>
</li>
<li>
<p>Log on to the instance and do the following (in this example we are increasing from 8 to 30G):</p>
<pre><code># install &quot;cloud-guest-utils&quot; if it is not installed already
apt install cloud-guest-utils

# lsblk will show that 30G is available but only 8G is partitioned
▶ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0  30G  0 disk
└─xvda1 202:1    0   8G  0 part /

# add a space between the device name and the partition number
▶ sudo growpart /dev/xvda 1
CHANGED: partition=1 start=2048 old: size=16775135 end=16777183 new: size=62912479,end=62914527

# confirm with lsblk
▶ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0  30G  0 disk
└─xvda1 202:1    0  30G  0 part /   

# df -h will still not show the full size, so you have to extend the filesystem
▶ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            992M     0  992M   0% /dev
tmpfs           200M   21M  180M  11% /run
/dev/xvda1      7.7G  4.8G  2.9G  63% /

▶ sudo resize2fs /dev/xvda1
resize2fs 1.42.13 (17-May-2015)
Filesystem at /dev/xvda1 is mounted on /; on-line resizing required
old_desc_blocks = 1, new_desc_blocks = 2
The filesystem on /dev/xvda1 is now 7864059 (4k) blocks long.

▶ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            992M     0  992M   0% /dev
tmpfs           200M   21M  180M  11% /run
/dev/xvda1       30G  4.8G   25G  17% /
</code></pre>
</li>
</ol>
<h2><a class="header" href="#increasing-volume-size---the-hard-way" id="increasing-volume-size---the-hard-way">Increasing Volume Size - the hard way</a></h2>
<p>This has down time.</p>
<p>http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-expand-volume.html</p>
<ol>
<li>Make sure the instance has an elastic IP. If it doesn't, let the client know there's going to be more downtime and assign an elastic IP. Make sure you have access to the DNS before doing any of this. </li>
<li>Optionally stop ec2 instance if downtime is not a concern</li>
<li><em>Note root device</em> (often <code>/dev/sda1</code> )</li>
<li>Note id of instance and look for volume based on that id in volumes (use search)
<ol>
<li>Name the volume</li>
</ol>
</li>
<li>Make snapshot of volume</li>
<li>Create a new volume from the snapshot
<ol>
<li>Make sure your ec2 availability zone matches your volume availability zone</li>
</ol>
</li>
<li>Name your volume (and snapshoots too) for easy reference</li>
<li>Now stop the instance if you didn't stop it on step 1</li>
<li>Detach old volume</li>
<li>Attach new volume
<ol>
<li>Attach to same root</li>
</ol>
</li>
<li>Restart instance</li>
</ol>
<p>Note that if you resized a volume with other mounted drives, then you will have to remount them. 
So whenever you're doing mounting, it's a good idea to keep the history of your commands somewhere. If you're mounting DB sources, then you'll also have to restart the services.</p>
<p>tags: ec2, aws, time server, ntp, time sync, ubuntu</p>
<p>Chrony should be used now: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html</p>
<h2><a class="header" href="#installing-ntp" id="installing-ntp">Installing NTP</a></h2>
<p>First, check if you have a timezone set, by running </p>
<pre><code>timedatectl
</code></pre>
<p>If no, then set a timezone:</p>
<pre><code># look for a list of timezones
timedatectl list-timezones

# set timezone (for our servers America/Los_Angeles is the one we use)
timedatectl set-timezone &lt;chosen timezone&gt;
</code></pre>
<p>Install NTP</p>
<pre><code>sudo apt-get install ntp
</code></pre>
<h5><a class="header" href="#original-article" id="original-article">Original Article</a></h5>
<p>https://www.digitalocean.com/community/tutorials/how-to-set-up-timezone-and-ntp-synchronization-on-ubuntu-14-04-quickstart</p>
<h5><a class="header" href="#ubuntu-docs" id="ubuntu-docs">Ubuntu docs</a></h5>
<p>https://help.ubuntu.com/lts/serverguide/NTP.html</p>
<h1><a class="header" href="#managing-keys-on-ubuntu" id="managing-keys-on-ubuntu">Managing keys on Ubuntu</a></h1>
<p>tags: ubuntu, keys</p>
<p>List keys:</p>
<pre><code class="language-bash">sudo apt-key list
</code></pre>
<p><a href="https://stackoverflow.com/a/46737148/186636">Renew keys</a>:</p>
<pre><code class="language-bash">sudo apt-key list | \
 grep &quot;expired: &quot; | \
 sed -ne 's|pub .*/\([^ ]*\) .*|\1|gp' | \
 xargs -n1 sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys
</code></pre>
<h1><a class="header" href="#deployment" id="deployment">Deployment</a></h1>
<p>tags: devops, deployment</p>
<p>There are multiple strategies for deployment.</p>
<p>One of the simplest is to use the dev's machine to deploy to a server directly.
This can be done using git push.</p>
<p>Another method is to have some sort of CI server setup to deploy code when
git changes are detected.</p>
<h1><a class="header" href="#deploying-with-gitlab" id="deploying-with-gitlab">Deploying with Gitlab</a></h1>
<p>tags: devops, deployment, gitlab, ci</p>
<p>Gitlab now has the concept of <a href="https://docs.gitlab.com/ee/ci/pipelines.html">pipelines</a>.
You can use pipelines to setup a series of stages. Stages are things like
test and deploy.</p>
<p>Deploys can be made to multiple <a href="https://docs.gitlab.com/ce/ci/environments.html">environments</a>. Environments
are things like <code>staging</code> and <code>production</code>.</p>
<p>You can define your stages and environments in a <a href="https://docs.gitlab.com/ce/ci/yaml/"><code>.gitlab-ci.yml</code></a> file at the
root of your repo.</p>
<p>To get Gitlab CI working, you have to setup a <a href="https://docs.gitlab.com/ee/ci/runners/README.html">runner</a>.
A runner is simply something that runs the stages. A very simple way to
do this is to <a href="https://docs.gitlab.com/ee/ci/runners/README.html#registering-a-shared-runner">set up a shared runner</a> on an EC2 box.</p>
<p>The runner will run under the user <code>gitlab-runner</code>.</p>
<h2><a class="header" href="#setting-up-gitlab-deploys-with-pipelines" id="setting-up-gitlab-deploys-with-pipelines">Setting up gitlab deploys with pipelines</a></h2>
<p>Here is how to setup deploys via pipelines to a staging server if you already have a gitlab runner setup.</p>
<ol>
<li>
<p>Add a deploy key to the server your project code will live on. This allows the repo to be read from that server.</p>
</li>
<li>
<p>add a <code>.gitlab-ci.yml</code> at the root of your project to define your stages and environments. below is an example that will run <code>npm test</code> with dependencies in the deploy dir, and then use pm2 deploy.</p>
<pre><code>stages:
  - test
  - deploy
test_staging:
  stage: test
  script:
    - npm install deploy
    - npm test
deploy_staging:
  stage: deploy
  script:
    - pm2 deploy deploy/sample.staging.config.js staging
  environment:
    name: staging
    url: https://sample.staging.com/
  only:
  - develop
</code></pre>
</li>
</ol>
<p>The cwd of the script is the root of the project, so in the case above the config file for the deploy are in a deploy dir a the root of the project.</p>
<p><a href="http://pm2.keymetrics.io/docs/usage/deployment/">PM2 deploy</a> is convenient for node deploys, but it can also be used for any other type of deploy. There are hooks to support
doing work both on either the runner or the deployed to server. It allows all these hooks to be stored in the repo as 
opposed to in a git hook outside the repo.</p>
<p>Below is how a PM2 config file could be setup for a PHP deploy. Sample for node deploys can be found in the PM2 docs.</p>
<pre><code>'use strict';
module.exports = {
    apps : [ ],
    /**
     * Deployment section
     * http://pm2.keymetrics.io/docs/usage/deployment/
     */
    deploy : {
        staging : {
            user : &quot;ubuntu&quot;,
            host : &quot;sample.staging.com&quot;,
            ref : &quot;origin/develop&quot;,
            repo : &quot;git@git.sample.com:group/project.git&quot;,
            path : &quot;/var/www/vhosts/project&quot;,
            &quot;pre-deploy-local&quot;: &quot;pm2 deploy deploy/sample.staging.config.js staging setup || echo 'already setup'&quot;,
            &quot;post-deploy&quot; : &quot;echo 'done. do not run default.'&quot;
        }
    }
};
</code></pre>
<h3><a class="header" href="#trouble-shooting" id="trouble-shooting">Trouble Shooting</a></h3>
<p>You will get a 403 when trying to run a build if you are not a member of the project. This can happen to admins who can access the build panel for projects they do not belong to.</p>
<h1><a class="header" href="#deploying-with-github" id="deploying-with-github">Deploying with Github</a></h1>
<p>tags: devops, deployment, github, webhooks</p>
<p>Github has many service that you can use for deployments.</p>
<p>Github also has webhooks. Webhooks are urls that github hits with a POST
request. Webhooks can also be used to trigger builds or do any number of
other things.</p>
<h2><a class="header" href="#securing-webhooks" id="securing-webhooks">Securing webhooks</a></h2>
<p>When you use webhooks, you want to make sure you <a href="https://developer.github.com/webhooks/securing/">secure your webhooks</a>.
This means setting a secret on github, and using that secret in your webhook
on the server to verify. In node you would do it as follows:</p>
<pre><code class="language-javascript">const express = require('express');
const bodyParser = require('body-parser');
const crypto = require('crypto');

const app = express();
const SECRET = 'my secret';

app.use(bodyParser.json());

app.post('/postreceive', (req, res) =&gt; {
    let hmac = crypto.createHmac('sha1', SECRET);
    let calculatedSignature = 'sha1=' + hmac.update(JSON.stringify(req.body)).digest('hex');
    let receivedSignature = req.headers['x-hub-signature'];
    if (calculatedSignature === receivedSignature) {
        // validated
    } else {
        // not validated
    }
</code></pre>
<h1><a class="header" href="#deploying-to-a-server" id="deploying-to-a-server">Deploying to a Server</a></h1>
<p>tags: devops, deployment, git-push</p>
<p>There are several types of deployments. A deployment workflow should always be
easy to remember, reliable, and repeatable. This section will cover how to deploy
from a work box to a staging or production server using <code>git push</code>.</p>
<p>Git 2.3+ supports push to deploy. In other words you can send code from your
computer to a server via ssh using git. Since git comes with hooks, including a
<code>post receive</code>, it is relatively straight forward to use git for deployment Heroku style.</p>
<p>Make sure you have git 2.3+. On a mac:</p>
<pre><code>brew update
brew upgrade git
</code></pre>
<p>You might have to rm a symlink to another version (<code>rm $(which git)</code>).</p>
<p>On ubuntu:</p>
<pre><code>sudo add-apt-repository ppa:git-core/ppa
sudo apt-get update
sudo apt-get install git
</code></pre>
<p>On the server, clone the repository. You should only clone the single branch the
deployments are on. This can be done with <code>--single-branch</code>:</p>
<p>For example, if all the deploys are on the branch <code>deploy/production</code>:</p>
<pre><code>cd /var/www/vhosts
git clone -b deploy/production --single-branch git@git.mydomain.com:foo/bar-project.git foo.bar.com
</code></pre>
<p>To enable pushing into the repo, you must enable it:</p>
<pre><code>cd foo.bar.com
git config receive.denyCurrentBranch updateInstead
</code></pre>
<p>Make sure ssh is enabled on your server.</p>
<p>This is the minimum setup. Additionally depending on the type of project, you
might want to setup post-receive hooks. These can be used to <code>npm install &amp;&amp; pm2 restart</code>,
notify New Relic of a deployment, etc.</p>
<p>The two tricky part about hooks are:</p>
<ol>
<li>
<p>Hooks are run by the user that was used for the ssh access. This could be important - for example - when updating node projects, where the user is important.</p>
</li>
<li>
<p>Commands must be fully qualified, so <code>git</code> won't work, but <code>/usr/local/bin/git</code> would.</p>
</li>
</ol>
<p>This completes the server setup. To setup your workbox, add the remote needed:</p>
<pre><code>git remote add deployProduction ssh://username@domain.com:1234/var/www/foo.bar.com
</code></pre>
<p>The format is the ssh login followed by the directory the git repo is in.</p>
<p>To deploy push the branch to the deployment remote:</p>
<pre><code>git push deployProduction deploy/production
</code></pre>
<p>This setup is flexible enough to allow deployments to multiple environments and repos.
Remember the full deployment command is a bother, so we often setup the command
<code>grunt deploy</code> which uses <code>grunt-prompt</code> to query the environment and any other information
needed:</p>
<pre><code>prompt : {
    deploy : {
        options : {
            questions : [
                {
                    config : 'environment',
                    type : 'list',
                    message : 'Envirnoment to deploy to:',
                    default : 'staging',
                    choices : ['staging', 'production']
                },
                {
                    config : 'clients',
                    type : 'checkbox',
                    message: 'Clients to deploy (space to pick, enter to finalize):',
                    choices: [
                        'one',
                        'two',
                        'two-and-a-half',
                        'three'
                    ]
                }
            ]
        }
    }
}
</code></pre>
<p>This can be combined with <code>grunt-shell</code> to do the full deploy.</p>
<h1><a class="header" href="#build-process-for-webpages" id="build-process-for-webpages">Build Process for Webpages</a></h1>
<p>tags: devops, deployment, web</p>
<p>This describes some general concepts for creating a build for an HTML page.
The HTML itself can be served as a file or via other methods (e.g. express &amp; a
jade template).</p>
<p>The build script itself has to accomplish some general things:</p>
<ul>
<li>build script (should be in bin of project)
<ul>
<li>it's generally useful to have things just work for locally deving, but
this means that for creating deploys you will have to run a specific
build task</li>
<li>differences between local dev and a deploy that need to be taken into
account for the build script.
<ul>
<li>replace watchify with browserify</li>
<li>make sure bin/deploy acutally builds all js/css/etc from the current.
<ul>
<li>This allows optimization of the assets</li>
<li>This will avoid issues where you just deploy the previously built local dev assets.</li>
</ul>
</li>
<li>make sure built assets are gitignored (bundle.js, main.css, etc)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>And some specific things:</p>
<ul>
<li>cache busting
<ul>
<li>convenient to us a hash of the file contents for this</li>
<li><code>&lt;script src=&quot;/optimized/js/dashboard.4978239874bae7.min.js&quot;&gt;&lt;/script&gt;</code></li>
<li>if using express and a jade template can use </li>
</ul>
</li>
<li>serving static assets
<ul>
<li>gzip and minify, ETAGs, ttl
<ul>
<li>gzip, minify, cache headers can be set in both nginx and node</li>
<li>gzip, minify nginx is good at</li>
<li>usually do etags on node</li>
</ul>
</li>
</ul>
</li>
<li>https://github.com/h5bp good source for boilerplate</li>
<li>awesome check http://tools.pingdom.com/fpt/</li>
<li>baseurl - if you want to be able to build to various folders</li>
<li></li>
</ul>
<h1><a class="header" href="#project-setup" id="project-setup">Project Setup</a></h1>
<p>tags: scaffolding, project-setup</p>
<p>This chapter describes a typical project setup. From deployment strategies, to
code organization. Many of the concepts covered will apply to any project, but
we will be using a website running with Mongo, Node, and Nginx as the example.
We'll assume the code is version controlled with git 2.3+. We'll also cover some
PHP Fpm concepts.</p>
<h1><a class="header" href="#application-architecture" id="application-architecture">Application Architecture</a></h1>
<p>tags: devops, scaffolding, project-setup, directories</p>
<h2><a class="header" href="#directory-structure" id="directory-structure">Directory structure</a></h2>
<p>The directory structure of an application has a surprisingly large effect on the
maintainability and debugability of a project. Being able to quickly find the
file you're looking for when onboarding to a new project increase efficiency.</p>
<p>For large JavaScript projects, there are two main ways to organize your files. One
is to separate files by functionality, and the other is two group functional units.</p>
<p>For example if you are making a Backbone app with models, views, and templates:</p>
<h3><a class="header" href="#functional-group-organization" id="functional-group-organization">Functional group organization</a></h3>
<pre><code>model
  calendar
  breadCrumb
  footer
view
  calendar
  breadCrumb
  footer
template
  calendar
  breadCrumb
  footer
</code></pre>
<h3><a class="header" href="#pod-organization" id="pod-organization">Pod organization</a></h3>
<pre><code>calendar
  model
  view
  template
breadCrumb
  model
  view
  template
footer
  model
  view
  template
</code></pre>
<h1><a class="header" href="#provisioning" id="provisioning">Provisioning</a></h1>
<p>tags: devops, scaffolding, provisioning</p>
<p>For each project you have to setup local, staging, and production environments.</p>
<p>It is almost always useful to have a Vagrant environment ready to go for local dev.
In some cases you may choose to not use it - for example node apps with limited data
are often very easy to run locally, but it is very helpful to be able to setup things
like nginx and databases on a Vagrant machine, so that you can emulate the server
and not have to drastically change or break your own local environment.</p>
<p>Vagrant uses a headless instance of Virtualbox to setup a virtual server that is
hosted by your computer. Your computer is referred to as the host, and the virtual
machine is referred to as the guest.</p>
<p>Vagrant has many base boxes ready for use. It is best practive to use a Vagrant
base box - such as <code>ubuntu/trusty64</code> - and provision it to cusomtize the environment.
This is more transparent than the alternative of taking a base box, customizing it,
and then using the snapshot of the customization for deving. Having the provisioning
of a vanilla base box in version control makes what is on the box very transparent.</p>
<p>Vagrant allows multiple methods of provisioning. Some are Puppet, shell, and Ansible.
In our experience shell provisioning - while simplest to initially setup - is too
difficult to maintain in the long run. You end up having to put too many conditionals
in your shell script to make it work irrespective of the starting state of the box.
Also shell script usually becomes spaghetti code, and instead of thinking about the
state you want to server to be in you end up thinking about how to get the server there.</p>
<p>Puppet is very full featured, but many devs find the syntax and details daunting to learn.
I find the docs hard to navigate. You also have to install puppet on your servers.</p>
<p>We found Ansible to have the smallest learning curve and the easiest to use in
practice. The only server dependency for Ansible is SSH access to the server.
Locally you have to have ansible installed, on a Mac this is:</p>
<pre><code class="language-shell">sudo easy_install pip
sudo pip install ansible
</code></pre>
<p>Ansible is written in python. Its commands are run in sequential order, which in my experience
makes it easier to debug than Puppet - which decdides upon the order to run things in.</p>
<h1><a class="header" href="#ansible" id="ansible">Ansible</a></h1>
<p>tags: devops, provisioning, ansible</p>
<p>Ansible allows you to guarantee an environment on one or many servers. At a high
level you run a playbook that has roles made up of tasks. Each role is a functional
chunck. For example there can be a &quot;git&quot; role that ensures git 2.3+ is available.</p>
<p>It is a good idea to separate general from project specific roles. For example
you could have an <code>nginx</code> role and an <code>nginx-project</code> role.</p>
<p>One of the nice things about Ansible is that it doesn't require anything else
than having Ansible installed locally and ssh access to the servers being
managed.</p>
<p>To install Ansible on a Mac use <code>pip</code>:</p>
<pre><code class="language-shell">sudo easy_install pip
sudo pip install ansible
</code></pre>
<p>If you are testing things out on vagrant - and not using just plain <code>vagrant up</code> - and need to use a password with ssh,
you might have to <a href="http://fauxzen.com/installing-sshpass-os-x/">install <code>sshpass</code></a>.
Though you don't need to install anything extra if you are simply using Ansible
as a provisioning agent for Vagrant.</p>
<p>We'll put everything in a directory. Create the directory and then we'll start by
setting up an Ansible hosts file. Below is an example setting up 2 vagrant boxes
at the same time. To follow along, setup vagrant in two separate directories with:</p>
<pre><code>config.vm.network &quot;private_network&quot;, ip: &quot;192.168.12.148&quot;
</code></pre>
<p>and</p>
<pre><code>config.vm.network &quot;private_network&quot;, ip: &quot;192.168.12.158&quot;
</code></pre>
<p>For example:</p>
<pre><code class="language-ruby"># -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure(&quot;2&quot;) do |config|
  config.vm.provider &quot;virtualbox&quot; do |v|
        # max specific
        # Give VM 1/4 system memory &amp; access to all cpu cores on the host
        cpus = `sysctl -n hw.ncpu`.to_i
        # sysctl returns Bytes and we need to convert to MB
        mem = `sysctl -n hw.memsize`.to_i / 1024 / 1024 / 4
        v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, mem]
        v.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, cpus]
  end

  config.vm.box = &quot;ubuntu/trusty64&quot;
  config.vm.network &quot;private_network&quot;, ip: &quot;192.168.12.158&quot;
end
</code></pre>
<p><a href="http://docs.ansible.com/intro_inventory.html#list-of-behavioral-inventory-parameters">Parameters you can add to a hosts file</a></p>
<pre><code>[vagrant]
192.168.12.148 ansible_ssh_user=vagrant ansible_ssh_pass=vagrant
192.168.12.158 ansible_ssh_user=vagrant ansible_ssh_pass=vagrant
</code></pre>
<p>Once vagrant is running (<code>vagrant global-status</code>), we can give things a test. Note
that you might have to manaully login once to add the RSA key fingerprints of the
Vagrant boxes. Then run the following:</p>
<pre><code class="language-shell">» ansible -m ping vagrant -i hosts
</code></pre>
<p>You should see:</p>
<pre><code>192.168.12.158 | success &gt;&gt; {
    &quot;changed&quot;: false,
    &quot;ping&quot;: &quot;pong&quot;
}

192.168.12.148 | success &gt;&gt; {
    &quot;changed&quot;: false,
    &quot;ping&quot;: &quot;pong&quot;
}
</code></pre>
<p>User roles to organize playbooks.</p>
<p>https://github.com/ansible/ansible-examples</p>
<h1><a class="header" href="#creating-an-ansible-playbook" id="creating-an-ansible-playbook">Creating an Ansible playbook</a></h1>
<p>tags: devops, provisioning, ansible</p>
<p>You can create an Ansible playbook with a set of roles. You will usually run roles
based on the host groups. You will probably end up running similar - though slightly different -
roles for your different host groups (local, staging, production).</p>
<p>You can quickly setup an Ansible playbook with a corresponding Vagrantfile using
the <code>ansible-ubuntu</code> npm. To use the npm, install it, then run it in the directory
you want your <code>Vagrantfile</code>:</p>
<pre><code class="language-shell">npm install -g ansible-ubuntu
cd ~/projects/my-new-project
ansible-ubuntu -v
</code></pre>
<p>The npm will prompt you for the roles you want included in your playbook.
After running it you will get an <code>ansible</code> directory and a <code>Vagrantfile</code>. You can
use these as a starting point for setting up your project specific playbook.</p>
<p>The <code>hosts</code> file lists the ips of the servers to provision. You can list multiple
name groups and pass variables based on the host. Ansible has docs on how to do this
in the hosts or inventory files.</p>
<p>The ansible-ubuntu npm adds a <code>vagrant</code> named group to be provisioned by vagrant.
If you update the private ip of the Vagrant box in the <code>Vagrantfile</code>, you have to
update the ip in the hosts file too.</p>
<p>To restrict Vagrant to only provision the <code>vagrant</code> named group, <code>ansible-limit</code> is used in
the <code>Vagrantfile</code>:</p>
<pre><code>config.vm.provision :ansible do |ansible|
   ansible.playbook = &quot;ansible/site.yml&quot;
   ansible.inventory_path = &quot;ansible/hosts&quot;
   ansible.limit = &quot;vagrant&quot;
   ansible.verbose = &quot;v&quot;
end
</code></pre>
<p>To share a directory between the hosts and guest, you can uncomment and modify
this line in the <code>Vagrantfile</code>:</p>
<pre><code># config.vm.synced_folder &quot;./&quot;, &quot;/var/www/vhosts/example/source&quot;, nfs: true
</code></pre>
<p>The first quoted path is the path on the host, and the second is the path on the guest.</p>
<h1><a class="header" href="#roles" id="roles">Roles</a></h1>
<p>tags: devops, provisioning, ansible</p>
<p>Roles are pod organized. The directory structure of each is essentially the same.
The following directories are often found in a role:</p>
<pre><code>- files
- meta
- tasks
- templates
</code></pre>
<p>Additionally <code>vars</code> and <code>defaults</code> may be found. Variables can be put into each
role or at the top of the directory structure. I find having all role related variables
in one place easier to manage than splitting them up.</p>
<p>To achieve this, you can make a <code>global_vars</code> directory at the top level. Each
file in this directory can be named based on the host group it applies to or <code>all</code>
if it applies to them all. Look at the docs for creating groups of groups, etc.</p>
<p>Roles can have conditional includes. These are most useful for handling various
scenarios is server environment differences (e.g. debian vs yum).</p>
<p>The roles to be run can be based on the host group in the <code>site.yml</code>. For example
to run a group of roles for all hosts, some for vagrant and some for staging:</p>
<pre><code class="language-yaml">---
- name: Environment Setup
  hosts: all
  sudo: yes
  roles:
    - essentials

- name: Server setup
  hosts: staging
  sudo: yes
  roles:
    - pm2-project

- name: Dev Server setup
  hosts: vagrant
  sudo: yes
  roles:
    - node-debug
</code></pre>
<p>host and group vars: http://docs.ansible.com/intro_inventory.html#splitting-out-host-and-group-specific-data</p>
<h1><a class="header" href="#vagrant" id="vagrant">Vagrant</a></h1>
<p>tags: vagrant, virtual box, debugging</p>
<p>How to add a locally downloaded vagrant box:</p>
<p>On the command line:</p>
<pre><code class="language-bash">vagrant box add my-box ~/Downloads/my-box
</code></pre>
<p>In you <code>Vagrantfile</code></p>
<pre><code class="language-ruby">  config.vm.box = &quot;my-box&quot;
</code></pre>
<h2><a class="header" href="#debugging-exports-files-is-invalid" id="debugging-exports-files-is-invalid">Debugging: Exports files is invalid</a></h2>
<p>If you move directories in which you've up vagrant instances, you'll end up getting an error related to the export file is invalid. Inspect and fix <code>/etc/exports</code> and then rerun the provisioning.</p>
<p>Sometimes it's easiest to delete the <code>/etc/exports</code> entry and shutoff and completely delete the Vagrant box and start from <code>vagrant up</code> again.</p>
<h2><a class="header" href="#debugging-vagrant-gathered-an-unknown-ansible-version" id="debugging-vagrant-gathered-an-unknown-ansible-version">Debugging: Vagrant gathered an unknown Ansible version</a></h2>
<p>Add a <a href="https://www.vagrantup.com/docs/provisioning/ansible_common.html#compatibility_mode">compatibility_mode</a> to the ansible config in your Vagrantfile.</p>
<p>e.g.:</p>
<pre><code>  config.vm.provision :ansible do |ansible|
    ansible.compatibility_mode = &quot;2.0&quot;
    ansible.playbook = &quot;ansible/site.yml&quot;
    ansible.inventory_path = &quot;ansible/hosts&quot;
    ansible.limit = &quot;vagrant&quot;
    ansible.verbose = &quot;v&quot;
  end
</code></pre>
<h2><a class="header" href="#debugging-weird-ansible-related-errors" id="debugging-weird-ansible-related-errors">Debugging: Weird ansible related errors</a></h2>
<p>Make sure Ansbile works. Run <code>ansible --version</code>. If it doesn't work, debug that first.</p>
<h1><a class="header" href="#exponential-back-off" id="exponential-back-off">Exponential Back Off</a></h1>
<p>tags: error-handling</p>
<p>Exponential back off is useful when dealing with things that can sporadically fail. For example if a server is under load,
a request might fail now, but it might work a few seconds later. This strategy eases pressure on the server, and the more times you try something and it fails,
the less likely it will work in the near future, so you can try at longer and longer intervals.</p>
<p>You should set a cap on the number of times to try.</p>
<p>This simple example uses recursion for the back off. <code>delay * 2</code> can be replaced with a function call that implements an alternative back off strategy.</p>
<pre><code class="language-javascript">// A function that keeps trying, &quot;toTry&quot; until it returns true or has
// tried &quot;max&quot; number of times. First retry has a delay of &quot;delay&quot;.
// &quot;callback&quot; is called upon success.
function exponentialBackoff(toTry, max, delay, callback) {
    var result = toTry();
    if (result) {
        callback(result);
    } else {
        if (max &gt; 0) {
            setTimeout(function() {
                exponentialBackoff(toTry, --max, delay * 2, callback);
            }, delay);
        } else {
             console.log('we give up');   
        }
    }
}
</code></pre>
<p><a href="http://jsfiddle.net/pajtai/pLka0ow9/">code</a></p>
<h1><a class="header" href="#file-upload" id="file-upload">File Upload</a></h1>
<p>tags: html, forms, files</p>
<h2><a class="header" href="#files-api" id="files-api">Files api</a></h2>
<p>Sending files via html/js can be done using the file api.</p>
<h3><a class="header" href="#javascript-example" id="javascript-example">JavaScript example</a></h3>
<pre><code class="language-html">&lt;input type=&quot;file&quot; id=&quot;it&quot; name=&quot;files&quot; multiple=&quot;multiple&quot; accept=&quot;image/*&quot; /&gt;
</code></pre>
<pre><code class="language-javascript">$.each($('input#it').files, function (file) {
    postNewAsset(file)
        .progress(function (progress) {
            console.log('Progress ' + progress);
        })
        .then(function () {
            alert('File uploaded!!!!');
        });
});

function postNewAsset (file) {
    var form_data = new FormData(),
        $deferred = new $.Deferred(),
        request;

    form_data.append('file', file);

    request = new XMLHttpRequest();

    request.upload.addEventListener('progress', function(e) {
        $deferred.notify((e.loaded / e.total) * 100 + '%');
    }, false);

    request.open('POST', 'http://example.com/upload');

    request.setRequestHeader('Accept', '*/*');

    request.onreadystatechange = function () {
        if (request.readyState !== 4) {
            return;
        }
        if ([200, 304].indexOf(request.status) === -1) {
            $deferred.reject(request.status);
        } else {
            $deferred.resolve(JSON.parse(request.response).message);
        }
    };

    request.send(form_data);

    return $deferred.promise();
}
</code></pre>
<h2><a class="header" href="#multipart" id="multipart">Multipart</a></h2>
<p>Multipart form data is used to send form data. It can be used to send files.</p>
<h3><a class="header" href="#sending-multipart-data-to-the-server" id="sending-multipart-data-to-the-server">Sending multipart data to the server</a></h3>
<ul>
<li>Data must be sent with a <code>Content-Type: multipart/form-data, boundary=--MY_UNIQUE_BOUNDARY--</code> header</li>
<li>The boundary is used to separate fields in the form. Example:</li>
</ul>
<pre><code class="language-text">----MY_UNIQUE_BOUNDARY--
Content-Disposition: form-data; name=&quot;field1&quot;

field value here
----MY_UNIQUE_BOUNDARY--
Content-Disposition: attachment; name=&quot;file1&quot;; filename=&quot;my_file.jpg&quot;
Content-Type: image/jpeg
Content-Transfer-Encoding: base64

874fbiu45fguh4uyb45b8uyb45uyb43fyutgrvub4yutgvbybrvuyuyfbuierhg4eiguqiubiuw4bgiu4b8b45g4g...
----MY_UNIQUE_BOUNDARY----
</code></pre>
<ul>
<li>Notes
<ul>
<li>boundaries in the post body must be prefixed with two hyphens (<code>--</code>)</li>
<li>the final boundary must have another two hyphens appended to it</li>
<li>lines must be terminated with a carriage-return followed by a line-break (<code>\r\n</code>)</li>
<li>Content-Encoding may be <code>base64</code> or <code>binary</code> (other encodings might be allowed as well)</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#c-example" id="c-example">C# example</a></h4>
<pre><code class="language-csharp">public async Task&lt;CurrentUser&gt; SetAvatar (byte[] imageBytes)
{
    var headerBoundary = &quot;--&quot; + Guid.NewGuid().ToString();
    var boundary = &quot;--&quot; + headerBoundary;
    var sb = new StringBuilder ();

    sb.Append(boundary + &quot;\r\n&quot;);
    sb.AppendFormat (&quot;Content-Disposition: attachment; name=\&quot;{0}\&quot;; filename=\&quot;{1}\&quot;\r\n&quot;, &quot;file&quot;, &quot;avatar.jpg&quot;);
    sb.Append (&quot;Content-Type: image/jpeg\r\n&quot;);
    sb.Append (&quot;Content-Transfer-Encoding: base64\r\n\r\n&quot;);
    sb.Append (Convert.ToBase64String (imageBytes, 0, imageBytes.Length) + &quot;\r\n&quot;);
    sb.AppendLine (boundary + &quot;--\r\n&quot;);

    var postBody = new StringContent (sb.ToString());
    postBody.Headers.Remove (&quot;Content-Type&quot;);
    postBody.Headers.TryAddWithoutValidation (&quot;Content-Type&quot;, &quot;multipart/form-data; boundary=&quot; + headerBoundary);

    UpdateFromUser(await Request.GetInstance ().Post&lt;User, StringContent&gt; (&quot;/user/avatar&quot;, postBody));

    return this;
}
</code></pre>
<p>Note the double quotes for the name and filename values. If you are receiving the data with the multiparty npm, then
currently this is needed. This will probably get fixed with <a href="https://github.com/andrewrk/node-multiparty/issues/101">issue 101</a>.</p>
<pre><code>name=\&quot;{0}\&quot;;
</code></pre>
<h1><a class="header" href="#forms" id="forms">Forms</a></h1>
<p>tags: html, forms</p>
<p>To restrict the type of files available in modern browsers, use <code>accept</code>:</p>
<pre><code class="language-html">&lt;input type=&quot;file&quot; id=&quot;uploadFileInput&quot; name=&quot;files&quot; multiple=&quot;multiple&quot; accept=&quot;image/*&quot; /&gt;
</code></pre>
<p><a href="http://jsfiddle.net/b69bvcg4/">code</a></p>
<h1><a class="header" href="#infusionsoft" id="infusionsoft">Infusionsoft</a></h1>
<p>tags: infusionsoft, crm</p>
<h2><a class="header" href="#api-overview" id="api-overview">API overview</a></h2>
<ul>
<li>Create a developer application at: https://keys.developer.infusionsoft.com/.</li>
<li>The developer application will have a client id and secret.</li>
<li>Normally this id and secret would be used to authenticate requests to the api, but with the Infusionsoft api, the id and secret merely identifies the application--api requests are authenticated with an access token obtained initially via an OAuth flow using an infusionsoft account.</li>
<li>The access token expires in 24h, but it includes a refresh token that can be used to obtain a new access token upon expiration. The refresh token lasts 90d.</li>
<li>Thus, infusionsoft api access involves setting up an OAuth interface to obtain the initial access token, and then managing the token refresh when it expires.</li>
<li>This setup is eased with the help of infusionsoft's sdks. With php it looks kinda like this:</li>
</ul>
<p>Path: all</p>
<pre><code class="language-php">require_once 'vendor/autoload.php';

$infusionsoft = new \Infusionsoft\Infusionsoft(array(
	'clientId'     =&gt; 'XXXXXXXXXXXXXXXXXXXXXXXX',
    'clientSecret' =&gt; 'XXXXXXXXXX',
    // Set to where to plan to handle the oauth callback in your app.
	'redirectUri'  =&gt; 'http://example.com/oauth-callback',
));

// Auth url goes to infusionsoft.com, where you can login and authorize this app to have api access.
// After authorizing, we will be redirected back to redirectUri above, where we can turn in the access code
// for an access token.
echo '&lt;a href=&quot;' . $infusionsoft-&gt;getAuthorizationUrl() . '&quot;&gt;Click here to authorize&lt;/a&gt;';
</code></pre>
<p>Path: <code>/oauth-callback</code> (Just an example to match redirectUri above.)</p>
<pre><code class="language-php">if (isset($_GET['code']) {
    // Oauth flow will return with code, which we turn in for an access code.
    $token = $infusionsoft-&gt;requestAccessToken($_GET['code']);

    // Save the token to storage (whatever that may be) for api requests.
	save_token_to_storage(serialize($token));
}
</code></pre>
<p>Path: <code>/infusionsoft-contacts</code> (Just an example page that lists contacts from infusionsoft.)</p>
<pre><code class="language-php">// Get token from storage (whatever that may be).
$token = unserialize(get_token_from_storage());

// If we don't have a token, we need an infusionsoft account to authorize via oauth to obtain one.
if (!$token) {
    return;
}

$infusionsoft-&gt;setToken($token);

// Check if token is expired, and refresh it if needed.
if ($infusionsoft-&gt;isTokenExpired()) {
    $token = $infusionsoft-&gt;refreshAccessToken();

    // Save new token to storage.
	save_token_to_storage(serialize($token));
}

// We now have a non-expired token to make infusionsoft requests with.
echo $infusionsoft-&gt;contacts()-&gt;all();
</code></pre>
<h2><a class="header" href="#sdks" id="sdks">Sdks</a></h2>
<ul>
<li>php: https://github.com/infusionsoft/infusionsoft-php</li>
</ul>
<h1><a class="header" href="#javascript" id="javascript">JavaScript</a></h1>
<p>tags: javascript</p>
<h2><a class="header" href="#scope" id="scope">Scope</a></h2>
<p>Working with modern JS methods, it's easy to forget about scope pollution. In vanilla JavaScript, a simple way to ensure you do not pollute the global namespace and can expose what you see fit is using the IIFE (Immediately Invoked Function Expression):</p>
<pre><code class="language-javascript">(function($) {
    const $imNotPolluting = $(&quot;#blah&quot;);
    const $thisWillBeGlobal = $(&quot;input&quot;, $imNotPolluting);
    
    window.$blahInputs = $thisWillBeGlobal;
})(jQuery);
</code></pre>
<p>References: </p>
<ul>
<li>http://benalman.com/news/2010/11/immediately-invoked-function-expression/</li>
<li>http://markdalgleish.com/2011/03/self-executing-anonymous-functions/</li>
</ul>
<h1><a class="header" href="#error-handling-in-javascript" id="error-handling-in-javascript">Error Handling in JavaScript</a></h1>
<p>tags: javascript, error-handling</p>
<p>Error handling is tricky in JavaScript because JavaScript is single threaded.
For example
the following code will not alert, &quot;error caught&quot;:</p>
<pre><code class="language-javascript">try {
  setTimeout(
    function() { throw new Error('async error'); }
  )
} catch (error) {
  alert('error caught');
}
</code></pre>
<p>This is because each line is only run once, and at the point the error is thrown,
the catch block has already executed - that is been skipped because there was no error.</p>
<p>So, these lines run first:</p>
<pre><code class="language-javascript">try {
  setTimeout(

  )
} catch (error) {
  alert('error caught');
}
</code></pre>
<p>After this is run and the call stack is depleted, the callback for setTimeout runs:</p>
<pre><code class="language-javascript">throw new Error('async error');
</code></pre>
<p>At this point the original catch block is no longer available to catch the error.</p>
<h1><a class="header" href="#es6" id="es6">ES6</a></h1>
<p>tags: javascript, es6</p>
<h2><a class="header" href="#let-keyword" id="let-keyword">Let keyword</a></h2>
<p><code>var</code> is the old way of defining variables. It has function scope.</p>
<p><code>let</code> is an es6 way pf defining variable; it has block scope.</p>
<pre><code class="language-javascript">
function() {
  // v1 exists but is undefined
  // v2 doesn't exist

  for(let v2=0; v2&lt;10; ++v2) {
    // v2 is defined
    // v1 is defined
}

  var v1=0;
  // v1 is defined
  // v2 doesn't exist
}
</code></pre>
<h2><a class="header" href="#const-keyword" id="const-keyword">const keyword</a></h2>
<p>gives you a constant that you cannot modify.</p>
<h2><a class="header" href="#returning-multiple-values" id="returning-multiple-values">returning multiple values</a></h2>
<p>Can assign return value to an array and then lift out the variables:</p>
<pre><code class="language-javascript">function account_info() {
    var info = 'something',
        err = Math.random() &lt; 0.5;

    return [err ? null : info, err ? 'the reason' : null];
}

setInterval(function() {
    var info, error;

    [info, error] = account_info();

    if (error) {
        console.log('sorry',error);
    } else {
        console.log('welcome',info);
    }

}, 1000);
</code></pre>
<h2><a class="header" href="#destructuring" id="destructuring">Destructuring</a></h2>
<h3><a class="header" href="#object" id="object">Object</a></h3>
<p>Pull variables out of an object:</p>
<pre><code class="language-js">const obj = {
    a: 'one',
    b: 'two'
}

const { a, b } = obj;

console.log(a) // one
console.log(b) // two
</code></pre>
<p>You can also reassign variables during deconstruction:</p>
<pre><code class="language-js">const { a: testA, b: testB } = obj;

console.log(testA) // one
console.log(testB) // two
</code></pre>
<p>You can even use bracket notation in deconstruction in case the object keys have special characters:</p>
<pre><code class="language-js">const obj = {
    'Difficult key': 'one',
    'what-a-pain': 'two'
}

const { ['Difficult key']: managable, ['what-a-pain']: painless } = obj;

console.log(managable) // one
console.log(painless) // two
</code></pre>
<h3><a class="header" href="#array" id="array">Array</a></h3>
<pre><code class="language-js">const [name, email] = ['John', 'john@mail.com'];

console.log(name) // John
console.log(email) // john@mail.com
</code></pre>
<ul>
<li>All destructuring examples work in function arguments too.</li>
</ul>
<h1><a class="header" href="#working-with-promises" id="working-with-promises">Working with promises</a></h1>
<p>tags: javascript, promises</p>
<p>Bluebird has a good section on anti patterns.</p>
<p>In general your then blocks should be small. Functions should return promises vs
passing promise chains in to functions, and the modification of the context should
always be at the same level of visibility as the bind. Specifics below:</p>
<h2><a class="header" href="#return-a-promise" id="return-a-promise">Return a promise</a></h2>
<p>If your functions return a promise, it is easy to reuse them.</p>
<pre><code class="language-javascript">function doWork(work) {
  return new BB(function(resolve)) {
    setTimeout(function() {
      resolve('done with ' + work);
    }, 500);
  }
}
</code></pre>
<p>Now you can create more async functions out of this:</p>
<pre><code class="language-javascript">function doMuchWork() {
  return BB.all([1,2,3,4,5].map(function(work) {
    return doWork(work);
  }));
}
</code></pre>
<p>This enables a clear control flow:</p>
<pre><code class="language-javascript">BB
  .try(doMuchWork)
  .then(doMuchMoreWork);
</code></pre>
<p>The antipattern to this is passing in promise chains that get added to:</p>
<pre><code class="language-javascript">// this is brittle and hard to modularize
function doWork(work, promises) {
  promises.push(doSomething(work));
  return promises;
}
</code></pre>
<h2><a class="header" href="#modify-the-context-at-one-level-of-visibility" id="modify-the-context-at-one-level-of-visibility">Modify the context at one level of visibility</a></h2>
<p>BB has a very useful method called bind:</p>
<pre><code class="language-javascript">BB
  .bind({
    name : 'ratatat'
  })
  .then(function() {
    console.log(this.name); // ratatat
  });
</code></pre>
<p>The context is useful for building up a complex compound result, but the context
can become difficult to manage. To ease in its management, do not hide it's modification,
but modify it at the same level of visibility as it is bound:</p>
<pre><code class="language-javascript">BB
    .bind({
      id : 'abc',
      name : null
    })
    .then(getName)
    .then(function(name) {
      this.name = name;
    })
    .then(returnResult);
</code></pre>
<p>The above is much easier to debug than having <code>this.name = name</code> inside the <code>getName</code>
function.</p>
<p>It is important to keep in mind that newly create chains are unbound so you have to rebind them:</p>
<pre><code class="language-javascript">BB
  .bind({
    name:'jane'
  })
  .then(function() {

      // Creating a new chain, so you have to bind it
      return BB
        .bind(this)
        .then(doSomething);
  });
</code></pre>
<h2><a class="header" href="#start-chains-with-a-function-reference" id="start-chains-with-a-function-reference">Start chains with a function reference</a></h2>
<p>If you start a chain with a function call, then synchronous errors in that function
are not caugh by the promise, so use a function reference:</p>
<pre><code class="language-javascript">// errors from functionReference will be caught by BB
BB
    .try(functionReference)
    .then(...)

// functionReference will through synchronous errors
functionReference()
    .then()
</code></pre>
<h2><a class="header" href="#use-join-if-you-know-how-many-promises-you-have" id="use-join-if-you-know-how-many-promises-you-have">Use join if you know how many promises you have:</a></h2>
<p>Note that the last function is the callback:</p>
<pre><code class="language-javascript">BB.join(getNames(), getNumbers(), function(name, numbers) {

  });
</code></pre>
<p>Combining BB with array / lodash methods can be very expressive:</p>
<h2><a class="header" href="#try-to-keep-the-control-flow-as-unified-as-possible-and-break-out-the-async-work" id="try-to-keep-the-control-flow-as-unified-as-possible-and-break-out-the-async-work">Try to keep the control flow as unified as possible, and break out the async work</a></h2>
<p>This often make future modifications and debugging easier. It keeps function logic separate
from control flow.</p>
<pre><code class="language-javascript">BB.try(getPartOne)
  .then(getPartTwo)
  .then(getPartThree)
  .then(assembleParts);
</code></pre>
<p>vs making a method call called <code>getParts</code> which chains the different get part calls.</p>
<h2><a class="header" href="#try-to-have-as-few-catches-as-possible-with-specific-throws" id="try-to-have-as-few-catches-as-possible-with-specific-throws">Try to have as few catches as possible with specific throws</a></h2>
<pre><code class="language-javascript">BB.try(getPartOne)
  .then(getPartTwo)
  .then(getPartThree)
  .catch();
</code></pre>
<p>vs having a catch in each get part. Remember if you do have a catch in each part, the
chain will keep going on an error and not terminate:</p>
<pre><code class="language-javascript">BB.try(getPartOne)
  .then(getPartTwo)
  .then(getPartThree)
  .catch();

  function getPartOne() {
    return BB.try(...)
      .catch();
  }
</code></pre>
<p>is equal to:</p>
<pre><code class="language-javascript">BB.try(getPartOne)
  .catch(...)
  .then(getPartTwo)
  .then(getPartThree)
  .catch();
</code></pre>
<p>so, you'll always get to getPartTwo.</p>
<h1><a class="header" href="#node" id="node">node</a></h1>
<p>tags: javascript, node</p>
<p>Here is a way to run an array of shell commands in order:</p>
<pre><code class="language-javascript">function runCommands(commands, done, cwd) {
  var childProcess,
      command;

  while (command = commands.shift()) {
    childProcess = exec(command, {
      cwd: cwd,
      customFds: [0, 1, 2]
    }, function(err) {
      console.log('done with:', command);
      if (err) {
        console.log('try the command again. there was an error:', err);

        // stop and call done on the next iteration.
        commands = [];
      }
    });
  }

  done();
}
</code></pre>
<pre><code class="language-javascript">function runCommands(commands, done, cwd) {
    var childProcess,
        command = commands.shift();

    if (!command) {
        done();
    } else {
        childProcess = exec(command, {
            cwd: cwd,
            customFds: [0,1,2]
        }, function(err) {
            console.log('done with', command);
            if (err) {
                console.log('try the command again. there was an error:', err);
                commands = [];
                done();
            } else {
                runCommands(commands, done, cwd);
            }
        });
        captureOutput(childProcess);
    }
}


function captureOutput(childProcess) {
    childProcess.stdout.pipe(process.stdout);
    childProcess.stderr.pipe(process.stderr);
    return childProcess;
}
</code></pre>
<p>Example usage:</p>
<pre><code>
</code></pre>
<h1><a class="header" href="#debugging-node-running-on-a-remote-server" id="debugging-node-running-on-a-remote-server">Debugging Node running on a remote server</a></h1>
<p>tags: javascript, node, debugging</p>
<p>Node uses a <a href="https://nodejs.org/api/debugger.html">TCP interface</a> for debugging, so if you can get a handle on the right port, you can debug apps running remotely. This means you can run through code on staging, Vagrant, etc. The following shows you how to start node with the debug flag and use an SSH tunnel to access the right port.</p>
<p>Things you need:</p>
<ul>
<li>ssh access to the server</li>
<li>ability to restart node app with <code>--debug</code> flag or <code>node-inspector</code> installed on server</li>
</ul>
<h2><a class="header" href="#debugging-using-visual-studio-code" id="debugging-using-visual-studio-code">Debugging using Visual Studio Code</a></h2>
<ol>
<li>Click on the Debug icon</li>
<li>In the upper dropdown, click &quot;Add Configuration&quot;</li>
<li>Select Node if needed</li>
<li>In the launch.json, pick &quot;Attach by Process&quot;</li>
<li>Start your app with the <code>--inspect</code> flag</li>
<li>Select &quot;Attach by Process ID&quot; right of the green play button</li>
<li>Click play button</li>
</ol>
<p>Your launch.json should look something like:</p>
<pre><code class="language-json">{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    &quot;version&quot;: &quot;0.2.0&quot;,
    &quot;configurations&quot;: [
        {
            &quot;type&quot;: &quot;node&quot;,
            &quot;request&quot;: &quot;attach&quot;,
            &quot;name&quot;: &quot;Attach by Process ID&quot;,
            &quot;processId&quot;: &quot;${command:PickProcess}&quot;
        }
    ]
}
</code></pre>
<h2><a class="header" href="#debugging-using-webstorm" id="debugging-using-webstorm">Debugging using Webstorm</a></h2>
<ol>
<li>
<p>Stop the app</p>
</li>
<li>
<p>Restart with <code>--inspect</code> flag (and include any necessary env flags) (could setup a name pm2 for this)</p>
<pre><code class="language-bash"># example with an env variable sent int
NODE_ENV=staging node --inspect /home/node_user/my-app
</code></pre>
</li>
<li>
<p>When it starts you should see something like <code>debugger listening on 5858</code></p>
</li>
<li>
<p>Setup webstorm</p>
<ol>
<li><code>Run &gt; Debug... &gt; Edit Configurations... &gt; Add new configuration &gt; Node.js Remote Debug</code></li>
<li>Host : <code>127.0.0.1</code> - Port : <code>5858</code></li>
</ol>
</li>
<li>
<p>Open SSH Tunnel to gain access to servers port 5858.</p>
<pre><code class="language-bash"># open an ssh tunnel, send it to the bg, and wait 10 seconds for connections
# once all connections are closed after 10 seconds then close the tunnel
ssh -f -o ExitOnForwardFailure=yes -L 5858:127.0.0.1:5858 node_user@168.144.24.98 sleep 10
</code></pre>
</li>
<li>
<p>Make sure you checkout the same code on your local machine as on the remote server.</p>
</li>
<li>
<p>Run the debugger in Webstorm (drop down in upper right next to the Bug icon - or the bug icon once you've run it once)</p>
</li>
</ol>
<h2><a class="header" href="#debugging-using-a-hrefhttpsgithubcomnode-inspectornode-inspectornode-inspectora" id="debugging-using-a-hrefhttpsgithubcomnode-inspectornode-inspectornode-inspectora">Debugging using <a href="https://github.com/node-inspector/node-inspector">Node Inspector</a></a></h2>
<p>You can follow similar instruction for using <a href="https://github.com/node-inspector/node-inspector">node-inspector</a> just use port <code>8080</code> instead of <code>5858</code> and open Chrome at: http://127.0.0.1:8080/?ws=127.0.0.1:8080&amp;port=5858 (you might want to use the <code>--debug-brk</code> flag instead of the <code>debug</code> flag if you can't set a breakpoint in time. Instead of starting with the debug flag, you woul install node incpector on the server and start the app using that.</p>
<p>In practice using Webstorm - port 5858 directly - seems to work much better.</p>
<h2><a class="header" href="#last-steps" id="last-steps">Last Steps</a></h2>
<p>If needed don't forget to stop the app and restart without the debug flag.</p>
<h1><a class="header" href="#npm" id="npm">npm</a></h1>
<p>tags: javascript, node, npm</p>
<p>When developing an npm module, you often want to test thing out before publishing.
There are two main ways to do this.</p>
<p>If you want to pull a local copy of an npm in, this can be done in two steps
using <a href="https://docs.npmjs.com/cli/link"><code>npm link</code></a>.</p>
<ol>
<li>Go to the module you are testing and run <code>npm link</code></li>
<li>Go the project you want to pull the module into and run <code>npm link &lt;module-name</code>.</li>
</ol>
<p>If you're not quite ready to even create a separate module in an app, then
you can make use of <a href="https://docs.npmjs.com/files/package.json#local-paths"><code>local paths</code></a>.
Local paths are module written into your app that get copied into <code>node_modules</code> when
you run and npm install of the for <code>file:...</code>.</p>
<p>If you are testing a module that has local modules, you will not be able to
install the test module without copying your local modules directories over.</p>
<p>For example if you are doing <code>npm install test-module</code> and your test-module
has local paths you will need to</p>
<pre><code>mkdir -p node_modules/test-module
cp -R /path/to/test-module/local_modules node_modules/test-module/local_modules
</code></pre>
<p>This is because <code>npm install</code> only write to <code>node_modules</code> after it succeeds,
so during the install it would not be able to find an local modules.</p>
<h2><a class="header" href="#packagejson" id="packagejson">package.json</a></h2>
<p>The scripts in ``package.json<code>can access the locally install</code>.bin<code>files. For example after</code>npm install --save-dev jshint<code>you can run jshint via</code>npm test<code>using the following addition to your</code>package.json` even if you do not
have jshint installed globally:</p>
<pre><code class="language-json">  &quot;scripts&quot;: {
    &quot;test&quot;: &quot;jshint app&quot;,
  },
</code></pre>
<h2><a class="header" href="#one-liners" id="one-liners">One-liners</a></h2>
<p>Install package and save to <code>package.json</code> <code>dependecies</code></p>
<pre><code class="language-sh">npm install --save package-name
</code></pre>
<p>Install package and save to <code>package.json</code> <code>devDependecies</code></p>
<pre><code class="language-sh">npm install --save-dev package-name
</code></pre>
<p>Get latest version of package</p>
<pre><code class="language-sh">npm view package-name version
</code></pre>
<p>Get version of current package, npm, node, etc.</p>
<pre><code class="language-sh">npm version
</code></pre>
<p>Bump current package version and commit it</p>
<pre><code class="language-sh">npm version [&lt;newversion&gt; | major | minor | patch | premajor | preminor | prepatch | prerelease | from-git]
</code></pre>
<p>Semver is <code>major.minor.patch[-pre]</code>. Each subcommand bumps the corresponding number. The <code>pre</code>-variant subcommands bump the corresponding number and append <code>-0</code>, if there is currently no <code>pre</code> number. If there is a prenumber, use <code>prerelease</code> to bump the <code>pre number. When you go to actually release, use the standard variant to remove the </code>pre` number.</p>
<h1><a class="header" href="#pm2" id="pm2">PM2</a></h1>
<p>tags: node, pm2, monitoring</p>
<h2><a class="header" href="#logs" id="logs">Logs</a></h2>
<p>App logs are kept in <code>~/.pm2/app-out.log</code> and ~/.pm2/app-error.log`.</p>
<p>PM2 level logs (e.g. process restarted) are kept in <code>~/.pm2/pm2.log</code>.</p>
<h1><a class="header" href="#transpiling-javascript" id="transpiling-javascript">Transpiling javascript</a></h1>
<p>tags: javascript, babel, typescript, es2015</p>
<h2><a class="header" href="#why" id="why">Why</a></h2>
<p>Javascript is in flux. New features are being added all the time and developers want to use these new features. The problem is that these new features might not actually be supported in browsers. To get around this, several projects (babel, typescript) have been created to convert this new js into functionally-equivalent old js. This process is called transpilation.</p>
<h2><a class="header" href="#transpile-vs-polyfill" id="transpile-vs-polyfill">Transpile vs. polyfill</a></h2>
<p><strong><em>Transpilation</em> converts syntactically-invalid code to functionally-equivalent valid code of the target, it does not <em>polyfill</em> javascript objects and methods the target lacks</strong>. E.g. in es5, rest/spread (<code>...</code>) and arrow functions (<code>=&gt;</code>) are syntax errors. <code>Object.assign</code> is not a part of native es5, but it is syntactially valid. So transpilation to es5 will convert rest/spread and arrow functions, but leave <code>Object.assign</code> as is. <code>Object.assign</code> will have to be polyfilled in addition to the transpilation process.</p>
<h1><a class="header" href="#vue" id="vue">Vue</a></h1>
<p>tags: javascript, vue</p>
<h2><a class="header" href="#reactivity" id="reactivity">Reactivity</a></h2>
<p>Things are reactive if a field change triggers a ui change. The way you get things reactive is by having the fields present
on the object when loaded from <code>data</code>.</p>
<p>If you are thinking about reactivity, then adding empty fields on the backend API responses is very helpful for reactivity
on the front end.</p>
<ul>
<li>https://vuejs.org/v2/guide/reactivity.html</li>
</ul>
<h2><a class="header" href="#using-sass" id="using-sass">Using sass:</a></h2>
<p>If you template:</p>
<pre><code class="language-html">&lt;style lang=&quot;scss&quot; scoped&gt;
body { background-color: $mycolor; }
&lt;/style&gt;
</code></pre>
<p>You can <code>@import</code> from templates as you see fit, but if you want to @import a framework or lot of css globally, then just use <code>main.js</code>.</p>
<p>The below will only work with Weback. It will not work with browserify.</p>
<pre><code class="language-javascript">// The Vue build version to load with the `import` command
// (runtime-only or standalone) has been set in webpack.base.conf with an alias.
import 'bulma/css/bulma.css';
import Vue from 'vue';
import App from './App';
import router from './router';

Vue.config.productionTip = false;
</code></pre>
<h2><a class="header" href="#loops" id="loops">Loops</a></h2>
<p>You can get the index in a loop</p>
<pre><code class="language-html">&lt;tr v-for=&quot;(trainee, index) in trainees&quot;&gt;
    &lt;td&gt;{{ trainee.display_name }}&lt;/td&gt;
    &lt;td @click=&quot;remove(index)&quot;&gt;&lt;i class=&quot;fa fa-minus-circle&quot;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;/tr&gt;
</code></pre>
<p>and then remove would look like:</p>
<pre><code class="language-javascript">remove(index) {
    this.trainees.splice(index, 1)
}
</code></pre>
<h1><a class="header" href="#web-apis" id="web-apis">Web apis</a></h1>
<p>tags: javascript, web</p>
<h2><a class="header" href="#intro" id="intro">Intro</a></h2>
<p>There are many apis avilable to javascript when working on the web. This doc will cover notable/tricky ones. See <a href="https://developer.mozilla.org/en-US/docs/Web/API">MDN</a> for the exhaustive list.</p>
<h2><a class="header" href="#fetch" id="fetch"><code>fetch</code></a></h2>
<p><code>fetch</code> takes a url and an optional options object, and returns a promise that resolves to a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Response"><code>Response</code></a> object.
Example:</p>
<pre><code class="language-js">// fetch is on the global object, e.g. window
fetch('https://cross-origin.example.com/api/v1/users', {
    method: 'GET',
    // By default, fetch does not include cookies.
    // For cross-origin requests use 'include'.
    // For same origin requests use 'same-origin'.
    credentials: 'include',
    // For cross-origin requests use mode 'cors'.
    mode: 'cors',
    // any headers you want to add to the request
    // browser will add cookie headers based on the credentials setting
    headers: {
        Accept: 'application/json'
    }
})
    .then(res =&gt; res.json())
    .then(json =&gt; {
        // use json here
    });
</code></pre>
<p>Notes</p>
<ul>
<li><code>fetch</code> is relatively new, so github has a <a href="https://github.com/github/fetch">polyfill</a> for older browsers implemented with <code>XMLHttpRequest</code></li>
</ul>
<h1><a class="header" href="#typescript" id="typescript">Typescript</a></h1>
<p>tags: typescript, javascript</p>
<p>Typescript is a structurally-typed language: Along with typing values as primitive types (string, number, etc.), you can create interfaces that describe the structure of objects. Interfaces are declared in typescript itself.</p>
<h2><a class="header" href="#type-declaration-files" id="type-declaration-files">Type declaration files</a></h2>
<p>A common scenario for using type declaration files is importing an npm. Some npms include type declaration files for themselves, while others are installed from Definitely-typed, which are under the @types namespace on npm. These type definition files are just typescript files. The convention is to name the file ending in <code>.d.ts</code>.</p>
<p>For example:</p>
<pre><code class="language-js">import { baseN } from 'js-combinatorics';
</code></pre>
<p>Will throw a typescript compile error because the module does not include its own type declarations. However, if you hover over the module name in vscode, the editor will suggest:</p>
<pre><code class="language-sh">npm install @types/js-combinatorics
</code></pre>
<p>It is a pretty popular module, so someone has actually created the type file for it. So with the types install, using <code>baseN</code> will compile.</p>
<p>However <code>knuth-shuffle</code> isn't so convenient:</p>
<pre><code class="language-js">import { knuthShuffle } from 'knuth-shuffle';
</code></pre>
<p>Typescript will complain about no types for this module, and unfortunately, <code>@types/knuth-shuffle</code> doesn't exist right now. We will have to write our own.</p>
<p>Add a <code>.d.ts</code> file to your project in the path included in your typescript config, and add the missing typing:</p>
<pre><code class="language-ts">declare module 'knuth-shuffle' {
    export function knuthShuffle&lt;T&gt;(array: T[]): T[];
}
</code></pre>
<p>Now you can use the function where you imported it, and typesscript will compile it.</p>
<h2><a class="header" href="#generics" id="generics">Generics</a></h2>
<p>Take this type declaration:</p>
<pre><code class="language-ts">export function someArrayFunction&lt;T&gt;(argName: T[]): T[];
</code></pre>
<p>Notice the <code>&lt;T&gt;</code>? It allows you to type a function return value by the type of its arguments. This is saying, &quot;someArrayFunction takes an array of values and returns another array of the same type of values.&quot; This pattern is used all the time in typescript. See <a href="https://www.typescriptlang.org/docs/handbook/generics.html">docs</a>.</p>
<h2><a class="header" href="#interfaces" id="interfaces">Interfaces</a></h2>
<p>Say you want to define an object literal with property as an empty array:</p>
<pre><code class="language-js">let obj = {
    a: [],
    b: 'text'
}
</code></pre>
<p>Typescript will think <code>obj.a</code> is type <code>never[]</code>. To get the type you want, you can create an interface:</p>
<pre><code class="language-ts">interface Obj {
    a: number[],
    b: string
}

let obj: Obj = {
    a: [],
    b: 'text
}
</code></pre>
<h2><a class="header" href="#type-assertion" id="type-assertion">Type assertion</a></h2>
<p>From the previous example, if you don't need to reuse the <code>Obj</code> interface anywhere else, you can simply annotate the obj literal properties by the using type assertion keyword <code>as</code>:</p>
<pre><code class="language-ts">let obj: Obj = {
    a: [] as number[],
    b: 'text
}
</code></pre>
<h2><a class="header" href="#configuration" id="configuration">Configuration</a></h2>
<p>Typescript is usually configured with a <code>tsconfig.json</code> in the root of the project.</p>
<pre><code class="language-json">{
  &quot;compilerOptions&quot;: {
    &quot;...&quot;: ...
  },
  &quot;include&quot;: [
    &quot;...&quot;
  ],
  &quot;exclude&quot;: [
    &quot;...&quot;
  ]
}
</code></pre>
<h2><a class="header" href="#standard-library" id="standard-library">Standard library</a></h2>
<p>Typescript might complain about newer javascript methods like <code>Array.from</code> from es2015. Typescript will compile js based on the target set in <code>tsconfig.json</code>, e.g. if you target <code>es5</code>, typescript will not compile <code>es2015</code> or later. To make typescript compile this, you have several options:</p>
<ol>
<li>Change the target: <code>compilerOptions.target: &quot;es2015&quot;</code> - target es2015 if you want to to compile es2015; this might not be an option if your js needs to run in older browsers</li>
<li>Include the lib: <code>compilerOptions.lib: [&quot;es2015&quot;]</code> - this will transpile to es2015 syntax to es5, with es2015 objects and methods intact. <strong>Note: transpilation does not polyfill objects and methods. See <a href="javascript/typescript//js/transpiling">transpiling</a></strong>.</li>
</ol>
<p>Add <code>&quot;dom&quot;</code> to libs, for DOM api support.</p>
<h2><a class="header" href="#vuejs" id="vuejs">Vue.js</a></h2>
<p>Vue has pretty solid typescript support. Their cli has a project scaffolder built-in with typescript as a first class option. That said, the typescript experience with the vue, vuex, vue-router stack leaves much to be desired. It is challenging to achieve type safety when integrating Vuex. Maybe future releases will make it so dead-simple and helpful that it would be stupid not to use typescript. But right now there is a lot of overhead involved, and you really have to want it to make it work.</p>
<h3><a class="header" href="#type-array-props" id="type-array-props">Type array props</a></h3>
<p>Vue's api allows developers to type component props with the type constructor in native js, e.g.</p>
<pre><code class="language-js">// in component definition
props: {
    id: Number,
    selectedIds: Array,
}
</code></pre>
<p>Typescript infers <code>this.id</code> as type <code>number</code>, but <code>this.selectedIds</code> is inferred as type <code>any[]</code>. This is not helpful; we need to know the type of the array items, e.g. <code>number[]</code>. This can be achieved by asserting the return type of the <code>Array</code> constructor:</p>
<pre><code class="language-ts">props: {
    selectedIds: Array as (() =&gt; number[])
}
</code></pre>
<p>Now <code>this.selectedIds</code> will be correctly inferred as type <code>number[]</code>.</p>
<h2><a class="header" href="#helpful-links" id="helpful-links">Helpful links</a></h2>
<ul>
<li><a href="https://basarat.gitbooks.io/typescript/content/docs/getting-started.html">Typescript Deep Dive</a> - awesome online book that is more readable than the typescript docs</li>
<li><a href="https://www.typescriptlang.org/docs/handbook/compiler-options.html">Typescript compiler options</a></li>
</ul>
<h1><a class="header" href="#creating-cli-commands" id="creating-cli-commands">Creating cli commands</a></h1>
<p>tags: linux, cli</p>
<h2><a class="header" href="#example" id="example">Example</a></h2>
<pre><code class="language-shell">#!/usr/bin/env bash
#set -x # for debugging

    while test $# -gt 0; do
        case &quot;$1&quot; in
            -h|--help)
                echo &quot;Ansible provisioning&quot;
                echo &quot; &quot;
                echo &quot;Provisions servers via Ansible. Must be run from project root&quot;
                echo &quot; &quot;
                echo &quot;options:&quot;
                echo &quot;-h, --help        show help&quot;
                echo &quot;-s|--staging      provision staging servers&quot;
                echo &quot;-p|--production   provision production servers&quot;
                exit 0
                ;;
            -s|--staging)
                shift
                ENVIRONMENT=&quot;staging&quot;
                ;;
            -p|--production)
                shift
                ENVIRONMENT=&quot;production&quot;
                ;;
            *)
                break
                ;;
        esac
    done

ansible-playbook ansible/site.yml -l $ENVIRONMENT -i ansible/hosts --ask-sudo-pass

</code></pre>
<p><code>#!/usr/bin/env bash</code> is more flexible than <code>#!/bin/bash/</code>. This means no flags on the first line and have to use, <code>set -x</code> for flags.</p>
<p>Use <code>while</code> and <code>shift</code> to grab the flags from the comand. Use <code>-h</code> to echo help and stop.</p>
<p>Can alias it once done, e.g. alias <code>provision=./home/user/provision</code> or <code>ln -s</code> it to somewhere <code>$PATH</code> looks... example: <code>ln -s /home/user/provision /usr/bin/local/provision</code>.</p>
<p>Example of, &quot;if then else&quot;:</p>
<pre><code class="language-shell">if [ -n &quot;$MYSQL_DB&quot; ]; then echo &quot;custom mysql db set to $MYSQL_DB&quot;; else MYSQL_DB=$THE_THEME; fi
</code></pre>
<p><a href="https://gist.github.com/pajtai/de2315fafde61e82ac17">Other similar example</a></p>
<p>Useful flags: </p>
<ul>
<li><code>-e</code> stops on first error. </li>
<li><code>-x</code> expands all commands (great for debugging). </li>
<li><code>-u</code> can't refer to uninitialized variables.</li>
</ul>
<h1><a class="header" href="#common-shell-commands" id="common-shell-commands">Common Shell Commands</a></h1>
<p>tags: linux, commands</p>
<h2><a class="header" href="#check-if-command-exists-from-script" id="check-if-command-exists-from-script">Check if command exists from script</a></h2>
<pre><code>command -v foo &gt;/dev/null 2&gt;&amp;1
</code></pre>
<p>http://stackoverflow.com/a/677212/186636</p>
<h2><a class="header" href="#curl" id="curl"><code>curl</code></a></h2>
<p>To display prettified JSON:</p>
<pre><code>curl http://something.blah.yad | python -m json.tool
</code></pre>
<h2><a class="header" href="#disk-usage" id="disk-usage">Disk usage</a></h2>
<pre><code># disk usage, human readable
du -chs /*
# disk usage, summary per directory
du -sh

# disk usage, filter by file size
find . -size +10k -exec ls -lh {} \+

# free space
df -h

free -h

# directories that use a gig or over
du -h / | grep '[0-9\.]\+G'
</code></pre>
<h2><a class="header" href="#files" id="files">files</a></h2>
<p>Delete all files older than 90 days in a directory:</p>
<pre><code>find ~/backups -type f -mtime +90 -delete
</code></pre>
<h2><a class="header" href="#dpkg" id="dpkg"><code>dpkg</code></a></h2>
<p>List where apt-get installed something</p>
<pre><code>dpkg -L nginx
</code></pre>
<h2><a class="header" href="#last-reboot" id="last-reboot">Last reboot</a></h2>
<pre><code>who –b
</code></pre>
<h2><a class="header" href="#links" id="links">Links</a></h2>
<p>Creating a symbolic link:</p>
<pre><code>ln -s from to
</code></pre>
<h2><a class="header" href="#means" id="means">Means</a></h2>
<p>To calculate the mean of a column of numbers in a file:</p>
<pre><code class="language-shell">awk '{ total += $1; count++ } END { print total/count }' nocache.log
</code></pre>
<p>Awk is a program for dealing with files with columns. <code>$1</code> means the first column.
The command <code>total += $1; count++</code> runs for each row.</p>
<h2><a class="header" href="#open" id="open"><code>open</code></a></h2>
<ul>
<li>Open a url with the default browser:</li>
</ul>
<pre><code class="language-shell">open http://localhost:4000
</code></pre>
<p>This command is often useful after running a watch task or something similar. A
background process can be used to solve the problem of using a task that doesn't
exit until you are done with it:</p>
<pre><code>(sleep 3; open http://localhost:4000)&amp;; someSortOfWatchTask
</code></pre>
<p>The <code>&amp;</code> symbol can be used to launch a background task.</p>
<h2><a class="header" href="#ports" id="ports">Ports</a></h2>
<p>To get the pid of a process running on a port, use <code>lsof</code> (list open files):</p>
<p>This will get the pid the process(es) running on port 4000.</p>
<pre><code>lsof -t -i:4000
</code></pre>
<p>To kill them:</p>
<pre><code>kill $(lsof -t -i:4000)
</code></pre>
<h2><a class="header" href="#scp" id="scp"><code>scp</code></a></h2>
<p>Scp is for copying content over ssh.</p>
<p>You can use your ssh aliases when defining the to and from locations:</p>
<pre><code>scp -r exampleStaging:/some/directory ~
</code></pre>
<h2><a class="header" href="#ssh" id="ssh"><code>ssh</code></a></h2>
<p>Open an SSH tunnel to example.com port 22 and use your local port 27018 to
map to example.com's 27017.</p>
<p>Something like this is useful for interacting with a locally bound process (e.g.
mongo, mysql, elasticsearch...).</p>
<pre><code class="language-shell">ssh -L27018:localhost:27017 user@example.com -p 22
</code></pre>
<p>You can get more complicate, for example if you want Object Rocket to think you are example.com from your machine:</p>
<pre><code class="language-shell">ssh -L38945:something.objectrocket.com:38945 user@example.com
</code></pre>
<p>Now you can use your port 38945 as if you were on example.com... allowing cli mongo login as well as Robomongo, etc access.</p>
<p>You can use the -N flag for non interactive tunneling.</p>
<p>You can also store your connections in a sock file for easy closing later:</p>
<pre><code class="language-shell"># open and background manually ---- not with -f flag
(ssh -N -L 9200:localhost:9200   -M -S /tmp/ssh_tunnel_9200_%h.sock $SSH_HOST_E)&amp;

# some point later close
ssh -S /tmp/ssh_tunnel_9200_%h.sock  -O exit $SSH_HOST
</code></pre>
<h2><a class="header" href="#sftp" id="sftp"><code>sftp</code></a></h2>
<pre><code class="language-sh">sftp -oPort=&lt;port&gt; &lt;user&gt;@&lt;host&gt;
# Enter password if prompted.

# E.g. upload wordpress theme directory
# Switch to themes directory on remote.
sftp&gt; cd wp-content/themes
# Run put command with recursive flag to upload your local theme directory
# to the current remote directory.
sftp&gt; put -r local/path/to/wp-content/themes/my-theme
</code></pre>
<h2><a class="header" href="#tar" id="tar"><code>tar</code></a></h2>
<p>There are two very common combination of flags in conjunction with the <code>tar</code> command:</p>
<pre><code># extract files with verbose output
tar -xvf some.file.tar.gz

# compress files with verbose output
tar -zcvf some.file.to.create.tar.gz directory-to-compress
</code></pre>
<p>If you want to delete the files as they get compressed, use the <code>--remove-files</code> flag.
This has to be the first flag used, or <code>tar</code> will think it's a file.</p>
<pre><code>tar --remove-files a.tar.gz b
</code></pre>
<p>The <code>--remove-files</code> flag is not supported by the <code>tar</code> command that ships with
Mac, but gnu tar does:</p>
<pre><code>brew instasll gnu-tar
</code></pre>
<h2><a class="header" href="#number-of-cores" id="number-of-cores">Number of cores</a></h2>
<pre><code>cat /proc/cpuinfo | awk '/^processor/{print $3}' | wc -l
</code></pre>
<h2><a class="header" href="#chmod-change-permissions" id="chmod-change-permissions"><code>chmod</code> (Change permissions)</a></h2>
<p>Change permission on a file:</p>
<pre><code>chmod 0755 &lt;file&gt;
</code></pre>
<ul>
<li>positions: user, group, everyone</li>
<li>read: 4</li>
<li>write: 2</li>
<li>execute: 1</li>
</ul>
<h2><a class="header" href="#cat" id="cat"><code>cat</code></a></h2>
<p>Send file contents to stdout:</p>
<pre><code>cat &lt;file&gt;
</code></pre>
<h2><a class="header" href="#grep" id="grep"><code>grep</code></a></h2>
<p>Filter text that matches a regular expression pattern:</p>
<pre><code>cat &lt;file&gt; | grep &lt;pattern&gt;

## -C for context of surrounding `n` lines
cat &lt;file&gt; | grep -C n &lt;pattern&gt;
</code></pre>
<h2><a class="header" href="#tail" id="tail"><code>tail</code></a></h2>
<p>See contents added to end of file in realtime:</p>
<pre><code>tail -f &lt;file&gt;

## with grep, filter new lines that match
tail -f &lt;file&gt; | grep --line-buffered &lt;pattern&gt;
</code></pre>
<h2><a class="header" href="#sed" id="sed"><code>sed</code></a></h2>
<p>Search and replace text</p>
<pre><code># read from in and write to out
sed 's/search_regex/replacement_string/g' &lt; file_in &gt; file_out

# convert to https in a mysql dump
sed 's/http:\/\/www\.example\.com\//https:\/\/www.example.com\//g' &lt; example.sql &gt; example.sql
</code></pre>
<h2><a class="header" href="#date" id="date"><code>date</code></a></h2>
<p>Get current timestamp on server</p>
<pre><code>date
</code></pre>
<h2><a class="header" href="#rsync" id="rsync"><code>rsync</code></a></h2>
<p>Sync directories. Useful over ssh.</p>
<p>If you want to get the content of two dirs to match, put a <code>/</code> after each one:</p>
<pre><code>rsync -rztP ~/dir/uploads/ staging-wordpress:/var/www/vhosts/vhost.com/source/httpdocs/wp-content/uploads/
</code></pre>
<p>The <code>t</code> tag is useful, since that preserves the timestamps, so that syncing is smart.</p>
<p>If using ec2 (or any other network), within network rsyncs are much faster than transferring out and back into a network. For example ec2 to your computer back up to ec2 can be multiple times slower than ec2 to ec2. Using forward agent is a good way to do ec2 to ec2.</p>
<h2><a class="header" href="#findmnt" id="findmnt"><code>findmnt</code></a></h2>
<h2><a class="header" href="#dns" id="dns">dns</a></h2>
<p>To check TTL you have to query an authorative server for the zone, or you just get the time remaining.</p>
<p>First get the name servers:</p>
<pre><code class="language-bash">dig @8.8.8.8 +short NS example.com
</code></pre>
<p>Then get ttl from one of the name servers:</p>
<pre><code class="language-bash">dig +nocmd +noall +answer @ns1.nameserverexample.com example.com
</code></pre>
<h2><a class="header" href="#check-emails-with-status-sent" id="check-emails-with-status-sent">Check emails with status sent</a></h2>
<pre><code class="language-bash"># can often be simplified to just grep status
cat /var/log/mail.log |grep -v &quot;relay=local&quot; |grep &quot;relay=&quot; |grep &quot;status=sent&quot;
</code></pre>
<h1><a class="header" href="#reboots" id="reboots">Reboots</a></h1>
<p>tags: linux, restart</p>
<p><code>/etc/rc.local</code> gets read on a reboot. If you make it executable, then it's a good place to put things that you want to run after the server reboots. </p>
<h1><a class="header" href="#sftp-1" id="sftp-1">SFTP</a></h1>
<p>tags: linux, sftp</p>
<p>SFTP is FTP over SSH. It can be setup with either keypairs or passwords.</p>
<p>A simple way to manage SFTP users is to put them all in one group and match on that group for SFTP access.</p>
<p>Here are the steps to create a sample SFTP user with password access.</p>
<p>First the parent directory of the user's sftp directory must be owned by <code>root:root</code> and have <code>755</code> permissions. Because of this restriction, you might have to symlink the sftp directory to where you want it to ultimately show up.</p>
<pre><code class="language-bash"># create a root directory
sudo mkdir /var/sftp
</code></pre>
<p>Then create your sftp user. This user should have a home directory nested in the root sft directory. In this case we're going to add them to the <code>www-data</code> group, to give them access to a Wordpress uploads directory.</p>
<pre><code class="language-bash"># create a user with their home directory in the root directory
sudo useradd -d /var/sftp/uploads -G www-data ftpuser --shell /usr/sbin/nologin
</code></pre>
<p>Now add a password to the user:</p>
<pre><code class="language-bash">echo -e &quot;my_secure_password\nmy_secure_password&quot; | sudo passwd ftpuser
</code></pre>
<p>Verify the information:</p>
<pre><code class="language-bash">grep ftpuser /etc/passwd
grep www-data /etc/group
</code></pre>
<p>Add any symlinks needed:</p>
<pre><code class="language-bash">sudo ln -s /var/sftp/uploads /var/www/vhosts/www.example.com/wp-content/uploads
</code></pre>
<p>We will next modify the SSH config to allow SFTP access for this user:</p>
<pre><code class="language-bash">sudo vim /etc/ssh/sshd_config
</code></pre>
<p>First comment out the following line:</p>
<pre><code>Subsystem sftp /usr/lib/openssh/sftp-server
</code></pre>
<p>Add the following to the end of the file</p>
<pre><code class="language-bash">#Subsystem sftp /usr/lib/openssh/sftp-server
Subsystem www-data internal-sftp # Use in-process SFTP server
Match Group sftp
  ChrootDirectory %h                 # Prevent user access to anything beyond their home folder
  #ChrootDirectory /var/sftp/uploads # can also hard code a directory for ChrootDirectory   
  X11Forwarding no               # Disable X11 forwarding
  AllowTcpForwarding no          # Disable tunneling
  AllowAgentForwarding no        # Disable port forwarding
  PermitTunnel no                # Disable network tunneling
  ForceCommand internal-sftp 
</code></pre>
<p>Before restarting SSH test the config file:</p>
<pre><code class="language-bash">sshd -t
</code></pre>
<p>If you do not do this, you risk getting locked out of your server!</p>
<p>If everything looks good restart SSH and test your SFTP access:</p>
<pre><code class="language-bash">sudo service ssh restart
</code></pre>
<h2><a class="header" href="#debugging-2" id="debugging-2">Debugging</a></h2>
<p>If you are having trouble connecting, then tail the auth log. You will usually see the cause of the error:</p>
<pre><code class="language-bash">tail -f /var/log/auth.log
</code></pre>
<h2><a class="header" href="#references-2" id="references-2">References</a></h2>
<ul>
<li><a href="http://www.inanzzz.com/index.php/post/ef2z/setting-up-a-sftp-server-and-users-on-ubuntu-16-04">Setting up an SFTP server and users on Ubuntu 16.04</a></li>
</ul>
<h1><a class="header" href="#ufw" id="ufw">UFW</a></h1>
<p>tags: ufw, firewall</p>
<p>Make sure you don't get locked out!</p>
<pre><code class="language-bash"># list added rules even if disabled 
sudo ufw add ssh
sudo ufw add 443
sudo ufw add 80
sudo ufw show added
</code></pre>
<p>Enable it</p>
<pre><code>sudo ufw enable
</code></pre>
<p>or disable it</p>
<pre><code>sudo ufw disable
</code></pre>
<h1><a class="header" href="#media-streaming-in-html5" id="media-streaming-in-html5">Media streaming in HTML5</a></h1>
<p>tags: html5, video, dash, hls, smooth-streaming, drm, clear-key, playready, widevine, fairplay, eme, mse</p>
<h2><a class="header" href="#html-spec-extensions" id="html-spec-extensions">HTML spec extensions</a></h2>
<p>Previously, html was not capable of playing encrypted or adaptive media streams. People like Netflix desired this functionality so they proposed and standardized extensions to the HTML spec to make it possible. Everybody wins. The extensions are:</p>
<ul>
<li>Media source extension (MSE) - adaptive streaming support</li>
<li>Encrypted module extension (EME) - drm support</li>
</ul>
<p>At a high level, these extensions add javascript apis to the browser and <code>HTMLMediaElement</code> which enable applications to decrypt protected content and feed video chunks to the <code>video</code> element as needed. These were first rolled out in a vendor-prefixed, pre-1.0 version that was specific to each vendor implementation, but the 1.0 release normalized the API across browers.</p>
<h3><a class="header" href="#eme" id="eme">EME</a></h3>
<ul>
<li><a href="https://developers.google.com/web/fundamentals/media/eme">Google Web Fundamentals overview</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/mt598601.aspx">Edge vs IE support</a></li>
<li><a href="https://docs.microsoft.com/en-us/microsoft-edge/dev-guide/multimedia/encrypted-media-extensions">Edge guide</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API">MDN</a></li>
<li><a href="https://docs.microsoft.com/en-us/windows/uwp/audio-video-camera/playready-encrypted-media-extension">UWP Playready</a></li>
</ul>
<h2><a class="header" href="#adaptive-streaming" id="adaptive-streaming">Adaptive streaming</a></h2>
<p>Adaptive streams adjust to the network conditions; lo-fi on 3g, hi-fi on broadband. This is possible by providing many media tracks of varying qualities that are then played at the appropriate time. These tracks are listed in a &quot;manifest&quot; that describes the overall stream. There are several manifest formats, but they all serve this same purpose:</p>
<table><thead><tr><th>Name</th><th>Champion</th><th><code>.ext</code></th><th>content type</th></tr></thead><tbody>
<tr><td>DASH (Dynamic adaptive streaming over HTTP)</td><td>open standard</td><td><code>.mpd</code></td><td><code>application/dash+xml</code></td></tr>
<tr><td>HLS (HTTP live streaming)</td><td>Apple</td><td><code>.m3u8</code></td><td><code>application/mpegurl</code></td></tr>
<tr><td>Smooth streaming</td><td>Microsoft</td><td>none</td><td><code>application/vnd.ms-sstr+xml</code></td></tr>
</tbody></table>
<p>Based on the current bandwidth, the browser can determine the most appropriate track to play from the manifest, and MSE exposes a js api that makes it possible for an applicaiton to actually change a playing video to that track.</p>
<h3><a class="header" href="#dash" id="dash">DASH</a></h3>
<ul>
<li><a href="http://dashif.org/conformance.html"><code>.mpd</code> manifest validator</a></li>
</ul>
<h2><a class="header" href="#drm-types" id="drm-types">DRM types</a></h2>
<p>The adaptive stream manifest file also specifies how/if the content is protected by drm. Each browser uses a different drm system. A manifest can specify multiple drm types, and the client application can use the one its client supports. An open format like DASH will support most drm systems, while a proprietary format, like Smooth streaming, will likely only support playready.</p>
<p>Name | Champion | Browser
--- | --- | --- | ---
Clear Key | open standard specified in the EME spec | All EME compliant browsers
Widevine | Google | Chrome
Playready | Microsoft | Edge, IE
Fairplay | Apple | Safari</p>
<h3><a class="header" href="#playready" id="playready">Playready</a></h3>
<ul>
<li><a href="http://test.playready.microsoft.com/Content/Content4X">Test license server and assets</a></li>
<li><a href="https://developer.microsoft.com/en-us/microsoft-edge/platform/issues/14593018/">Edge 16 bug</a></li>
<li><a href="https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/PlayReady">Client code samples</a></li>
</ul>
<p>Note: Edge 16 in browserstack and virtual machine report support for unprefixed software drm on playready's <a href="http://test.playready.microsoft.com/Tool/Hwdrm">tool</a></p>
<h2><a class="header" href="#html5-javascript-player-libraries" id="html5-javascript-player-libraries">HTML5 javascript player libraries</a></h2>
<table><thead><tr><th>Name</th><th>Price</th><th>Open source</th></tr></thead><tbody>
<tr><td><a href="https://bitmovin.com/video-player/">Bitmovin</a></td><td>LICENSED</td><td>No</td></tr>
<tr><td><a href="https://developer.jwplayer.com/">JW Player (full)</a></td><td>LICENSED</td><td>No</td></tr>
<tr><td><a href="http://amp.azure.net/libs/amp/latest/docs/index.html">Azure Media Player</a></td><td>LICENCED</td><td>No</td></tr>
<tr><td><a href="http://viblast.com/player/">Viblast</a></td><td>Free</td><td>No</td></tr>
<tr><td><a href="https://github.com/jwplayer/jwplayer">JW Player (limited) </a></td><td>Free</td><td>Yes</td></tr>
<tr><td><a href="https://github.com/google/shaka-player">Google Shaka Player</a></td><td>Free</td><td>Yes</td></tr>
<tr><td><a href="https://github.com/Orange-OpenSource/hasplayer.js">hasplayer.js</a></td><td>Free</td><td>Yes</td></tr>
<tr><td><a href="https://github.com/Dash-Industry-Forum/dash.js">dash.js</a></td><td>Free</td><td>Yes</td></tr>
<tr><td><a href="https://github.com/video-dev/hls.js/">hls.js</a></td><td>Free</td><td>Yes</td></tr>
<tr><td><a href="https://github.com/videojs/video.js">video.js</a></td><td>Free</td><td>Yes</td></tr>
</tbody></table>
<h2><a class="header" href="#live-demo-players" id="live-demo-players">Live demo players</a></h2>
<ul>
<li><a href="https://test.playready.microsoft.com/Tool/PlayerHAS">Playready</a></li>
<li><a href="https://developer.microsoft.com/en-us/microsoft-edge/testdrive/demos/eme/">Edge</a></li>
<li><a href="https://ampdemo.azureedge.net/azuremediaplayer.html">Azure</a></li>
<li><a href="https://bitmovin.com/mpeg-dash-hls-drm-test-player/">Bitmovin</a></li>
<li><a href="http://reference.dashif.org/dash.js/nightly/samples/dash-if-reference-player/index.html">dashif.org</a></li>
<li><a href="https://shaka-player-demo.appspot.com/">shaka</a></li>
<li><a href="http://yt-dash-mse-test.commondatastorage.googleapis.com/demo-player/dash-player-2018.html">Youtube</a></li>
</ul>
<p>Note: All Playready samples, except Bitmovin, worked in Edge 16. Azure and Bitmovin Widevine samples worked in Chrome.</p>
<h1><a class="header" href="#cordova" id="cordova">Cordova</a></h1>
<p>tags: cordova, mobile, ios, android, webview, js, javascript</p>
<h2><a class="header" href="#project" id="project">Project</a></h2>
<h2><a class="header" href="#plugins" id="plugins">Plugins</a></h2>
<p>To add a plugin:</p>
<pre><code># Save plugin to plugins list in package.json
cordova plugin add &lt;plugin-name&gt; # might need `--save`

# Remove plugins and platforms to install new plugin.
rm -rf plugins platforms

# Install new plugin with prepare.
cordova prepare # Rebuilds plugins and platforms dirs with new plugin.
</code></pre>
<h1><a class="header" href="#react-native" id="react-native">React native</a></h1>
<p>tags: react-native, react, native, mobile, ios, android, js, javascript</p>
<h2><a class="header" href="#react-native-libraries" id="react-native-libraries">React native libraries</a></h2>
<ul>
<li>See helpful libraries with examples <a href="mobile/react-native//mobile/react-native/libraries">here</a>.</li>
</ul>
<h2><a class="header" href="#images" id="images">Images</a></h2>
<ul>
<li>Example:
<pre><code class="language-jsx">  import { Image } from &quot;react-native&quot;
  &lt;Image source={require(&quot;./my-image.png&quot;)}/&gt;
</code></pre>
</li>
<li>Include base, 2x, and 3x sizes for devices with different screen densities. See full example here: https://reactnative.dev/docs/images</li>
<li><code>Image</code> supports png, jpg since that's what the native platforms support. svg support is possible via react native plugins, though prefer png, jpg.</li>
</ul>
<h2><a class="header" href="#debug" id="debug">Debug</a></h2>
<ul>
<li>On the simulator, press <code>command + D</code>, then click Debug. This will open debugger in chrome devtools and you can look at console logs.</li>
</ul>
<h2><a class="header" href="#running-on-device" id="running-on-device">Running on device</a></h2>
<p>iOS</p>
<ul>
<li>Be sure your apple id is added as a developer to the apple developer team that manages the bundle id, and ensure you are given permission for certificates, so that you can create a development certificate. (Developers can't downlaod or manage the distribution certs, so you don't need to worry about access.)</li>
<li>XCode &gt; Preferences &gt; Account &gt; Add your apple id. Once added, your personal team and the development team you were added to should be listed.</li>
<li>Select the development team, and select manage certificates..., then click the + in the bottom left, and select Apple development. This will add an apple development certificate to the development team.</li>
<li>Then when signing builds, select automatically manage signing, and select the development team (not personal), and it should automatically select your new development cert, and create a provisioning profile.</li>
<li>Plug in your device with usb.</li>
<li>Select your device in the device selector in Xcode.</li>
<li>Press Play button to build and run on device.</li>
</ul>
<p>Android</p>
<ul>
<li>Much easier than ios. Basically enable usb debugging on device, plugin with usb and run <code>react-native android</code>.</li>
<li>Full steps are clear here: https://reactnative.dev/docs/running-on-device</li>
<li>If device doesn't show up with <code>adb devices</code>, unplug usb and reconnect.</li>
</ul>
<h2><a class="header" href="#assets" id="assets">Assets</a></h2>
<ul>
<li>Add path to assets folder to <code>react-native.config.js</code>, e.g.
<pre><code>  module.exports = {
      assets: [&quot;./app/assets/fonts/&quot;]
  }

</code></pre>
</li>
<li>Run <code>react-native link</code> (NOTE: react-native@0.60 or greater automatically links native dependencies, so you don't have to run <code>react-native link &lt;my-dep&gt;</code>, but asset linking is different, and you have to do it even on &gt;0.60)</li>
</ul>
<h2><a class="header" href="#fonts" id="fonts">Fonts</a></h2>
<ul>
<li>Use a separate <code>fontFamily</code> for each weight needed, e.g. <code>fontFamily: &quot;OpenSans-Bold&quot;</code>, not <code>fontFamily: &quot;OpenSans&quot;, fontWeight: &quot;bold&quot;</code>. The platforms handle it differently, so the first method works consistently on both ios and android.</li>
<li>On ios, the fontFamily should match the postscript name of the font. To check this, open the file in Font Book mac app, and select View &gt; Show font info.</li>
<li>On android, the fontFamily should match the file name. Ideally, this will match the postscript name, so that the same string can be used on ios and android.</li>
</ul>
<h2><a class="header" href="#react-native-developer-resources" id="react-native-developer-resources">React Native Developer Resources</a></h2>
<ul>
<li>https://www.reactnative.guide/</li>
</ul>
<h2><a class="header" href="#troubleshooting" id="troubleshooting">Troubleshooting</a></h2>
<p>Android app crashes after dev build and launch (&quot;App keeps stopping&quot;)</p>
<ul>
<li>Check crash log with <code>adb logcat</code>.</li>
<li>It usually helps to blow away the build dir and start clean: <code>rm -rf android/app/build</code>.</li>
</ul>
<p>Android build error: <code>Requested internal only, but not enough space</code></p>
<ul>
<li>Close emulator.</li>
<li>Open android studio &gt; Configure &gt; AVD Manager &gt; (Virtual device dropdown on right) &gt; Wipe data.</li>
</ul>
<p>iOS build error: <code>multiple commands produced &lt;file&gt;</code>
This probably happened because you added files to xcode project manually, but react native &gt;= v0.60 auto links files, resulting in duplicate files.</p>
<ul>
<li>Open project in Xcode.</li>
<li>Select project in the project navigator left sidebar.</li>
<li>Find the files you added manually and delete them.</li>
<li>If needed, select Build Phases tab &gt; Copy Bundle Resources, and delete files there too.</li>
</ul>
<h2><a class="header" href="#versioning" id="versioning">Versioning</a></h2>
<p>iOS</p>
<ul>
<li>Update properties in <code>ios/{project}/Info.plist</code>
<ul>
<li>CFBundleShortVersionString: string, e.g. &quot;1.2&quot;</li>
<li>CFBundleVersion: integer, incremented for each release, e.g. 12</li>
</ul>
</li>
</ul>
<p>Android</p>
<ul>
<li>Update properties in <code>android/app/build.gradle</code>
<ul>
<li>versionName: string, e.g. &quot;1.2&quot;</li>
<li>versionCode: integer, incremented for each release, e.g. 12</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#release" id="release">Release</a></h2>
<p>iOS</p>
<ul>
<li>Use an ios distribution certificate.</li>
<li>Be sure the devices that will install the app are included in the provisioning profile.</li>
<li>TODO: document release build via Xcode. All i've done currently is app center.</li>
</ul>
<p>Android</p>
<ul>
<li>Follow steps here to create release signing key: https://reactnative.dev/docs/signed-apk-android.html</li>
<li>TODO: document release build via Mac. All i've done currently is app center.</li>
</ul>
<h1><a class="header" href="#react-native-libraries-1" id="react-native-libraries-1">React native libraries</a></h1>
<p>tags: react-native, react, native, mobile, ios, android, js, javascript</p>
<h2><a class="header" href="#react-native-community" id="react-native-community">React native community</a></h2>
<ul>
<li>Many of the react native core components have been extracted into individual repos hosted in the react native community group.</li>
<li>Use the community component instead of the core component, unless otherwise specified.</li>
<li>See list here for repos and activity state: https://github.com/react-native-community/.github/blob/master/MAINTAINERS.md</li>
</ul>
<h2><a class="header" href="#icons" id="icons">Icons</a></h2>
<ul>
<li>use <code>react-native-vector-icons</code>.</li>
<li>Use the built-in icon sets, e.g. Material, FontAwesome:
<pre><code class="language-jsx">import Icon from &quot;react-native-vector-icons/MaterialIcons&quot;
&lt;Icon name=&quot;done&quot; size={24} color=&quot;green&quot; /&gt;
</code></pre>
</li>
<li>Use custom icon sets from svg via icon tools like icomoon.io:
<pre><code class="language-jsx">import { createIconSetFromIcoMoon } from 'react-native-vector-icons'
import icoMoonConfig from './selection.json' // Downloaded from icomoon.io after uploading svgs.

const IconCustom = createIconSetFromIcoMoon(
  icoMoonConfig,
  'bliss',
  'bliss.ttf' // Downloaded from icomoon.io after uploading svgs, placed in assets folder.
)

&lt;IconCustom name=&quot;shield&quot; size={24} color=&quot;green&quot;/&gt;
</code></pre>
</li>
</ul>
<h2><a class="header" href="#navigation" id="navigation">Navigation</a></h2>
<ul>
<li>For common navigation patterns, e.g. top-level tabs, forward/back within series of screens, use <code>react-navigation</code>.</li>
<li>Follow the installation intructions to install extra deps, and initialize lib: https://reactnavigation.org/docs/getting-started#installation</li>
<li>Navigation container required to wrap your entire app:
<pre><code class="language-jsx">import { NavigationContainer } from '@react-navigation/native';
&lt;NavigationContainer&gt;{/* Rest of your app code */}&lt;/NavigationContainer&gt;
</code></pre>
</li>
<li>Tab navigator, to add bottom tab navigation, which is used to change between top level sections of the app:
<pre><code class="language-jsx">import { createBottomTabNavigator } from &quot;@react-navigation/bottom-tabs&quot;
const Tab = createBottomTabNavigator()
&lt;Tab.Navigator&gt;
  &lt;Tab.Screen name=&quot;home&quot; component={Home} /&gt; // Home is a user-defined react component.
  &lt;Tab.Screen name=&quot;account&quot; component={Account} /&gt; // Account is a user-defined react component.
&lt;/Tab.Navigator&gt;
</code></pre>
</li>
<li>Stack navigator, to navigate forward/back within series of screens.
<pre><code class="language-jsx">import { createStackNavigator } from &quot;@react-navigation/stack&quot;
const Stack = createStackNavigator()
const HomeStack = (
  &lt;Stack.Navigator&gt;
    &lt;Stack.Screen name=&quot;home&quot; component={Home}/&gt; // Home is a user-defined react component.
    &lt;Stack.Screen name=&quot;detail&quot; component={Detail}/&gt; // Detail is a user-defined react component.
  &lt;/Stack.Navigator&gt;
)
</code></pre>
</li>
<li>Nested navigators, e.g. use stack navigator inside tab navigator:
<pre><code class="language-jsx">&lt;Tab.Navigator&gt;
  &lt;Tab.Screen name=&quot;home&quot; component={HomeStack} /&gt; // HomeStack defined above.
  &lt;Tab.Screen name=&quot;account&quot; component={Account} /&gt; // Account is a user-defined react component.
&lt;/Tab.Navigator&gt;
</code></pre>
</li>
<li>All components passed as <code>component</code> to <code>Stack.Screen</code> receive <code>navigation</code> as a prop, so then you can navigate with <code>props.navigation.navigate(/* Screen name. */ &quot;detail&quot;)</code>.</li>
<li><code>react-navigation</code> also powers the header, with back button to return to previous screen in stack, title, and other actions. Header can be customized or removed if needed.</li>
</ul>
<h1><a class="header" href="#setting-up-xdebug-with-vagrant" id="setting-up-xdebug-with-vagrant">Setting up xdebug with Vagrant</a></h1>
<p>tags: php, debugging</p>
<h2><a class="header" href="#installing-xdebug" id="installing-xdebug">Installing xdebug</a></h2>
<p>Assuming you don't have xdebug in your environment, first output phpinfo</p>
<pre><code class="language-php">&lt;?php
phpinfo();
</code></pre>
<p>Now take that output, paste it into https://xdebug.org/wizard.php, and follow the instructions.</p>
<p>These php.ini settings (in addition to pointing to the so) worked for me:</p>
<pre><code>[XDebug]
xdebug.remote_enable = 1
xdebug.remote_autostart = 1
xdebug.remote_connect_back = 1
</code></pre>
<p>Look for you IDE key in <code>phpinfo()</code> if you need it.</p>
<hr />
<h2><a class="header" href="#phpstorm-setup" id="phpstorm-setup">PhpStorm Setup</a></h2>
<p>From the file menu: <code>Run &gt; Edit Configurations...</code>.</p>
<p>Add one to <code>PHP Remote Debug</code>: ide key = <code>xdebug</code> - the value from php.ini.</p>
<p>Under settings (<code>Cmd-,</code>) type, &quot;server&quot; and make sure that the Debug port is
<code>9000</code> - the value from php.ini. Also, the <code>Can accept external connections</code> must
be checked (<code>Languages &amp; Frameworks &gt; PHP &gt; Debug</code>)</p>
<p>Finally under <code>Languages &amp; Frameworks &gt; PHP &gt; Servers</code>, set the Host to <code>192.168.12.138</code>, port <code>9000</code>,
debugger <code>xdebug</code>.</p>
<p>You also have to check <code>use path mappings</code>. Here you have to have your local project directory
on the left and the corresponding vagrant directory on the right. e.g <code>~/git/project</code> and <code>/vagrant</code>.</p>
<p>At this point clicking <code>run debugger</code> should work after clicking on a breakpoint
in PhpStorm.</p>
<h2><a class="header" href="#vs-code-setup" id="vs-code-setup">VS Code Setup</a></h2>
<ul>
<li>Open a project</li>
<li>Click the bug icon in the left nav</li>
<li>In the dropdown above (near the green arrow), click 'Add Configuration'</li>
<li>Select PHP</li>
</ul>
<p>This will create a <code>.vscode/launch.json</code> in your project root. It should look like this:</p>
<pre><code>
{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    &quot;version&quot;: &quot;0.2.0&quot;,
    &quot;configurations&quot;: [

        {
            &quot;name&quot;: &quot;Listen for XDebug&quot;,
            &quot;type&quot;: &quot;php&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;port&quot;: 9000,
            &quot;pathMappings&quot;: {
                &quot;/vagrant&quot;: &quot;${workspaceRoot}&quot;
            }
        },
    ]
}
</code></pre>
<ul>
<li>Save it and click the green play button.</li>
<li>In the 'breakpoints' section on the left, uncheck the 'everything' box</li>
<li>Then set a breakpoint by clicking in the line numbers on the left when editing a file.</li>
<li>Reload the page and you should see the debugger automatically kick in</li>
</ul>
<h2><a class="header" href="#request-timeout" id="request-timeout">Request Timeout</a></h2>
<p>The default fastcgi timeout is 1 minute, so to avoid getting 504 errors (which
are generally not harmful to debugging), you can add the
following to your nginx config</p>
<pre><code>fastcgi_read_timeout 1d;
</code></pre>
<p>This is a timeout of one day - hopefully long enoug for your debugging session ;)</p>
<h2><a class="header" href="#older-php" id="older-php">Older PHP</a></h2>
<p>The wizard above only work on php 7 and above. For older versions:</p>
<pre><code>sudo apt-get install php-xdebug`
</code></pre>
<p>add the following to your loaded php.ini as retrieved from <code>phpinfo()</code>:</p>
<pre><code>[XDebug]
xdebug.remote_enable = 1
xdebug.remote_autostart = 1
xdebug.remote_connect_back = 1
</code></pre>
<p>Now restart php: <code>sudo service php5.6-fpm restart</code></p>
<p>If you need to restart send a signal: <code>sudo nginx -s reload</code>. Sending a signal will do nothing if there's a syntax error in your cofigs. Restarting the service will first stop the service and then fail to restart if there's an error.</p>
<h2><a class="header" href="#debugging-on-a-remote-server" id="debugging-on-a-remote-server">Debugging on a Remote Server</a></h2>
<p>Basically you use the instructions above and open an SSH tunnel:</p>
<pre><code>ssh -f my-server -L 9000:127.0.0.1:9000 -N
</code></pre>
<p>The above will put the tunnel into the background. To kill it:</p>
<pre><code>kill -9 $(lsof -t -i:9000)
</code></pre>
<p>https://confluence.jetbrains.com/display/PhpStorm/Remote+debugging+in+PhpStorm+via+SSH+tunnel</p>
<h2><a class="header" href="#references-3" id="references-3">References</a></h2>
<p>http://walkah.net/blog/debugging-php-with-vagrant/</p>
<h1><a class="header" href="#eloquent" id="eloquent">Eloquent</a></h1>
<p>tags: mysql, db, orm</p>
<h2><a class="header" href="#aliasing" id="aliasing">Aliasing</a></h2>
<p>Aliasing the models table name, a column name, and only pulling in certain columns:</p>
<pre><code class="language-php">ClassActivityModel::from('class_activity as ca')
    -&gt;join('wp_posts', 'activity_post_id', '=', 'wp_posts.ID')
    -&gt;where('class_id', $class_id)
    -&gt;select('ca.*', 'wp_posts.post_title as description')
    -&gt;get();
</code></pre>
<h2><a class="header" href="#joins" id="joins">Joins</a></h2>
<p>A join without using the from would be:</p>
<pre><code class="language-php">Model::join(...
</code></pre>
<h2><a class="header" href="#group-and-count" id="group-and-count">Group and Count</a></h2>
<pre><code class="language-php">$user_info = DB::table('usermetas')
                 -&gt;selectRaw('browser, count(*) as total')
                 -&gt;groupBy('browser')
                 -&gt;get();
</code></pre>
<p>Join on multiple columns:</p>
<pre><code class="language-php">-&gt;join('class_trainee as ct', function($join) {
    $join-&gt;on('ct.class_id', '=', 'ca.class_id');
    $join-&gt;on('ct.user_id', '=', 'u.ID');
})
</code></pre>
<h2><a class="header" href="#wherecolumn" id="wherecolumn">whereColumn</a></h2>
<p>If your value is another column, then you must use <code>-&gt;whereColument</code>:</p>
<pre><code class="language-php">$sessionActivity = new SessionActivityModel();
$result = $sessionActivity
    -&gt;select('cta.user_id', 'u.display_name')
    -&gt;from('session_activity as sa')

    -&gt;join('class_activity as ca', 'ca.id', '=', 'sa.class_activity_id')
    -&gt;join('class_trainee_activity as cta', 'ca.activity_post_id', '=', 'cta.activity_post_id')
    -&gt;join('wp_users as u', 'cta.user_id', '=', 'u.ID')

    -&gt;where('sa.session_id', '=', $session_id)
    -&gt;where('sa.class_activity_id', '=', $class_activity_id)
    -&gt;whereColumn('cta.class_id', '=', 'ca.class_id')

    -&gt;get();
</code></pre>
<h2><a class="header" href="#relationships" id="relationships">Relationships</a></h2>
<p>With namespaces it is simplest to not use string references, but to import
classes and use <code>::class</code>. For example:</p>
<pre><code class="language-php">class ClassModel extends ClassBaseModel {
    protected $table = 'wp_hhskills_class';

	public function activities() {
		return $this-&gt;hasMany(ClassActivityModel::class, 'class_id');
	}
}
</code></pre>
<p>Make sure you read the section about eager / lazy loading, since it
affects the number of queries created.</p>
<p>For example if you will be looping through many activities and showing the <code>-&gt;title</code>, lazy loading would create
a query for each, but eager loading would not. Eager load using <code>with</code>:</p>
<pre><code class="language-php">ClassModel::find(5)-&gt;with(
</code></pre>
<h2><a class="header" href="#debugging-3" id="debugging-3">Debugging</a></h2>
<p>Replace <code>-&gt;get()</code> with <code>-&gt;toSql()</code>.</p>
<h2><a class="header" href="#docs" id="docs">Docs</a></h2>
<ul>
<li>https://laravel.com/docs/5.6/queries</li>
</ul>
<h1><a class="header" href="#laravel" id="laravel">Laravel</a></h1>
<p>tags: laravel, php, mysql, mvc</p>
<h2><a class="header" href="#overview" id="overview">Overview</a></h2>
<ul>
<li>At a high level, Laravel is an MVC framework:
<ul>
<li>Models are linked to database tables, and you can read/write to the database via the models.</li>
<li>Views are blade template files.</li>
<li>Controllers handle requests and return a response, e.g. view, redirect, etc.</li>
</ul>
</li>
<li>It also handles routing, migrations, events, and much more.</li>
<li>The docs are good. Use the search feature. https://laravel.com/docs/7.x</li>
</ul>
<h2><a class="header" href="#cli" id="cli">CLI</a></h2>
<ul>
<li>Laravel includes a cli tool <code>artisan</code> which is used extensively to generate files, run migrations, etc.</li>
</ul>
<h2><a class="header" href="#logging" id="logging">Logging</a></h2>
<ul>
<li>Laravel supports many custom options for logging, but by default logs to <code>storage/logs/laravel.log</code>.</li>
<li>Log yourself with static methods on the log facade <code>Illuminate\Support\Facades\Log</code>, e.g. <code>debug</code>, <code>error</code>, etc. https://laravel.com/docs/7.x/logging#writing-log-messages</li>
</ul>
<h2><a class="header" href="#override-vendor-views" id="override-vendor-views">Override vendor views</a></h2>
<ul>
<li>Override vendor views by placing a file with the same path and name in the application's views folder, e.g.
<ul>
<li>vendor file: <code>vendor/&lt;vendor&gt;/&lt;vendor module&gt;/resources/views/products/edit.blade.php</code></li>
<li>override file: <code>resources/views/vendor/&lt;vendor module&gt;/products/edit.blade.php</code></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#events" id="events">Events</a></h2>
<ol>
<li>Add the event to <code>app/Providers/EventServiceProvider.php</code>'s <code>listen</code> array, e.g.
<pre><code class="language-php">use Illuminate\Auth\Events\Login;
use App\Listeners\UpdateLastLogin;

//

protected $listen = [
    Login::class =&gt; [
        UpdateLastLogin::class,
    ],
];
</code></pre>
</li>
<li>Then run <code>php artisan event:generate</code>. This will create the listener class at <code>app/Listeners/UpdateLastLogin.php</code> (and any other listeners not yet defined).</li>
<li>Then add your code to the <code>handle</code> method in the new class.</li>
</ol>
<h2><a class="header" href="#migration" id="migration">Migration</a></h2>
<ol>
<li>Generate migration script with <code>php artisan make:migration &lt;migration_name&gt;</code>. This will generate a migration file at <code>database/migrations/&lt;timestamp&gt;_&lt;migration_name&gt;.php</code>.</li>
<li>Fill in the <code>up</code> and <code>down</code> methods in the new class, e.g.
<pre><code>// up
Schema::table('users', function (Blueprint $table) {
    $table-&gt;timestamp('last_login_at')-&gt;nullable();
});

// down
Schema::table('users', function (Blueprint $table) {
    $table-&gt;dropColumn('last_login_at');
});
</code></pre>
</li>
<li>Run migrations with <code>php artisan migrate</code>. This will run the <code>up</code> methods of all outstanding migrations (it keeps track of which ones it has run in the database).</li>
</ol>
<ul>
<li>Rollback migrations with <code>php artisan migrate:rollback</code>. This will run the <code>down</code> methods.</li>
</ul>
<h2><a class="header" href="#jscss" id="jscss">js/css</a></h2>
<ul>
<li>Front end assets are compiled in <code>webpack.mix.js</code> via a wrapper called <code>laravel-mix</code>. You pretty much just give it the source file and tell it where to put the result:
<pre><code class="language-js">mix.js('resources/js/app.js', 'public/js')
  .sass('resources/sass/app.scss', 'public/css')
  .sass('resources/sass/auth.scss', 'public/css');
</code></pre>
</li>
<li>This setup greatly simplifies webpack. The tradeoff is it reduces customization as well. But it pretty much does what you want with almost no effort.</li>
<li>for dev run: <code>npm run dev</code></li>
<li>for minified run: <code>npm run prod</code></li>
</ul>
<h2><a class="header" href="#models" id="models">Models</a></h2>
<ul>
<li>Create models with artisan (This will add the model file, and the migration file.)
<pre><code class="language-sh">php artisan make:model Topic --migration
</code></pre>
</li>
<li>Add the table columns in the migration file. See all column types here: https://laravel.com/docs/7.x/migrations#columns</li>
<li>Save model to db:
<pre><code class="language-php">$myModel = new MyModel();

$myModel-&gt;myColumn = 'Hello';

$myModel-&gt;save();
</code></pre>
</li>
<li>Load models from db:
<pre><code class="language-php">// All records.
$myModels = MyModel::all();

// Query records.
$myModels = MyModel::where('active', 1)-&gt;get();
</code></pre>
</li>
<li>To update models, just set the fields and save.</li>
</ul>
<h2><a class="header" href="#routing" id="routing">Routing</a></h2>
<ul>
<li>Add routes to <code>routes/web.php</code>.</li>
<li>Hello world:
<pre><code class="language-php">Route::get('home', function() {
  return 'Hello, world';
});
</code></pre>
</li>
<li>Typically you pass a controller and method name though:
<pre><code class="language-php">Route::get('home', 'HomeController@index');
</code></pre>
</li>
<li>Resource controllers automatically support crud methods, typically for models:
<pre><code class="language-php">Route::resource('posts', 'PostController');
</code></pre>
</li>
</ul>
<h2><a class="header" href="#controllers" id="controllers">Controllers</a></h2>
<ul>
<li>Generate controllers with artisan:
<pre><code class="language-sh">php artisan make:controller HomeController
</code></pre>
</li>
<li>Resource controllers have the crud methods prepopulated (also, pass the model when generating to include type hints):
<pre><code class="language-sh">php artisan make:controller PostController --resource --model=Post
</code></pre>
</li>
<li>See the resource actions available here: https://laravel.com/docs/7.x/controllers#resource-controllers</li>
<li>Each controller method receives the request as the first argument. This has the request params (query string and form data) and many helpful methods:
<pre><code class="language-php">public function index($request)
{
  $myParam = $request-&gt;myParam;

  $user = $request-&gt;user();

  // return response here...
}
</code></pre>
</li>
</ul>
<h2><a class="header" href="#views" id="views">Views</a></h2>
<ul>
<li>Views are blade template files that allow dynamic data to be rendered in html:</li>
</ul>
<pre><code class="language-php">&lt;h1&gt;{{ $user-&gt;name }}&lt;/h1&gt;
</code></pre>
<ul>
<li>Views are typically rendered as a responses from controller methods using the <code>view</code> helper:
<pre><code class="language-php">public function index($request)
{
  return view('my-view', [
      'user' =&gt; $request-&gt;user()
  ]);
}
</code></pre>
</li>
<li>Pass the path to the blade template inside <code>resources/views</code>, and omit <code>.blade.php</code>.</li>
<li>Pass data to the view as an array. The keys will be available as variables in the blade template.</li>
</ul>
<h2><a class="header" href="#forms-1" id="forms-1">Forms</a></h2>
<ul>
<li>Validate forms with the validate method on the request:
<pre><code class="language-php">public function store($request)
{
  $request-&gt;validate([
      'myParam' =&gt; ['required'],
  ])

  // Validation passed! Save form data to db, etc.

  return back() // back helper redirects back to referrer, i.e. the form that posted.
    -&gt;with('status', 'success') // set session data so we can display a success message.
}
</code></pre>
</li>
<li>If validation fails, it will automatically redirect back to the form with <code>$errors</code> in the session.</li>
<li>Also notice above how we redirect back with success in the session if the form submitted successfully.</li>
</ul>
<h1><a class="header" href="#magento-2" id="magento-2">Magento 2</a></h1>
<p>tags: magento, e-commerce</p>
<h2><a class="header" href="#nomenclature" id="nomenclature">Nomenclature</a></h2>
<ul>
<li>Action File: A Controller by another name</li>
<li><a href="https://devdocs.magento.com/guides/v2.3/architecture/archi_perspectives/components/modules/mod_and_areas.html">Area</a>: A logical component made of multiple modules. Each area can process url requests differently.</li>
<li><a href="https://devdocs.magento.com/guides/v2.3/mtf/mtf_entities/mtf_block.html">Block</a>: A PHP class which links layouts and templates</li>
<li>Controller: A file that responds to a route</li>
<li><a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/layouts/layout-overview.html">Layout</a>: the way items are arranged on a page. This is defined in an XML file</li>
<li><a href="https://devdocs.magento.com/guides/v2.3/architecture/archi_perspectives/components/modules/mod_intro.html">Module</a>: A logical group. Each module has a defined directory structure with a set of expected files.</li>
<li><a href="https://devdocs.magento.com/page-builder/docs/index.html">Page Builder</a>: Magento 2 extension that allows you to create pages without coding. Page Builders comes with Magento 2.</li>
<li>Route: a url made of three parts: <code>frontName-controllerName-actionName</code></li>
<li><a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/templates/template-overview.html">Template</a>: Code (PHTML - which is PHP) that adds the features and contents you see</li>
<li><a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/themes/theme-overview.html">Theme</a>: The way to customize the look and feel of a an application area (e.g. the storefront or the admin)</li>
</ul>
<h2><a class="header" href="#cli-1" id="cli-1">CLI</a></h2>
<p>Magento 2 has a great <a href="https://devdocs.magento.com/guides/v2.3/config-guide/cli/config-cli-subcommands.html">cli</a>. <a href="https://www.emiprotechnologies.com/technical_notes/magento-technical-notes-60/post/magento-2-useful-commands-list-391">Here</a> is a summary of useful commands.</p>
<h2><a class="header" href="#caching" id="caching">Caching</a></h2>
<pre><code class="language-bash">bin/magento cache:disable
# or
bin/magento cache:enable

bin/magento cache:flush
</code></pre>
<h2><a class="header" href="#routes" id="routes">Routes</a></h2>
<p>The frontend and admin area each have a merged routes.xml file.</p>
<p>The merged file is created from each modules routes file (<code>etc/&lt;area&gt;/routes.xml</code>)</p>
<h2><a class="header" href="#templates" id="templates">Templates</a></h2>
<p>To understand which templates are used on a page, enable template hints and clear the cache:</p>
<pre><code class="language-bash"># cd to project root first
bin/magento dev:template-hints:enable
bin/magento cache:clean
</code></pre>
<h2><a class="header" href="#themes" id="themes">Themes</a></h2>
<p><a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/themes/theme-apply.html">Change a theme</a> for a domain in <code>CONTENT &gt; Design &gt; Configuration</code>, then clear the cache: <code>bin/magento cache:clean</code>.</p>
<pre><code class="language-bash">bin/magento setup:static-content:deploy
</code></pre>
<h3><a class="header" href="#modes" id="modes">Modes</a></h3>
<ol>
<li>Developer mode is where you develop your Magento site. Static files are written to pub/ directory every time they are called, as well as displaying exception errors being thrown in the front end.</li>
<li>Production mode: Static files are deployed and when requested, it is pulled from cache only. These files are located in root install dir/pub/static</li>
</ol>
<p>Set mode:</p>
<pre><code class="language-bash">bin/magento deploy:mode:set developer
# or
php bin/magento deploy:mode:set production
</code></pre>
<h3><a class="header" href="#static-theme-files" id="static-theme-files">Static theme files</a></h3>
<p>Static files are the stuff that is not PHP / Less:</p>
<pre><code>app/design/frontend/&lt;vendor&gt;/&lt;theme&gt;/
├── web/
│ ├── css/
│ │ ├── source/
│ ├── fonts/
│ ├── images/
│ ├── js/
</code></pre>
<h3><a class="header" href="#less-files" id="less-files">Less files</a></h3>
<p>To extend use <code>_extend.less</code> in <code>web/css/source</code></p>
<p>To override use <code>_theme.less</code> in <code>web/css/source</code> (clobbers parents <code>_theme.less</code>)</p>
<h4><a class="header" href="#local-compilation" id="local-compilation">Local Compilation</a></h4>
<pre><code class="language-bash">grunt npm install -g grunt-cli
npm i
</code></pre>
<p>Add theme to <a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/css-topics/css_debug.html"><code>dev/tools/grunt/configs/theme.js</code></a></p>
<pre><code class="language-json">&quot;theme&quot;: {
  &quot;area&quot;: &quot;frontend&quot;,
  &quot;name&quot;: &quot;Mytheme/default&quot;,
  &quot;locale&quot;: &quot;language&quot;,
  &quot;files&quot;: [
    &quot;path_to_file1&quot;,
    &quot;path_to_file2&quot;
  ],
  &quot;dsl&quot;: &quot;less&quot;
},
</code></pre>
<p>(you could also <a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/css-topics/gulp-sass.html">use gulp sass</a>)</p>
<h2><a class="header" href="#admin-session-timeout" id="admin-session-timeout">Admin session timeout</a></h2>
<ul>
<li>Stores &gt; Settings &gt; Configuration &gt; Advanced &gt; Admin &gt; Security &gt; Admin Session Lifetime (seconds)</li>
<li>Source: https://magento.stackexchange.com/a/101861/83194</li>
</ul>
<h2><a class="header" href="#search-results" id="search-results">Search results</a></h2>
<ul>
<li>m1 search type could be configured from three options, like, fulltext, or combined (like and fulltext)</li>
<li>m2 search type cannot be configured and is set to fulltext.</li>
<li>m2 search is tuned by adjusting the products attributes at Stores &gt; Attribute &gt; Product:
<ul>
<li>Use in search: set yes/no to search the attribute.</li>
<li>Weight: increase to make the attribute more important to search results, e.g. name should probably have a higher search weight than other attributes.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#helpful-references" id="helpful-references">Helpful References</a></h2>
<ul>
<li><a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/themes/theme-create.html">Creating a theme</a></li>
<li><a href="https://devdocs.magento.com/#/individual-contributors">Dev Docs</a></li>
<li><a href="https://glossary.magento.com/">Magento Glossar</a></li>
<li><a href="https://devdocs.magento.com/guides/v2.3/frontend-dev-guide/themes/theme-structure.html">Theme Structure</a></li>
</ul>
<h1><a class="header" href="#create-a-page-in-magento-2" id="create-a-page-in-magento-2">Create a page in Magento 2</a></h1>
<p>tags: e-commerce, magento, pages</p>
<p>This describes how to <a href="https://devdocs.magento.com/videos/fundamentals/create-a-new-page/">create a new page</a> in Magento.</p>
<p>The description below is for the <code>HelloPage</code> page in the <code>Learning</code> Area. </p>
<p>To create a new page, you need a controller that responds to a route.</p>
<p>A route has three parts: <code>frontName-controllerName-actionName</code></p>
<p>The steps to do this are:</p>
<ol>
<li>Create a new module</li>
<li>Create a <code>routes.xml</code> file</li>
<li>Add a controller</li>
</ol>
<h2><a class="header" href="#routesxml" id="routesxml">Routes.xml</a></h2>
<p>Since we're in the frontend, we create a frontend routes.xml file: <code>app/code/Learning/HelloPage/etc/frontend/routes.xml</code></p>
<h2><a class="header" href="#creating-a-new-module" id="creating-a-new-module">Creating a new module</a></h2>
<h1><a class="header" href="#customizations-in-magento" id="customizations-in-magento">Customizations in Magento</a></h1>
<p>tags: magento, overrides, plugins, observers</p>
<h2><a class="header" href="#overriding-blocks" id="overriding-blocks">Overriding blocks</a></h2>
<p>Looks in the <code>view/frontend/layout/default.xml</code> of the module you want to override. Create a <code>layout/default.xml</code> in yours and use <code>referenceBlock</code> to override just the needed bits.</p>
<p>For example for a custom logo.</p>
<p>The block is found in:  <code>/vendor/magento/module-theme/view/frontend/layout/default.xml</code>, so we create: <code>/app/design/frontend/Solid/LoveAndPromise/Magento_Theme/layout/default.xml</code></p>
<p>The contents are something like:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;page xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;urn:magento:framework:View/Layout/etc/page_configuration.xsd&quot;&gt;
    &lt;body&gt;
        &lt;referenceBlock name=&quot;logo&quot;&gt;
            &lt;arguments&gt;
                &lt;argument name=&quot;logo_file&quot; xsi:type=&quot;string&quot;&gt;images/my_logo.svg&lt;/argument&gt;
                &lt;argument name=&quot;logo_alt&quot; xsi:type=&quot;string&quot;&gt;My Logo&lt;/argument&gt;
                &lt;argument name=&quot;logo_img_width&quot; xsi:type=&quot;number&quot;&gt;109&lt;/argument&gt;
                &lt;argument name=&quot;logo_img_height&quot; xsi:type=&quot;number&quot;&gt;85&lt;/argument&gt;
            &lt;/arguments&gt;
        &lt;/referenceBlock&gt;
    &lt;/body&gt;
&lt;/page&gt;
</code></pre>
<h2><a class="header" href="#overriding-classes" id="overriding-classes">Overriding Classes</a></h2>
<p>You can override an entire class by setting a preference in di.xml:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;config xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;urn:magento:framework:ObjectManager/etc/config.xsd&quot;&gt;
    &lt;preference for=&quot;MageWorkshop\DetailedReview\Block\Review\Product\View\Rating\ReviewRating&quot; type=&quot;Solid\DetailedReviewRatingCustomization\Block\Review\Product\View\Rating\ReviewRating&quot; /&gt;
&lt;/config&gt;
</code></pre>
<p>You can now create a class the extends the original class.</p>
<h2><a class="header" href="#overriding--modifying-class-methods" id="overriding--modifying-class-methods">Overriding / Modifying Class Methods</a></h2>
<p>You can use <a href="https://devdocs.magento.com/guides/v2.3/extension-dev-guide/plugins.html">Interceptors (Plugins)</a> to run stuff before / after / or instead of methods.</p>
<h2><a class="header" href="#events-and-observers" id="events-and-observers">Events and Observers</a></h2>
<p>You can send <a href="https://devdocs.magento.com/guides/v2.3/extension-dev-guide/events-and-observers.html">events and setup observers</a> for them.</p>
<p>There are 3 places you can put an <code>events.xml</code> file to setup an Observer. For front end events use <code>etc/frontend/events.xml</code> inside your module.</p>
<p>In <code>events.xml</code> declare the event you want to obeserve and its observer:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;config xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;urn:magento:framework:Event/etc/events.xsd&quot;&gt;
    &lt;event name=&quot;page_block_html_topmenu_gethtml_after&quot;&gt;
        &lt;observer name=&quot;solid_menu_observer&quot; instance=&quot;Solid\Menu\Observer\Topmenu&quot; /&gt;
    &lt;/event&gt;
&lt;/config&gt;
</code></pre>
<p>The observer is a class that implements the <code>ObserverInterface</code>. You create an <code>execute</code> methods that takes the <code>$observer</code> as an argument. You can dependencies in the constructor if needed.</p>
<p>In my opinion, the trickiest part of observers is knowing what methods to call on them.
For example here is how you get and set the data for the example above:</p>
<pre><code class="language-php">&lt;?php
namespace Solid\Menu\Observer;
use Magento\Framework\Event\Observer as EventObserver;
use Magento\Framework\Event\ObserverInterface;
class Topmenu implements ObserverInterface
{
    public function execute(EventObserver $observer)
    {
        $transport = $observer-&gt;getData('transportObject');
        $html = $transport-&gt;getHtml();
        $html .= '&lt;h3&gt;This is customized!&lt;/h3&gt;';
        $transport-&gt;setHtml($html);
    }
}
</code></pre>
<p>The way to know that the data to get is <code>transportObject</code> and the the getter/setter is Html is to look at where the event is fired:</p>
<pre><code class="language-php">&lt;?php
// From vendor/magento/module-theme/Block/Html/Topmenu.php
$transportObject = new \Magento\Framework\DataObject(['html' =&gt; $html]);
$this-&gt;_eventManager-&gt;dispatch(
    'page_block_html_topmenu_gethtml_after',
    ['menu' =&gt; $this-&gt;getMenu(), 'transportObject' =&gt; $transportObject]
);
</code></pre>
<h2><a class="header" href="#custom-blocks" id="custom-blocks">Custom blocks</a></h2>
<ul>
<li>If you need to add some functionality to a template, add a custom block to handle the functionality because then you will have access to the dependency injection system provided by magento 2.</li>
<li>Add the block php file to <code>app/code/{vendor}/{module}/Block</code>. The class name should match the file name, and should be namespaced under <code>{vendor}\{module}\Block</code>. You can place the block class in a deeper folder, just be sure to update the namespace to match the folders.</li>
<li>Extend the class from <code>Magento\Framework\View\Element\Template</code>.</li>
<li>Reference the block class from the layout xml, e.g. <code>&lt;block class=&quot;{vendor}\{module}\Block\CustomBlock&quot; ... /&gt;</code>.</li>
<li>Add dependencies as parameters to the block class constructor. Magento will automatically inject the dependencies when the block is instantiated.</li>
<li>Access the block in the template as the variable <code>$block</code>.</li>
</ul>
<h2><a class="header" href="#customize-strings" id="customize-strings">Customize strings</a></h2>
<ul>
<li>To customize strings from magento core, add <code>&quot;{source}&quot;, &quot;{new}&quot;</code> as a new line to <code>app/design/frontend/{vendor}/{theme}/i18n/en_US.csv</code>.</li>
</ul>
<h1><a class="header" href="#debugging-magento-2" id="debugging-magento-2">Debugging Magento 2</a></h1>
<p>tags: magento, debugging</p>
<h2><a class="header" href="#bucket-doesnt-exist-error" id="bucket-doesnt-exist-error">Bucket doesn't exist error.</a></h2>
<p>This is due to categories not being selected as &quot;anchor&quot; categories.</p>
<p>The fix can be done manually by going to <a href="https://meetanshi.com/blog/set-anchor-to-yes-in-all-categories-in-magento-2/">each category in the admin</a>, opening the accordion and selecting the checkbox... or in the DB:</p>
<pre><code class="language-mysql">SELECT attribute_id FROM eav_attribute where attribute_code = 'is_anchor';

# 120 was the attribute id from the above
UPDATE catalog_category_entity_int set value = 1 where attribute_id = 120;
</code></pre>
<p>to see the updates from the DB you have to reindex:</p>
<pre><code class="language-bash">bin/magento indexer:reindex
</code></pre>
<h2><a class="header" href="#error-unable-to-retrieve-deployment-version-of-static-files-from-the-file-system" id="error-unable-to-retrieve-deployment-version-of-static-files-from-the-file-system">Error: <code>Unable to retrieve deployment version of static files from the file system.</code></a></h2>
<ul>
<li>Source: Could get this error on <code>grunt exec</code>.</li>
<li>Solution: add <code>'static_content_on_demand_in_production' =&gt; 1</code> to root array of <code>app/etc/env.php</code>.</li>
</ul>
<h2><a class="header" href="#nginx-502" id="nginx-502">nginx 502</a></h2>
<p>Check <code>/etc/log/nginx/error.log</code></p>
<ul>
<li><code>upstream sent too big header while reading response header from upstream</code>
<ul>
<li>add this to magento main location block in nginx config:
<pre><code>fastcgi_buffers 128 4096k;
fastcgi_buffer_size 4096k;
</code></pre>
</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#namespaces" id="namespaces">Namespaces</a></h1>
<p>tags: php, namespaces</p>
<p><a href="http://php.net/manual/en/language.namespaces.php">Namespaces</a> allow you to not have to worry about naming collisions. You will often have to reach into other namespaces.
Here is an example:</p>
<pre><code class="language-php">use WeDevs\ORM\Eloquent\Model;

class ClassTrainee extends Model {
</code></pre>
<p>is easier to read than:</p>
<pre><code class="language-php">class ClassTrainee extends \WeDevs\ORM\Eloquent\Model {
</code></pre>
<h2><a class="header" href="#references-4" id="references-4">References:</a></h2>
<ul>
<li>http://php.net/manual/en/language.namespaces.php</li>
</ul>
<h1><a class="header" href="#wordpress" id="wordpress">Wordpress</a></h1>
<p>tags: php, wordpress, mysql</p>
<h2><a class="header" href="#svg-uploads" id="svg-uploads">SVG Uploads</a></h2>
<pre><code class="language-php">function cc_mime_types($mimes) {
    $mimes['svg'] = 'image/svg+xml';
    return $mimes;
}
add_filter('upload_mimes', 'cc_mime_types');
</code></pre>
<h2><a class="header" href="#create-an-admin-user-via-wp-cli" id="create-an-admin-user-via-wp-cli">Create an admin user via wp cli</a></h2>
<pre><code>THE_ENV=production wp user create example.user exmple.user@soliddigital.com --role=administrator
</code></pre>
<p>This returns the new user's password.</p>
<h2><a class="header" href="#create-an-admin-user-via-mysql" id="create-an-admin-user-via-mysql">Create an admin user via mysql</a></h2>
<p>Replace the dummy data with your info:</p>
<pre><code class="language-sql">INSERT INTO `wp_users` (
	`user_login`,
	`user_pass`,
	`user_nicename`,
	`user_email`,
	`user_url`,
	`user_registered`,
	`user_activation_key`,
	`user_status`,
	`display_name`
) VALUES (
	'username',
	MD5('password'),
	'nice-name',
	'email_address',
	'website',
	NOW(),
	'',
	'0',
	'Full Name'
);
</code></pre>
<p>Then grab the <code>$user_id</code> of your new user to use in the next insert:</p>
<pre><code class="language-sql">INSERT INTO `wp_usermeta` (
	`user_id`,
	`meta_key`,
	`meta_value`
) VALUES (
	$user_id,
	'wp_capabilities',
	'a:1:{s:13:&quot;administrator&quot;;s:1:&quot;1&quot;;}'
), (
	$user_id,
	'wp_user_level',
	'10'
);
</code></pre>
<hr />
<h6><a class="header" href="#source-httpwwwwpbeginnercomwp-tutorialshow-to-add-an-admin-user-to-the-wordpress-database-via-mysql" id="source-httpwwwwpbeginnercomwp-tutorialshow-to-add-an-admin-user-to-the-wordpress-database-via-mysql">Source: http://www.wpbeginner.com/wp-tutorials/how-to-add-an-admin-user-to-the-wordpress-database-via-mysql/</a></h6>
<h2><a class="header" href="#wp-cron" id="wp-cron">Wp cron</a></h2>
<p>Prefer calling <code>wp-cron.php</code> manually with server crontab, rather than default wp cron behavior, which checks if it needs to run on every page load, and then runs if needed, extending that user's page load. To implement:</p>
<ul>
<li>disable default wp cron behavior in <code>wp-config.php</code>
<pre><code>define('DISABLE_WP_CRON', true);
</code></pre>
</li>
<li>then add call to <code>wp-cron.php</code> at desired frequency in your server's crontab (using <code>wget</code> here but you can use whatever to make the request):
<pre><code>0 * * * * wget http://www.example.com/wp-cron.php
</code></pre>
</li>
<li>To actually implement a regular task to be run by <code>wp-cron.php</code>, use <code>wp_schedule_event()</code>. Full example:</li>
</ul>
<pre><code class="language-php">add_action('init', 'init');
add_action('my_hourly_task', 'my_hourly_task');

function init()
	// Check if your task is already scheduled.
	if (!wp_next_scheduled('my_hourly_task')) {
		// Schedule the event, passing the interval, and the name of the action hook to call.
		// Now when wp-cron.php is called (via crontab, maybe), if my_hourly_task is scheduled,
		// and the time interval is elapsed, it will run do_action('my_hourly_task');
		wp_schedule_event(time(), 'hourly', 'my_hourly_task');
	}
}

public function my_hourly_task() {
	// Do the work that needs to run every hour.
}
</code></pre>
<h2><a class="header" href="#queries" id="queries">Queries</a></h2>
<p>To see the queries during a page render:</p>
<pre><code class="language-php">define('SAVEQUERIES', true);
</code></pre>
<p>Then the queries are stored on:</p>
<pre><code class="language-php">$wpdb-&gt;queries;
</code></pre>
<h2><a class="header" href="#multisite-network-settings" id="multisite-network-settings">Multisite network settings</a></h2>
<ul>
<li>A wordpress multisite network has additional settings in admin at My Sites &gt; Network Admin &gt; Settings, or <code>/wp-admin/network/settings.php</code></li>
<li>Notable settings include file upload settings
<ul>
<li>Max upload file size: default is 1500k</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#elementor" id="elementor">Elementor</a></h1>
<p>tags: wordpress, elementor, widgets</p>
<h2><a class="header" href="#creating-custom-widgets" id="creating-custom-widgets">Creating Custom Widgets</a></h2>
<p>One of the powerful things about elementor is that it easy easy to create custom widgets.</p>
<p>Widgets are seens as tiles on the back and that you drag and drop into place in the page builder. On the front end they can look however you want.</p>
<p>The preferred way of registering a widget is via a plugin.</p>
<p><a href="https://developers.elementor.com/creating-an-extension-for-elementor/">Here is how you create an Elementor Plugin</a></p>
<p>Once you have your plugin, that can register the widget.</p>
<p><a href="https://developers.elementor.com/creating-a-new-widget/">Here is how you create an Elementor Widget</a></p>
<p><a href="https://benmarshall.me/build-custom-elementor-widgets/">This blog post</a> does a good job of tying the above two concepts together.</p>
<h1><a class="header" href="#i10n" id="i10n">i10n</a></h1>
<p>tags: L10n, i18n, Wordpress, PHP</p>
<p>The way this works in WP is through use of WP's builtin <code>__()</code> function. There's a lot more to this but for the sake of brevity here's what a dev needs to know to work with this stuff.</p>
<p>So let's say I wanted to run:</p>
<p><code>__('Hello!')</code></p>
<p>It's just a string replacement function that gets it's replacement strings from a particular file (usually with the .po or .pot extension) instead of an array or some other data structure you might normally use in php.</p>
<p>The .po file will have a lot of frontmatter type stuff like this at the top:</p>
<pre><code># Copyright (C) 2018 Some Guy
# This file is distributed under the GPL-3.0+.
&quot;Project-Id-Version: The Cool Plugin 4.1.14\n&quot;
&quot;Report-Msgid-Bugs-To: &quot;
&quot;https://wordpress.org/support/plugin/the-cool-plugin\n&quot;
&quot;POT-Creation-Date: 2018-09-29 04:00:45+00:00\n&quot;
&quot;MIME-Version: 1.0\n&quot;
</code></pre>
<p>But it can be ignored. That stuff is mostly intended for the apps used by non-technical people for editing these, like Poedit. Just below that you will see something like</p>
<pre><code>msgid &quot;Change status to moderate&quot;
msgstr &quot;Cambiar estado a moderar&quot;

msgid &quot;Trash the post&quot;
msgstr &quot;a la Basura&quot;

msgid &quot;Cheating&quot;
msgstr &quot;a la Basura&quot;
</code></pre>
<p>It's basically an object where the keys are the strings you need translated. If there is a value for the key you use, you get the associated translation, if not it just returns the same text. So again, if we were to run <code>__('Hello!')</code> against this, <code>__()</code> would just return <code>'Hello!'</code>. Let us add a line for translating it</p>
<pre><code>msgid &quot;Change status to moderate&quot;
msgstr &quot;Cambiar estado a moderar&quot;

msgid &quot;Trash the post&quot;
msgstr &quot;a la Basura&quot;

msgid &quot;Cheating&quot;
msgstr &quot;a la Basura&quot;

msgid &quot;Hello!&quot;
msgstr &quot;¡Hola!&quot;
</code></pre>
<p>Now when we run <code>__('Hello!')</code> we get <code>'¡Hola!'</code>. Nice! Since we now understand everything there is to understand about .po and .pot files, there's a couple more things to know about this stuff:</p>
<h2><a class="header" href="#1-i-lied-__-actually-uses-mo-files-not-po" id="1-i-lied-__-actually-uses-mo-files-not-po">#1: I lied, <code>__()</code> actually uses .mo files, not .po</a></h2>
<p>And .mo files are what's used by wordpress to actually do the translation. Not to worry, they are generated by the .po/.pot file. So if the file we were working with above was named <code>the-cool-plugin_spanish.po</code>, the generated .mo file might be something like <code>the-cool-plugin_spanish.mo</code>. The generation of .mo files can be in many ways. Poedit is one, there's also web based tools for it. If you prefer the terminal, msgfmt is a good option. Grunt and Gulp can even do it, with their respective potomo plugins.</p>
<h2><a class="header" href="#2-text-domains" id="2-text-domains">#2 Text Domains:</a></h2>
<p><a href="https://codex.wordpress.org/I18n_for_WordPress_Developers#Text_Domains">May or may not</a> be something you have to do a lot of thinking about. Think of it as a form of namespacing for your translations. If you are making your own .mo files though, you are probably overriding WP's built in translation functionality, which is a whole other big markdown file unto itself.</p>
<h1><a class="header" href="#wordpress-engine" id="wordpress-engine">Wordpress Engine</a></h1>
<p>tags: wordpress, wp-engine</p>
<p>Ideally hook WP Engine up with Git deploy.</p>
<p>If you're doing a one time deploy with no Git hookup, here is a quick way to do it:</p>
<ol>
<li>Make a backup point in WP Engine</li>
<li>Do a search and replace with wp cli on the dev environment from the dev to production domain</li>
<li>Download the sql file from your dev environment</li>
<li>rsync the sql file onto wp-engine's wp-content directory (it will not be publicly accessible)</li>
<li>rsync the uploads dir onto wp engine (e.g. <code>rsync -rztP ./uploads/ example@example.ssh.wpengine.net:/home/wpe-user/sites/example/wp-content/uploads/</code> - <code>r</code> recursive, <code>z</code> comress, <code>t</code> preserve time stamps, <code>P</code> progress bar)</li>
<li>rsync the plugins dir onto wp engine</li>
<li>rsync the themes dir onto wp engine</li>
<li>ssh in to wp-enginen and load the sql file into the db using the credentials in wp-config.php</li>
</ol>
<p>Note that you might have to change the table prefix after uploading the SQL.</p>
<p>Also not that the sql file size limit is small on Wp Engine's PHPMyAdmin, so it's generally easier to upload the sql via ssh.</p>
<h1><a class="header" href="#profiling-websites--apis" id="profiling-websites--apis">Profiling Websites / APIs</a></h1>
<p>tags: profiling, ab, stress-testing, autocannon, performance</p>
<h2><a class="header" href="#apache-ab" id="apache-ab">Apache AB</a></h2>
<p>To do some rough profiling around response time, you can use <code>ab</code> - apache benchmark.</p>
<p>This will send a total of 1000 requests, 10 at a time to <code>http://www.something.com/</code>.</p>
<pre><code>ab -n 1000 -c 10 -g something.tsv http://www.something.com/
</code></pre>
<p><code>-g</code> means each response is listed separately, and the file is tab separated.</p>
<pre><code>starttime	seconds	ctime	dtime	ttime	wait
Wed Apr 15 18:54:11 2015	1429149251	1	147	148	147
Wed Apr 15 18:54:11 2015	1429149251	0	152	152	152
Wed Apr 15 18:54:11 2015	1429149251	1	152	153	152
...
</code></pre>
<p><code>-e</code> would be comma separated and would have to requests binned by the time it
took to complete that percent of requests.</p>
<pre><code>Percentage served,Time in ms
0,117.436
1,117.436
2,120.811
3,120.811
...
</code></pre>
<p>Of course each format is useful for different things, so don't restrict yourself:</p>
<pre><code>ab -n 1000 -c 10 -e something.csv -g something.tsv http://www.something.com/
</code></pre>
<p>Additionally you get a summary of the requests.</p>
<pre><code>Document Path:          /
Document Length:        0 bytes

Concurrency Level:      10
Time taken for tests:   55.637 seconds
Complete requests:      1000
Failed requests:        0
Non-2xx responses:      1000
Total transferred:      357000 bytes
HTML transferred:       0 bytes
Requests per second:    17.97 [#/sec] (mean)
Time per request:       556.368 [ms] (mean)
Time per request:       55.637 [ms] (mean, across all concurrent requests)
Transfer rate:          6.27 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    9  89.3      1    1003
Processing:   376  547 137.9    530    1942
Waiting:      376  546 137.9    530    1942
Total:        377  555 168.9    531    1942

Percentage of the requests served within a certain time (ms)
  50%    531
  66%    552
  75%    568
  80%    577
  90%    611
  95%    653
  98%   1473
  99%   1655
 100%   1942 (longest request)
</code></pre>
<p>You can use gnuplot to visualize:</p>
<p>http://www.bradlanders.com/2013/04/15/apache-bench-and-gnuplot-youre-probably-doing-it-wrong/</p>
<p>You can place multiple outputs on the same graph. This is useful for comparing
before and afters, or showing degradation as concurrency increases.</p>
<p>It is possible to send data, headers, and cookies with requests.</p>
<h2><a class="header" href="#autocannon" id="autocannon">Autocannon</a></h2>
<p><a href="https://github.com/mcollina/autocannon">Autocannon</a> is easy to use if you like node, but graphing is harder.</p>
<h1><a class="header" href="#web-profiling-with-lighthouse" id="web-profiling-with-lighthouse">Web Profiling with Lighthouse</a></h1>
<p>tags: lighthouse, profiling, chrome, performance</p>
<p>Chrome now has an <a href="https://developers.google.com/web/updates/2017/05/devtools-release-notes#lighthouse">audit panel</a> in their
dev tools console. </p>
<p>The audits are done with <a href="https://developers.google.com/web/tools/lighthouse/">Lighthouse</a>. There is an <a href="https://www.npmjs.com/package/lighthouse">npm</a> 
with which you can use Lighthouse programmatically both on your local box and on a server.</p>
<p>Regular chrome is now headless, so you like don't have to install anything aside from npms on your local box.</p>
<p>On Ubuntu, you can install chromium, to have a headless browser to use with Lighthouse:</p>
<pre><code class="language-bash">sudo apt install chromium-browser
</code></pre>
<p>To use light house programatically you need 2 npms: </p>
<pre><code class="language-bash">npm i lighthouse chrome-launcher
</code></pre>
<p>Here is an example of how to get performance data from an array of urls. In this instance we're running the tests in series
and not in parallel, so as to put less stress on the server.</p>
<p>User <code>results.lhr</code> for javascript parseable results. There is a lot more information on the results object to look at.</p>
<pre><code class="language-javascript">'use strict';

const urls = ['https://www.soliddigital.com', 'https://www.soliddigital.com/insights'];
const lighthouse = require('lighthouse');
const chromeLauncher = require('chrome-launcher');
const flags = {
    chromeFlags: ['--headless'],
    onlyCategories: [
        'performance',
        'accessibility',
        'best-practices',
        'seo'
    ]
};

const BB = require('bluebird');

module.exports = performAudit;

function performAudit() {
    console.log('Starting audit');

    return BB.mapSeries(urls, url =&gt; {
        return auditUrl(url, flags)
            .catch(e =&gt; {
                console.log('lighthouse error', e);
                console.log('continuing through the rest of the urls....');
            });
    });
}

function auditUrl(url, flags) {
    return launchChromeAndRunLighthouse(url, flags)
        .then(results =&gt; {
            const audit =  {
                performance: results.lhr.categories.performance.score,
                accessibility: results.lhr.categories.accessibility.score,
                bestPractices: results.lhr.categories['best-practices'].score,
                seo: results.lhr.categories.seo.score
            };

            console.log(audit);

            return audit;
        });
}

function launchChromeAndRunLighthouse(url, flags = {}, config = null) {
    return chromeLauncher.launch(flags).then(chrome =&gt; {
        flags.port = chrome.port;
        return lighthouse(url, flags, config)
            .then(results =&gt; chrome.kill().then(() =&gt; results));
    });
}
</code></pre>
<p>For interpretation of Lighthouse scores, see <a href="https://developers.google.com/web/tools/lighthouse/scoring">this page</a>.</p>
<h1><a class="header" href="#security" id="security">Security</a></h1>
<p>tags: security</p>
<p>This is a very incomplete and partial look at security.</p>
<h2><a class="header" href="#binding-to-localhost-1" id="binding-to-localhost-1">Binding to localhost</a></h2>
<p>Binding to localhost increases security and removes the ability for easy access
to many services that use ports to run (mysql, mongo, elasticsearch).</p>
<p>This means that the
ports the services use will not be available directly from other hosts. This allows
better control of access. For example if you bind mongo to localhost, applications
running on your server can still access it. You can also get access via SSH
tunnels or proxies. For example using nginx and htpasswd you can password protect
something like elasticsearch. Nginx can listen on port 80, and only allow access
in certain cases by doing a proxy_pass to localhost port 9200.</p>
<h2><a class="header" href="#login-1" id="login-1">Login</a></h2>
<p>SSH login is much more secure - and ends up being easer to manage for users - than
password login, so it is a good idea to turn off password login and enable ssh
login.</p>
<p>SSH login can be enabled and password login disabled in <code>/etc/ssh/ssh_confd</code>:</p>
<pre><code>PubkeyAuthentication yes
PasswordAuthentication no
</code></pre>
<p>After this is done the sshd service must be restarted for the changes to take effect:</p>
<pre><code>sudo service ssh restart
</code></pre>
<p>Make sure you don't lock yourself out. It is a good idea to first enable ssh login,
test it, then disable password login.</p>
<h2><a class="header" href="#ssh-port" id="ssh-port">SSH port</a></h2>
<p><code>tail -f /var/log/auth.log</code> will often show a lot of attempted logins on port 22
of people you don't know. Changing the ssh port to something other than 22 will
decrease this barage.</p>
<p>The ssh port can be change in <code>/etc/ssh/sshd_config</code>:</p>
<pre><code>Port 22
</code></pre>
<h2><a class="header" href="#disabling-sslv3" id="disabling-sslv3">Disabling sslv3</a></h2>
<p>In the http context:</p>
<p>http://nginx.org/en/docs/http/configuring_https_servers.html</p>
<pre><code>##
# SSL Settings
##
ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
ssl_ciphers  HIGH:!aNULL:!MD5;
ssl_prefer_server_ciphers on;
</code></pre>
<p>Check your results:</p>
<p>https://www.ssllabs.com/ssltest/</p>
<h1><a class="header" href="#https" id="https">HTTPS</a></h1>
<p>tags: security, https, certs, tls</p>
<h2><a class="header" href="#certs" id="certs">Certs</a></h2>
<p>There are 3 main types of certs: DV, OV, and EV. <a href="https://www.ssl.com/article/dv-ov-and-ev-certificates/">DV and EV certs are most common</a>.</p>
<h3><a class="header" href="#confirm-a-secure-connection-via-openssl" id="confirm-a-secure-connection-via-openssl">Confirm a secure connection via openssl</a></h3>
<pre><code class="language-bash">openssl s_client -connect &lt;domain.com&gt;:443 -tls1_2
</code></pre>
<p>If you get the certificate chain and the handshake you know the system in question 
supports TLS 1.2. If you see don't see the certificate chain, and something similar to 
&quot;handshake error&quot; you know it does not support TLS 1.2. You can also test for TLS 1 or 
TLS 1.1 with -tls1 or tls1_1 respectively.</p>
<p>More info <a href="https://serverfault.com/questions/638691/how-can-i-verify-if-tls-1-2-is-supported-on-a-remote-web-server-from-the-rhel-ce">here</a></p>
<h3><a class="header" href="#use-nmap-for-cipher-information" id="use-nmap-for-cipher-information">Use nmap for cipher information</a></h3>
<pre><code class="language-bash">nmap --script ssl-enum-ciphers -p 443 &lt;domain.com&gt;
</code></pre>
<p>This will tell you the available ciphers for the server and their strength.</p>
<h3><a class="header" href="#test-with-ssl-labs" id="test-with-ssl-labs">Test with SSL Labs</a></h3>
<p>SSL labs offers an online tool for verifying SSL/TLS. It's nice because you don't have to install any
packages or memorize any commands.</p>
<ul>
<li>Go here <a href="https://www.ssllabs.com/ssltest/index.html">https://www.ssllabs.com/ssltest/index.html</a></li>
<li>Enter the full domain https://&lt;domain.com&gt; and hit submit</li>
</ul>
<h2><a class="header" href="#tls-versions" id="tls-versions">TLS versions</a></h2>
<p>TLS 1.0 is no longer considered secure. Therefore PCI compliance states that it must be disabled.</p>
<p>IE 10 has support for TLS 1.1 and 1.2, but it is disabled by default, so disabling TLS 1.0 can block the typical IE10 user.</p>
<p>https://caniuse.com/#search=tls</p>
<p>https://help.salesforce.com/articleView?id=000220586&amp;language=en_US&amp;type=1</p>
<p>https://www.netsparker.com/web-vulnerability-scanner/vulnerabilities/insecure-transportation-security-protocol-supported-tls-10/</p>
<h1><a class="header" href="#apache" id="apache">Apache</a></h1>
<p>tags: apache</p>
<h2><a class="header" href="#example-1" id="example-1">Example</a></h2>
<pre><code class="language-xml">&lt;VirtualHost *:80&gt;
    DocumentRoot /var/www/vhosts/domain.com/current
    ServerName www.domain.com
    ServerAlias domain.com
    &lt;Directory /var/www/vhosts/domain.com/current/&gt;
        Options MultiViews FollowSymLinks Indexes
        AllowOverride ALL
    &lt;/Directory&gt;
&lt;/VirtualHost&gt;

&lt;VirtualHost *:443&gt;
    ServerName www.domain.com
    ServerAlias domain.com
    DocumentRoot /var/www/vhosts/domain.com/current
    SSLEngine on
    SSLCompression off
    SSLProtocol All -SSLv2 -SSLv3
    SSLHonorCipherOrder On
    SSLCipherSuite ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS
    SSLCertificateFile /etc/ssl/certs/domain.com/ServerCertificate.cer
    SSLCertificateKeyFile /etc/ssl/certs/domain.com/domain.com.key
    SSLCACertificateFile /etc/ssl/certs/domain.com/CACertificate-1.cer

    Alias /robots.txt /var/www/vhosts/robots.txt

    &lt;Location &quot;/var/www/vhosts/robots.txt&quot;&gt;
            Order deny,allow
            Allow from all
    &lt;/Location&gt;

    &lt;Directory /var/www/vhosts/domain.com/current/&gt;
            Options Indexes FollowSymLinks MultiViews
            AllowOverride All
    &lt;/Directory&gt;
&lt;/VirtualHost&gt;
</code></pre>
<h2><a class="header" href="#restart" id="restart">Restart</a></h2>
<p>Always test if the config is valid before attempting a restart:</p>
<pre><code class="language-sh">apache2ctl configtest
</code></pre>
<p>If so:</p>
<pre><code class="language-sh">service apache2 restart
</code></pre>
<h2><a class="header" href="#version" id="version">Version</a></h2>
<pre><code class="language-sh">apache2 -v
</code></pre>
<h1><a class="header" href="#apache-redirects" id="apache-redirects">Apache Redirects</a></h1>
<p>tags: redirects, apache, rewriterule, rewritecond</p>
<p>There are multiple way to handle redirects with Apache.</p>
<h2><a class="header" href="#redirect" id="redirect">Redirect</a></h2>
<p>The simplest way to do a redirect in Apache is using the <a href="https://httpd.apache.org/docs/2.4/mod/mod_alias.html#redirect">Redirect</a> directive.</p>
<p>Any request <strong>beginning</strong> with the url path will be affected:</p>
<pre><code class="language-apacheconfig">Redirect &quot;/account/&quot; &quot;/services/account/&quot;
</code></pre>
<p>(use quote marks if you have spaces in your urls - if you always use quote marks, you don't have to think about whether you need them or now)</p>
<p>The above will redirect <code>/account/</code> and <code>/account/login/</code>.</p>
<p>The following will cause a redirect loop:</p>
<pre><code class="language-apacheconfig"># Redirect loop
Redirect &quot;/account/&quot; &quot;/account/services/&quot;
</code></pre>
<p>You cannot match get parameters with <code>Redirect</code>. </p>
<h2><a class="header" href="#rewriterule" id="rewriterule">RewriteRule</a></h2>
<p><a href="https://httpd.apache.org/docs/2.4/rewrite/intro.html">RewriteRule</a> uses a regular expression to match the path.</p>
<p><code>RewriteRule</code> cannot match get parameters.</p>
<p>You do not have to escape <code>/</code> in RewriteRule.</p>
<p><code>$n</code> is used to refer to capture groups</p>
<pre><code class="language-apacheconfig">RewriteRule ^/car/([^/]+)/ /my/$1/automobile/
</code></pre>
<h2><a class="header" href="#rewritecond" id="rewritecond">RewriteCond</a></h2>
<p>Describes conditions under which a RewriteRule should be applied. You can test <a href="https://httpd.apache.org/docs/2.4/mod/mod_rewrite.html#rewritecond">many things</a> with RewriteCond.</p>
<p>A useful item to test with RewriteCond, which cannot be tested with Redirect or RewriteRule is a GET parameter:</p>
<pre><code class="language-apacheconfig">RewriteCond %{REQUEST_URI} ^/search/$
RewriteCond %{QUERY_STRING} query=weather
RewriteRule ^.*$ /weather/?type=local [R=301,L]
</code></pre>
<p>It is a <a href="https://techjourney.net/add-trailing-slash-to-the-end-of-the-url-with-htaccess-rewrite-rules/">good idea</a> to normalize your trailing forward slashes with RewriteCond, since it makes the rest of you rules easier:</p>
<pre><code class="language-apacheconfig">    RewriteEngine on

    RewriteBase /
    RewriteCond %{REQUEST_FILENAME} !-f
    RewriteCond %{REQUEST_FILENAME} !-d
    RewriteCond %{REQUEST_URI} !(.*)/$
    RewriteCond %{REQUEST_FILENAME} !\.(gif|jpg|png|jpeg|css|js|txt)$ [NC]
    RewriteRule ^ %{REQUEST_SCHEME}://%{HTTP_HOST}%{REQUEST_URI}/ [L,R=301,NE]
</code></pre>
<p>or </p>
<pre><code class="language-apacheconfig">RewriteCond %{REQUEST_URI} !\.[^./]+$
RewriteCond %{REQUEST_URI} !(.*)/$
RewriteRule ^(.*)$ /$1/ [R=301,L] 
</code></pre>
<h1><a class="header" href="#nginx" id="nginx">Nginx</a></h1>
<p>tags: nginx</p>
<p>Nginx is a light weight web server that is designed for speed and high concurrency.</p>
<p>Nginx is a good reverse proxy. For example it can pass http requests to node or php-fpm.</p>
<p>Nginx serves static content very quickly.</p>
<p>Nginx is also load balancer.</p>
<p>Many people find configuring Nginx easier than configuring Apache. Clearly this is a matter of opinion.</p>
<p>Nginx has a free and paid version. The free version lags behind in feature to the paid version, but the free
version is definitely production ready.</p>
<ul>
<li><a href="http://nginx.org/en/docs/beginners_guide.html">Nginx beginner guide</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/apache-vs-nginx-practical-considerations">Nginx vs Apache opnion</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts">Nginx context</a></li>
<li><a href="https://wiki.debian.org/Nginx/DirectoryStructure">Typical Nginx directory structure</a>
<ul>
<li>Configs are loaded starting at <code>/etc/nginx/nginx.conf</code>. Usually <code>/etc/nginx/sites-enabeld/*</code> is loaded form there</li>
<li>Store virtual hosts in <code>/etc/nginx/sites-available</code> and add symlinks to sites-enabled. These symlinks should point to sites availabed.</li>
<li>Using sites-availabe / sites-enabled allows you to pick the currently enabled sites from a store house of potential available sites</li>
</ul>
</li>
</ul>
<p>Use <code>nginx -s reload</code> to restart nginx. Do not use service to do so. Sending a signal will first
test you configs and do nothing if they have a syntax error. Using the service will first stop the
nginx service, so if there's a syntax error, you just took down the server.</p>
<h1><a class="header" href="#nginx-configs" id="nginx-configs">Nginx configs</a></h1>
<p>tags: nginx, configs, error, php</p>
<h2><a class="header" href="#restarting" id="restarting">Restarting</a></h2>
<p>After making changes to the nginx config files don't forget to restart:</p>
<pre><code>sudo nginx -s reload
</code></pre>
<p>Avoid using <code>sudo service nginx restart</code>, since that will crash the server if
there are syntax errors in the changes. <code>sudo nginx -s reload</code> will not do a
restart if it finds erros.</p>
<h2><a class="header" href="#request-entity-too-large---413" id="request-entity-too-large---413">Request Entity Too Large - 413</a></h2>
<p>This can be fixed in the global <code>http</code> block or an individual <code>server</code> block.</p>
<pre><code class="language-nginx">client_max_body_size 20M;
</code></pre>
<p>If you are working with PHP, then don't forget to modify these two lines in you php.ini:</p>
<pre><code class="language-php">; e.g. in /etc/php/7.0/fpm/php.ini
upload_max_filesize = 20M
post_max_size = 20M
</code></pre>
<h1><a class="header" href="#fastcgi" id="fastcgi">FastCgi</a></h1>
<p>tags: fastcgi, nginx</p>
<h2><a class="header" href="#environmental-variables" id="environmental-variables">Environmental variables</a></h2>
<p>It's often convenient to define environemental variables as they are passed in.
The allows per vhost setting for things like php's <code>$_SERVER['foo']</code>.</p>
<pre><code>fastcgi_param foo &quot;bar&quot;
</code></pre>
<h2><a class="header" href="#prepend-and-append" id="prepend-and-append">Prepend and append</a></h2>
<p>You can prepend and postpend files using nginx when passing to fastcgi with
<code>fastcgi_param</code>. The same value can also be add to <code>php.ini</code>.</p>
<pre><code>    fastcgi_param PHP_VALUE &quot;auto_prepend_file=/var/www/vhosts/profile/header.php
auto_append_file=/var/www/vhosts/profile/footer.php&quot;;
</code></pre>
<p>You can do the same with <code>auto_append_file</code> too.</p>
<p>The functional difference between the two is that if you use nginx, you can
easily control which virtual hosts receive the files, while in <code>php.ini</code> all
vhosts will receive it.</p>
<h1><a class="header" href="#nginx-redirects" id="nginx-redirects">NGINX Redirects</a></h1>
<p>tags: nginx, redirects</p>
<p>You can use the nginx <a href="http://nginx.org/en/docs/http/ngx_http_map_module.html">map module</a> to do these redirects:</p>
<pre><code># load the variables
map $uri $new {
    include /etc/nginx/redirect.map;
}

server {
    ...
   if ($new) {
        rewrite ^ $new redirect;
    }
}
</code></pre>
<p>The redirects file would look like:</p>
<pre><code>/old-url1 https://example.com/new-url1;
/old-url2 https://example.com/new-url2;
</code></pre>
<p>If you have many redirects you will have to bump <a href="http://nginx.org/en/docs/http/ngx_http_map_module.html#map_hash_bucket_size">map_hash_bucket_size</a>.</p>
<h1><a class="header" href="#tv" id="tv">TV</a></h1>
<p>tags: tv, js, html</p>
<h2><a class="header" href="#arrow-key-navigation" id="arrow-key-navigation">Arrow key navigation</a></h2>
<p>Helper libs:</p>
<ul>
<li><a href="https://github.com/Solid-Interactive/magic-focus-finder">Magic focus finder</a></li>
<li><a href="https://github.com/Microsoft/TVHelpers/wiki/DirectionalNavigation">Microsoft TVHelpers directional navigation</a></li>
<li><a href="https://github.com/luke-chang/js-spatial-navigation">JavaScript SpatialNavigation</a></li>
<li><a href="https://github.com/gauntface/dpad-navigation">D-Pad Navigation Library</a></li>
<li><a href="https://github.com/mozilla-b2g/gaia/blob/master/shared/js/smart-screen/spatial_navigator.js">Mozilla spatial navigator</a></li>
</ul>
<h1><a class="header" href="#roku" id="roku">Roku</a></h1>
<p>tags: roku, tv</p>
<ul>
<li><a href="tv/roku//tv/roku/development">Development and Deploying</a></li>
<li><a href="tv/roku//tv/roku/debugging">Debugging</a></li>
<li><a href="tv/roku//tv/roku/events">Events</a></li>
<li><a href="tv/roku//tv/roku/focus">Focus</a></li>
</ul>
<h2><a class="header" href="#conditional-compilation" id="conditional-compilation">Conditional Compilation</a></h2>
<ul>
<li>https://sdkdocs.roku.com/display/sdkdoc/Conditional+Compilation</li>
</ul>
<h2><a class="header" href="#scenegraph" id="scenegraph">SceneGraph</a></h2>
<p><a href="https://sdkdocs.roku.com/display/sdkdoc/SceneGraph+Core+Concepts">SceneGraph</a> is a framework that can be used to create
screens within an Roku app.</p>
<ul>
<li><a href="https://sdkdocs.roku.com/display/sdkdoc/SceneGraph+Core+Concepts">SceneGraph Core Concepts</a></li>
<li><a href="https://sdkdocs.roku.com/display/sdkdoc/SceneGraph+API+Reference">SceneGraph API Reference</a></li>
</ul>
<p>Examples:</p>
<ul>
<li><a href="https://sdkdocs.roku.com/display/sdkdoc/Dialogs+Markup">Dialogs</a></li>
</ul>
<h2><a class="header" href="#entry-points" id="entry-points">Entry Points</a></h2>
<ul>
<li><a href="https://sdkdocs.roku.com/pages/viewpage.action?pageId=1608546">Init function</a> - called after XML parsed</li>
<li><a href="https://sdkdocs.roku.com/pages/viewpage.action?pageId=1608547">onKeyEvent</a> - receives remote control key events</li>
</ul>
<h2><a class="header" href="#including-brs-files" id="including-brs-files">Including <code>.brs</code> files</a></h2>
<p>xml files can include BrightScript directly. If you want to separate out your BrightScript files, do it with <code>script</code>
tags:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
&lt;component name=&quot;LogOutDialog&quot; extends=&quot;Dialog&quot;&gt;
	&lt;script uri=&quot;LogOutDialog.brs&quot; type=&quot;text/brightscript&quot;&gt;&lt;/script&gt;
&lt;/component&gt;

</code></pre>
<h2><a class="header" href="#resolution" id="resolution">Resolution</a></h2>
<ul>
<li>Docs: https://sdkdocs.roku.com/display/sdkdoc/Specifying+Display+Resolution</li>
<li>Roku's recommendation:</li>
<li>In <code>manifest</code>, declare <code>ui_resolutions=fhd</code></li>
<li>Size ui elements for fhd (1080p), in values divisible by 3.</li>
<li>Roku will autoscale the ui when the display is 720p, and values divisible by 3 will produce integer sizes.</li>
<li>Use images that match the final scaled down size the image will display at.
<ul>
<li>ex: size element width 276; width will autoscale to 184 on 720p; if image, use image with width of 276 on 1080p, and image with width of 184 on 720p; see below for getting the current resolution.</li>
</ul>
</li>
<li>Get ui resolution from your root scene object
<ul>
<li>Docs: https://sdkdocs.roku.com/display/sdkdoc/Scene</li>
<li>ex: <code>resAssocArray = rootScene.currentDesignResolution()</code></li>
</ul>
</li>
</ul>
<h3><a class="header" href="#image-resources-based-on-resolution" id="image-resources-based-on-resolution">Image resources based on resolution</a></h3>
<p>In the manifest you can put the variable key and variables to replace the key with for sd, hd, and full hd:</p>
<pre><code>uri_resolution_autosub=$$RES$$,SD,720p,1080p
</code></pre>
<p>Then, you can use <code>$$RES$$</code> in xml attributes or brs:</p>
<pre><code class="language-brs">m.SEARCH_BLURRED = &quot;pkg:/images/nav-search-blurred-$$RES$$.png&quot;
</code></pre>
<pre><code class="language-xml">&lt;Poster
  uri=&quot;pkg:/images/nav-logo-$$RES$$.png&quot;/&gt;
</code></pre>
<h2><a class="header" href="#colors" id="colors">Colors</a></h2>
<ul>
<li>Colors are specified with a string formatted like so: <code>&quot;0xRRGGBBAA&quot;</code>, where RRGGBB is the standard 6-digit hex code, and AA specifies the alpha channel, <code>FF</code> fully opaque, and <code>00</code> fully transparent.</li>
<li>Use this chart to convert decimal opacity to hexidecimal: http://online.sfsu.edu/chrism/hexval.html</li>
<li>Colors can also be declared without strings by prefixing the hex code with <code>&amp;h</code>, e.g. <code>&amp;h0a0b0d</code></li>
</ul>
<h2><a class="header" href="#open-questions" id="open-questions">Open Questions</a></h2>
<ul>
<li>Add open questions here.</li>
</ul>
<h2><a class="header" href="#images-1" id="images-1">Images</a></h2>
<ul>
<li>Use the <code>Poster</code> node, with the <code>uri</code> field. <code>&lt;Poster uri=&quot;/image.jpg&quot; /&gt;</code></li>
<li>If you want to use a packaged image use the format: <code>uri=&quot;pkg:/images/image.jpg</code></li>
<li>Roku can resize images on the fly so that they use less texture memory (though the original image size should be close to the target size, because the original size has to be loaded into memory in order to be scaled down.)</li>
<li>example
<pre><code class="language-xml">&lt;Poster
  id=&quot;thumbnail&quot;
  loadDisplayMode=&quot;limitSize&quot;
  loadWidth=&quot;256&quot;
  loadHeight=&quot;384&quot;
  uri=&quot;http://image.example.com/800x1200.jpg&quot;/&gt;
</code></pre>
<ul>
<li>Note: <code>load...</code> fields must be set before <code>uri</code> for the load scaling to work.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#borders" id="borders">Borders</a></h2>
<ul>
<li>No border functionality built in. Use a <code>Rectangle</code> node for each side of your node.</li>
</ul>
<h2><a class="header" href="#positioning" id="positioning">Positioning</a></h2>
<ul>
<li>Use field <code>translation</code> to position an element relative to its parent.</li>
<li>Every node defines its own new coordinate system.</li>
<li>example:
<pre><code class="language-xml">&lt;Rectangle
  translation=&quot;[0, 100]&quot;&gt;
  &lt;Rectangle
    id=&quot;rec2&quot;
    translation=&quot;[0, 100]&quot;&gt;&gt;
  &lt;/Rectangle&gt;
&lt;/Rectangle&gt;
</code></pre>
<code>rec2</code> will start 200px down the page.</li>
</ul>
<h2><a class="header" href="#fonts-1" id="fonts-1">Fonts</a></h2>
<ul>
<li>Define the font settings on a <code>Font</code> node inside a <code>Label</code> node.</li>
<li>example:
<pre><code class="language-xml">&lt;Label
  text=&quot;Hello, Roboto&quot;&gt;
  &lt;Font
    role=&quot;font&quot;
    uri=&quot;pkg:/fonts/Roboto.otf&quot;
    size=&quot;28&quot;/&gt;
&lt;/Label&gt;
</code></pre>
<code>role</code> attribute is required.</li>
</ul>
<h2><a class="header" href="#gradients" id="gradients">Gradients</a></h2>
<p>Use a <a href="https://sdkdocs.roku.com/display/sdkdoc/Poster">Poster</a> node with an image background. Images should fit Posters as close as possible.</p>
<p><a href="https://sdkdocs.roku.com/display/sdkdoc/MaskGroup">Mask Groups</a> have some promise, but we've found cross device support lacking and their implementation tricky.</p>
<h2><a class="header" href="#hide-overflow" id="hide-overflow">Hide overflow</a></h2>
<p>Use the field <code>clippingRect</code> to set the visible area of the component, e.g.</p>
<pre><code class="language-xml">&lt;Group
  clippingRect=&quot;[0, 0, 200, 100]&quot;&gt;
  &lt;!-- Everything in here outside the 200 wide and 100 tall rect will be clipped. --&gt;
&lt;/Group&gt;
</code></pre>
<h2><a class="header" href="#brightscript" id="brightscript">Brightscript</a></h2>
<ul>
<li><code>sub</code> vs <code>function</code> - sub can only return void; any other value will error on compile.</li>
</ul>
<h2><a class="header" href="#functions" id="functions">Functions</a></h2>
<p>Functions can be declared with <code>sub</code> or <code>function</code>. A <code>sub</code> can only return <code>void</code>. A <code>function</code> can return other things.</p>
<p>A <code>sub</code> is a <code>function</code> without a return type.</p>
<h2><a class="header" href="#multi-threading" id="multi-threading">Multi Threading</a></h2>
<p>SceneGraph introduced the concept of <a href="https://sdkdocs.roku.com/display/sdkdoc/SceneGraph+Threads">multithreading</a>.</p>
<p>Render thread execution is limited to 3 seconds on side loaded channels and 10 seconds
on production channels.</p>
<p>To do something on another thread, use a <a href="https://sdkdocs.roku.com/display/sdkdoc/Task">Task</a>.</p>
<h2><a class="header" href="#optimization" id="optimization">Optimization</a></h2>
<p>Keep init methods as small as possible.</p>
<p>Optimization References:</p>
<ul>
<li>https://sdkdocs.roku.com/display/sdkdoc/SceneGraph+Performance+Guide</li>
<li>https://sdkdocs.roku.com/display/sdkdoc/Optimization+Techniques</li>
<li>https://sdkdocs.roku.com/display/sdkdoc/Performance+FAQ</li>
</ul>
<h2><a class="header" href="#persistent-storage" id="persistent-storage">Persistent storage</a></h2>
<ul>
<li>Use the registry: https://sdkdocs.roku.com/display/sdkdoc/roRegistry</li>
<li>Place registry sections in the registry: https://sdkdocs.roku.com/display/sdkdoc/roRegistrySection</li>
<li>To reset the registry, delete the app and restart the roku.</li>
</ul>
<h2><a class="header" href="#roku-device-models" id="roku-device-models">Roku device models</a></h2>
<ul>
<li><a href="https://sdkdocs.roku.com/display/sdkdoc/The+Roku+Channel+Developer+Program#TheRokuChannelDeveloperProgram-SupportedModels">Roku Supported models</a></li>
<li><a href="https://en.wikipedia.org/wiki/Roku">Overview of Roku Models</a></li>
</ul>
<h2><a class="header" href="#packaging-and-publishing" id="packaging-and-publishing">Packaging and publishing</a></h2>
<ul>
<li>Packaging a channel for publishing is done on the roku device.</li>
<li>A packaging key is used to sign the channel package.</li>
<li>A packaging key can be generated for the initial channel package.</li>
<li>Updates to the channel should be packaged with the initial key. The packaging key is embedded in the packaged channel, and you can rekey the roku device with a key from an existing packaged channel.</li>
<li>Each channel should have a unique packaging key.</li>
</ul>
<h3><a class="header" href="#generate-packaging-key" id="generate-packaging-key">Generate packaging key</a></h3>
<ul>
<li>Run <code>telnet &lt;roku-ip&gt; 8080</code></li>
<li>Then at prompt, enter <code>genkey</code></li>
<li>Copy DevId and password.</li>
</ul>
<h3><a class="header" href="#package-a-channel" id="package-a-channel">Package a channel</a></h3>
<ul>
<li>Side load the channel to be packaged.</li>
<li>Open roku ip (e.g. 192.168.2.3) in web browser (user: rokudev, password: set when dev mode activated on roku device).</li>
<li>Select Packager from tabs.</li>
<li>Add channel name, and enter password from genkey.</li>
</ul>
<h3><a class="header" href="#rekey-roku-device-from-packaged-channel" id="rekey-roku-device-from-packaged-channel">Rekey roku device from packaged channel</a></h3>
<ul>
<li>Open roku ip in web browser.</li>
<li>Select Utilities from tabs.</li>
<li>Upload package, enter password, and select rekey.</li>
<li>Your device is now ready to package an update to the channel you rekeyed from.</li>
<li>Note: apps sideloaded in dev mode will now use the dev key of the packaged app, and roku will consider them the &quot;same app&quot; in that they will share a registry. This is helpful for testing how an app update you are developing will interact with the existing live, packaged version. However, the channelClientId will be different between the packaged and dev versions.</li>
</ul>
<h3><a class="header" href="#publish-packaged-channel" id="publish-packaged-channel">Publish packaged channel</a></h3>
<ul>
<li>Upload here: https://developer.roku.com/developer-channels/channels</li>
<li>Private, non-certified channels don't have to be certified by roku and can be installed with an access code created for you at time of channel creation.</li>
</ul>
<h2><a class="header" href="#dev-mode-script-flag" id="dev-mode-script-flag">Dev mode script flag</a></h2>
<ul>
<li>Check if app is running in dev mode (side-loaded) with the <code>roAppInfo</code> object, <code>createObject(&quot;roAppInfo&quot;).isDev()</code></li>
</ul>
<h2><a class="header" href="#support" id="support">Support</a></h2>
<ul>
<li>Roku developer forums: https://forums.roku.com/viewforum.php?f=34</li>
<li>Roku developer knowledge center: https://partnersuccess.roku.com/hc/en-us/categories/360000494533-Development</li>
<li>Roku developer slack: https://rokudevelopers.slack.com</li>
</ul>
<h1><a class="header" href="#roku-development-and-deploying" id="roku-development-and-deploying">Roku: Development and Deploying</a></h1>
<p>tags: roku, development</p>
<p>There are several options for deploying. All options require you to activate developer mode. To enable development mode, 
enter the remote control sequence: <code>🏠🏠🏠 ↑↑ → ← → ← →</code>.  The entire sequence must be entered within 10 seconds.</p>
<h3><a class="header" href="#using-a-packaged-zip-file" id="using-a-packaged-zip-file">Using a packaged zip file</a></h3>
<ul>
<li><a href="https://sdkdocs.roku.com/display/sdkdoc/Loading+and+Running+Your+Application">Manually at the Roku's IP with a zip file</a></li>
</ul>
<h3><a class="header" href="#using-code" id="using-code">Using code</a></h3>
<ul>
<li><a href="https://www.npmjs.com/package/roku-deploy">roku-deploy npm</a> - IDE Agnostic</li>
<li><a href="https://marketplace.visualstudio.com/items?itemName=fuzecc.roku-development">Roku Development VisualStudio Code Package</a>
<ul>
<li>Setup configs per readme and the <code>Cmd-Shift-P</code> to issue commands</li>
<li>Note that you have to open your projects directory that contains only the Roku files, since this Package bundles up the currently root directory</li>
</ul>
</li>
<li><a href="https://marketplace.visualstudio.com/items?itemName=celsoaf.brightscript">BrightScript VisulStudioCode package</a>
<ul>
<li>Note that <code>v1.3.0</code> does not work for deploying. The highlight does work.</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#vim" id="vim">VIM</a></h3>
<p>Via <a href="https://github.com/VundleVim/Vundle.vim">Vundle</a>: Add <code>Plugin 'chooh/brightscript.vim'</code> to your <code>.vimrc</code> and run <code>:PluginInstall</code></p>
<h1><a class="header" href="#roku-debugging" id="roku-debugging">Roku: Debugging</a></h1>
<p>tags: roku, debugging</p>
<p>Debugging your application is <a href="https://sdkdocs.roku.com/display/sdkdoc/Debugging+Your+Application">summarized here in the docs</a></p>
<ul>
<li>Roku device exposes info on three ports. See ports, and commands available on each, here: https://sdkdocs.roku.com/display/sdkdoc/Debugging+Your+Application</li>
<li>Connect to the device with a telnet client, e.g. <code>nc</code> on macOS ( or <code>brew install telnet</code> )
<pre><code class="language-bash">$ nc &lt;roku_ip&gt; &lt;port&gt;
$ telnet &lt;roku_ip&gt; &lt;port&gt;
</code></pre>
Once connected, issue commands to get info:
<pre><code class="language-bash">&gt; loaded_textures
</code></pre>
</li>
<li>Use the brightscript console to get info about brightscript variables, pause execution, and step through code.
<ul>
<li>The VSCode extension is great for setting breakpoints and stepping though code.
<ul>
<li><a href="https://marketplace.visualstudio.com/items?itemName=celsoaf.brightscript">BrightScript VS package</a></li>
<li>Note that <code>v1.3.0</code> broke deploying. Hopefully open issue will be resolved soon. Use Previous version.</li>
<li>Set breakpoints in your code and execution will stop on those lines. Hover expressions to view their current value.</li>
</ul>
</li>
</ul>
</li>
<li>Use the debug server to get non-brightscript info, like memory usage.</li>
</ul>
<h2><a class="header" href="#brightscript-console" id="brightscript-console">Brightscript console</a></h2>
<p>The brightscript console is on port 8085. It will show console prints and if the application is breaked, it can be used
to query variables, etc.</p>
<h2><a class="header" href="#debug-server-commands" id="debug-server-commands">Debug server commands</a></h2>
<p>To send commands to the currently running app, use port 8080.</p>
<p>To turn on the fps and free-memory display, do <code>fps_display 1</code>.</p>
<p>To check where you're performing rendezvous, do <code>enhanced_dev_log rendezvous on</code>.</p>
<h1><a class="header" href="#roku-events" id="roku-events">Roku: Events</a></h1>
<p>tags: roku, events</p>
<p>Roku let's you observe fields on other nodes using <code>node.observeField(&quot;fieldName&quot;, &quot;onFieldName&quot;)</code>.</p>
<p><code>onFieldName</code> is a function on the component doing the observing.</p>
<p>If the field is on the component itself, then you can add the <code>onChange</code> attribute with the callback to the component instead
of using the <code>observeField</code> method. However, do note that <a href="https://sdkdocs.roku.com/display/sdkdoc/Optimization+Techniques"><code>onChange</code> is usually executed on the render thread</a>.</p>
<p>The allowed types for reactive fields are listed <a href="https://sdkdocs.roku.com/display/sdkdoc/interface#interface-Attributes">here</a></p>
<h3><a class="header" href="#appstate" id="appstate">AppState</a></h3>
<p><a href="https://sdkdocs.roku.com/display/sdkdoc/SceneGraph+Data+Scoping#SceneGraphDataScoping-GlobalScope">Global scope</a> can be used
to store transient App State.</p>
<h4><a class="header" href="#example-appstate-implementation" id="example-appstate-implementation">Example AppState Implementation</a></h4>
<p>Sample AppState XML:</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
&lt;component name=&quot;AppState&quot;&gt;
    &lt;script uri=&quot;AppState.brs&quot; type=&quot;text/brightscript&quot;/&gt;
	&lt;interface&gt;
        &lt;field id=&quot;isLoggedIn&quot; type=&quot;boolean&quot; value=&quot;true&quot;/&gt;
    &lt;/interface&gt;
&lt;/component&gt;
</code></pre>
<p>Adding app state to <code>m.global</code>:</p>
<pre><code class="language-brs">' Add AppState to m.global - do this in a Scene's BrightScript
m.global.addFields({
        appState: createObject(&quot;roSGNode&quot;, &quot;AppState&quot;)
})
</code></pre>
<ul>
<li>Manage global app state with the <code>appState</code> node on the global node.</li>
<li>Update the global state with assignment from components
<pre><code class="language-brs">m.global.appState.myStringField = &quot;Hello&quot;
</code></pre>
</li>
<li>Observe the state fields in your components to update the ui based on state changes.
<pre><code class="language-brs">m.global.appState.observeField(&quot;myStringField&quot;, &quot;handler&quot;)
</code></pre>
</li>
<li>Note that the signature for the handlers must accept an <code>Object</code>. The event is passed to the handler, not the field.
<pre><code class="language-brs">sub handler(event as Object)
</code></pre>
</li>
<li>Add fields to the app state interface in <code>AppState.xml</code>.
<ul>
<li>Add change listeners if you need to update other fields based on field changes.</li>
</ul>
<pre><code class="language-xml">&lt;field id=&quot;myStringField&quot; type=&quot;string&quot; onChange=&quot;changeHandler&quot;/&gt;
</code></pre>
</li>
</ul>
<h3><a class="header" href="#key-press-events" id="key-press-events">Key Press Events</a></h3>
<p>Key press events start at the most nested element and are bubbled up.</p>
<p><a href="https://sdkdocs.roku.com/pages/viewpage.action?pageId=1608547"><code>onKeyEvent</code></a> is called up the
entire chain. The second argument is used to pass to the next element up the chain what the previous element returned.
By convention, returning true means the keypress was handled, and returning false means it was not.</p>
<h1><a class="header" href="#roku-focus" id="roku-focus">Roku: Focus</a></h1>
<p>tags: roku, focus, events</p>
<h3><a class="header" href="#set-focus" id="set-focus">Set focus</a></h3>
<ul>
<li>Docs: https://sdkdocs.roku.com/display/sdkdoc/ifSGNodeFocus</li>
<li>Call <code>node.setFocus(true)</code> on a node to focus it.</li>
<li>example:
<pre><code class="language-brs">myNode.setFocus(true)
</code></pre>
</li>
</ul>
<h3><a class="header" href="#respond-to-focus-events" id="respond-to-focus-events">Respond to focus events</a></h3>
<ul>
<li>Docs: https://sdkdocs.roku.com/display/sdkdoc/Node</li>
<li>Observe field <code>focusedChild</code></li>
<li>observing field is generally needed for initial and final focus. Once focus is within an element, key presses on that element generally handle focus changes on child elements.</li>
<li><code>focusedChild</code> is set every time it gains <strong>OR</strong> loses focus
<ul>
<li>focus changes within an element are not captured</li>
</ul>
</li>
<li>Use <code>node.hasFocus()</code> to determine if node is focused.</li>
<li>General pattern is to focus a component, and let the component delegate focus to one of its children.</li>
</ul>
<p>Example</p>
<pre><code class="language-brs">sub init()
    m.top.observeField(&quot;focusedChild&quot;, &quot;onFocusedChild&quot;)
end sub

sub onFocusedChild()

    if (NOT m.top.isInFocusChain())
        ' handle losing focus
        removeFocusFromAllChildItems()
        return
    end if
    
    if (m.top.hasFocus())
        print &quot;element is gaining initial focus&quot;
        setInitialFocus()
    end if
end sub
</code></pre>
<p>To check whether an element or any of its descendants is focused, use <code>m.top.isInFocusChain()</code></p>
<h1><a class="header" href="#samsung-smart-tv-tizen-dev" id="samsung-smart-tv-tizen-dev">Samsung Smart TV (Tizen) Dev</a></h1>
<p>tags: samsung, tizen</p>
<h2><a class="header" href="#prereqs" id="prereqs">Prereqs</a></h2>
<ul>
<li>TV
<ul>
<li>Activate developer mode, and enter your dev machine’s ip
<ul>
<li><a href="http://developer.samsung.com/tv/develop/getting-started/using-sdk/tv-device">docs</a></li>
</ul>
</li>
<li>Note tv’s ip from tv network settings. Will use later to connect from dev machine</li>
</ul>
</li>
<li>Dev machine
<ul>
<li>JDK 8
<ul>
<li><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">download</a></li>
</ul>
</li>
</ul>
</li>
<li>Ensure dev machine and tv are on same network</li>
</ul>
<h2><a class="header" href="#tizen-studio-installation" id="tizen-studio-installation">Tizen studio installation</a></h2>
<ul>
<li>This process known to work on macOS and Windows 10</li>
<li><a href="http://developer.samsung.com/tv/develop/getting-started/setting-up-sdk/installing-tv-sdk">docs</a></li>
<li>Install latest tizen studio (2.4 known to work): <a href="https://developer.tizen.org/development/tizen-studio/download">Download page</a></li>
<li>Tizen studio cannot build to samsung tvs without the necessary extensions installed</li>
<li>Unfortunately, the latest tv extension (4.1) is buggy and fails to build to tvs, so we have to download an old version (4.0.1)</li>
<li>Download 4.0.1 from the <a href="https://developer.samsung.com/tv/develop/tools/tv-extension/archive">archive page</a></li>
<li>Open package manager (studio installation process will prompt this when finished)
<ul>
<li>Click the configuration gear icon in the top right
<ul>
<li>Turn off auto-update to prevent the latest broken version from being auto installed</li>
<li>Click Extensions dropdown</li>
<li>Deactivate all extension except samsung certificate manager</li>
<li>Click the plus icon to add an extension</li>
<li>Set the label to &quot;tv extension 4.0.1&quot; (doesn't really matter, just for your reference)</li>
<li>Browse to the downloaded <code>.zip</code> of 4.0.1 and select it</li>
</ul>
</li>
</ul>
</li>
<li>Close configuration and restart package manager
<ul>
<li>Click extensions tab and install
<ul>
<li>samsung certificate extension</li>
<li>samsung tv extension (will be labeled &quot;TV Extensions-4.0&quot;, but it is the 4.0.1 you just added)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#tizen-studio-workflow" id="tizen-studio-workflow">Tizen studio workflow</a></h2>
<h3><a class="header" href="#connect-to-device" id="connect-to-device">Connect to device</a></h3>
<ul>
<li><a href="http://developer.samsung.com/tv/develop/getting-started/using-sdk/tv-device">docs</a></li>
<li>In tizen studio Tools &gt; device manager</li>
<li>Scan for devices</li>
<li>Connect to device that pops up (should work if prereqs completed)</li>
</ul>
<h3><a class="header" href="#create-certificate-profile" id="create-certificate-profile">Create Certificate profile</a></h3>
<ul>
<li><a href="http://developer.samsung.com/tv/develop/getting-started/setting-up-sdk/creating-certificates">docs</a></li>
<li>In tizen studio Tools &gt; certificate manager</li>
<li>Click + to add new profile</li>
<li>Select Samsung</li>
<li>Select TV</li>
<li>Select Create new profile</li>
<li>Select Create new author cert</li>
<li>Sign into samsung account (can be created for free)</li>
<li>Select Create new distributor cert</li>
<li>Under privilege, select Partner (certain tizen apis require partner level privilege)</li>
<li>DUID of device should auto populate if you are connected to device</li>
<li>The profile will now be set as active, meaning it will be used to sign apps before installation to devices.</li>
<li>Close certificate manager</li>
</ul>
<h3><a class="header" href="#permit-to-install-applications" id="permit-to-install-applications">Permit to install applications</a></h3>
<ul>
<li>In tizen studio Tools &gt; device manager</li>
<li>Right click the connected device</li>
<li>Select “Permit to install applications”
<ul>
<li>This will push the device-profile.xml from the active certificate profile to the device</li>
</ul>
</li>
<li>Close device manager.</li>
</ul>
<h3><a class="header" href="#create-or-import-project-into-tizen-studio" id="create-or-import-project-into-tizen-studio">Create or Import project into tizen studio</a></h3>
<ul>
<li><a href="http://developer.samsung.com/tv/develop/getting-started/creating-tv-applications">docs</a></li>
<li>In tizen studio File &gt; Import</li>
<li>Select Tizen &gt; Tizen Project</li>
<li>Select Root directory</li>
<li>Select the directory that contains your <code>config.xml</code></li>
<li>You probably installed the latest samsung tv extensions (4.0) which is fine even if you are targeting a device that runs lower e.g. 2.4. Select the version that will allow you to import and you should be good to go.</li>
</ul>
<h3><a class="header" href="#run-application" id="run-application">Run application</a></h3>
<ul>
<li>Right click project in project explorer and click &quot;Run as tizen web application”</li>
<li>This will build, sign, and install the app to the tv and run it.</li>
</ul>
<h3><a class="header" href="#debug-application" id="debug-application">Debug application</a></h3>
<ul>
<li>Right click project in project explorer and click &quot;Debug as tizen web application</li>
<li>This will build, sign, and install the app to the tv and run it, and open an instance of chrome devtools connected to the remote app.</li>
</ul>
<h2><a class="header" href="#terminology" id="terminology">Terminology</a></h2>
<ul>
<li>Certificate Profile
<ul>
<li>Created from certificate manager tool in tizen studio</li>
<li>A profile consists of:
<ul>
<li>author certificate</li>
<li>distributor certificate</li>
<li>Device profile
<ul>
<li>Push this to the device to allow applications to install</li>
</ul>
</li>
</ul>
</li>
<li>Profiles are stored in ~/SamsungCertificate</li>
<li>profiles.xml
<ul>
<li>Location: tizen-studio-data/profiles/profiles.xml</li>
<li>Lists certificate profiles</li>
<li><code>active</code> attribute on root profiles node is where active profile is set</li>
<li>This is how tizen studio knows which profile to sign the packages with</li>
</ul>
</li>
</ul>
</li>
<li>SDB
<ul>
<li>Software development bridge</li>
<li>Cli tool used by tizen studio to:
<ul>
<li>connect to devices</li>
<li>Transfer files to devices (primarily the device-profile.xml)</li>
</ul>
</li>
<li>Location: ~/tizen-studio/tools/sdb</li>
</ul>
</li>
<li>Privilege
<ul>
<li>You are required to declare use of certain tizen apis in your <code>config.xml</code>.</li>
<li>Certain apis are only available to &quot;Partner&quot;s. Ensure your certificate profile is set as Partner if you need to use these apis.</li>
</ul>
</li>
<li>Partner
<ul>
<li>A privilege level required by certain tizen apis. See Privilege Term.</li>
</ul>
</li>
<li>Please add more...</li>
</ul>
<h2><a class="header" href="#development" id="development">Development</a></h2>
<ul>
<li>When you update code (js, csss, html), right click the project in Tizen Studio and select Refresh. This will load the new code changes and check the device connectivity.</li>
<li>Ensure the device is connected.</li>
<li>Right click project and select run. This will push the app to the tv. You should get some output on what’s happening in the tizen studio log.</li>
<li>If deploy fails, up the log level, Preferences &gt; Tizen Studio &gt; Logging, and move slider to DEBUG. Then investigate logs in ~/tizen-studio-data/ide/logs/ for more info on what might be going wrong</li>
</ul>
<h2><a class="header" href="#troubleshooting-1" id="troubleshooting-1">Troubleshooting</a></h2>
<ul>
<li>118 - likely a certificate issue, check privileges used and privileges of certificate profile</li>
<li>nullPointerException - could indicate tv disconnected during launch. This might lock the app in launch mode and prohibit subsequent builds with error “could not launch because the app is in launch mode.” if this happens, unplug tv and restart tizen studio.</li>
<li>Tizen studio 2.0, tv extension 4.0 try using a tizen certificate rather than a samsung certificate - https://stackoverflow.com/questions/47424846/error-when-deploying-tizen-app-failed-to-get-a-device-information</li>
<li>Else, try unplugging the tv</li>
<li>Logging:
<ul>
<li>Right click package in ide and select Debug &gt; Debug as Tizen application</li>
<li>Logs do not appear until you acknowledge the prompt on the tv first</li>
<li>Logs are logged to console in ide, but it’s better to view them in the dev tools opened by the ide</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#cli-workflow-incomplete" id="cli-workflow-incomplete">CLI workflow (incomplete)</a></h2>
<p>The entire project creation, tv connection, cert installation, packaging, signing, and installation process can theoretically be achieved with the tizen cli instead of using the tizen studio ide (Under the hood the studio is just using the cli commands anyway), but there seems to be a disconnect in the docs and all the steps don’t seem to work as expected. Good goal would be to get this setup to eliminate the need for the ide.</p>
<ul>
<li><a href="http://stackoverflow.com/questions/38308306/how-to-install-apps-on-samsung-tizen-tv-from-command-line">More info here</a></li>
<li><a href="https://developer.tizen.org/development/tizen-studio/web-tools/cli">Cli docs</a></li>
<li><a href="https://developer.tizen.org/development/tizen-studio/download/installing-tizen-studio#cli_installer">Installation</a></li>
<li>Example commands known to work:
<ul>
<li>Connect to device: <code>~/tizen-studio/tools/sdb connect &lt;tv-ip&gt;:26101</code></li>
<li>Device capability: <code>~/tizen-studio/tools/sdb capability</code></li>
<li>Create cert profile: tbd</li>
<li>Permit to install applications: <code>~/tizen-studio/tools/sdb push ~/SamsungCertificate/&lt;certificate-profile-name&gt;/device-profile.xml /home/developer</code></li>
<li>Build and sign app package: tbd</li>
<li>Install app: <code>~/tizen-studio/tools/ide/bin/tizen install -n &lt;package-name&gt;.wgt -s &lt;tv-ip&gt;:26101</code></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#publish" id="publish">Publish</a></h2>
<ul>
<li>Sign in to the <a href="https://seller.samsungapps.com/tv/portal/main">online portal</a> with your Samsung account.</li>
<li>Partner level membership requires commercial agreement.</li>
<li>Seller portal includes helpful checklist for certification requirements.</li>
</ul>
<h2><a class="header" href="#reference" id="reference">Reference</a></h2>
<ul>
<li><a href="http://developer.samsung.com/tv/develop/api-references/samsung-product-api-references">Samsung tv api docs</a>
<ul>
<li>always add the required privilege to <code>config.xml</code> before attempting to use a specific api</li>
</ul>
</li>
<li><a href="https://developer.tizen.org/community/tip-tech/sample-web-application-development-using-command-line-interface">Tizen Cli Tutorial</a></li>
<li>Package manager cli executable is located at: <code>~/tizen-studio/package-manager/package-manager-cli.bin</code></li>
<li><a href="https://marketplace.visualstudio.com/items?itemName=tizensdk.tizentv">tizentv vscode extension</a></li>
<li><a href="https://github.com/reaktor/tizendev">Node cli proxy of tizen cli</a>
<ul>
<li>have not tested</li>
<li>could potentially use instead of studio</li>
</ul>
</li>
<li><a href="https://developer.tizen.org/community/tizen-projects">Other tizen tools</a>
<ul>
<li>see items tagged as Tools</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#vizio-tv-app-development" id="vizio-tv-app-development">Vizio tv app development</a></h1>
<p>tags: vizio, via, smartcast</p>
<h2><a class="header" href="#via-vizio-internet-apps-plus-development" id="via-vizio-internet-apps-plus-development">VIA+ (Vizio Internet Apps Plus) development</a></h2>
<p>VIA is built on the Yahoo Connected TV (YCTV) platform. See the <a href="tv/vizio//tv/yctv/README.html">YCTV page</a> for more details.</p>
<h2><a class="header" href="#smartcast" id="smartcast">Smartcast</a></h2>
<p>SmartCast is some type of html based app but it seems like you need a business relationship with them to test on their platform.</p>
<h1><a class="header" href="#yahoo-connected-tv-yctv" id="yahoo-connected-tv-yctv">Yahoo Connected TV (YCTV)</a></h1>
<p>tags: yahoo, tv, smart-tv</p>
<p>Yahoo's smart tv platform has been implemented by several tv manufacturers, including Vizio.</p>
<p>See the YCTV docs for a general overview:</p>
<ul>
<li><a href="https://developer.yahoo.com/connectedtv/devguide/CTV_DG_Review_the_Sample_TV_App_Files.html">Overview</a></li>
<li><a href="https://developer.yahoo.com/connectedtv/installguide/CTV_IG_Testing_on_a_Consumer_Device.html">Testing on Device</a></li>
</ul>
<h2><a class="header" href="#test-on-device" id="test-on-device">Test on device</a></h2>
<p>For testing on devices, widgets are uploaded to the yahoo network and then downloaded to devices with a special pin code. Follow these steps:</p>
<ol>
<li>On TV, open app store and go to Settings &gt; Developer Settings to get pin code</li>
<li>Go to <code>https://tv.widgets.yahoo.com/publisher/</code></li>
<li>Sign in to yahoo account</li>
<li>Upload widget</li>
<li>In &quot;My TV Apps&quot;, right click app and add tester, using pin code from tv</li>
<li>Back in tv store developer settings, select &quot;Show My Test Apps&quot; and sign in to the yahoo account that you added as a tester</li>
<li>Go to app store and go to Categories &gt; Test Apps to select your app
If you activate test apps before adding the pin as a tester, the test apps section will not appear in the store. If this happens, reset the tv to retry the process.</li>
</ol>
<h1><a class="header" href="#universal-windows-platform-uwp-development-web-based" id="universal-windows-platform-uwp-development-web-based">Universal Windows Platform (UWP) Development (Web-based)</a></h1>
<p>tags: uwp, web, js, html, xbox</p>
<p>The Universal Windows Platform is Microsoft's unified app platform for desktop, mobile, and Xbox apps.</p>
<h2><a class="header" href="#helpful-links-1" id="helpful-links-1">Helpful links</a></h2>
<ul>
<li><a href="https://docs.microsoft.com/en-us/windows/uwp/">UWP overview</a></li>
<li><a href="https://docs.microsoft.com/en-us/windows/uwp/xbox-apps/getting-started">Xbox dev overview</a></li>
<li><a href="https://docs.microsoft.com/en-us/uwp/api/">UWP api namespace reference</a></li>
<li><a href="https://docs.microsoft.com/en-us/windows/uwp/xbox-apps/tailoring-for-xbox">Xbox Best practices</a></li>
<li><a href="https://docs.microsoft.com/en-us/visualstudio/debugger/quickstart-debug-html-and-css">Visual Studio debug DOM Explorer</a></li>
<li><a href="https://docs.microsoft.com/en-us/visualstudio/debugger/quickstart-debug-javascript-using-the-console">Visual Studio debug js console</a></li>
</ul>
<h2><a class="header" href="#uwp-development" id="uwp-development">UWP development</a></h2>
<h3><a class="header" href="#prereqs-1" id="prereqs-1">Prereqs</a></h3>
<ul>
<li>Windows 10</li>
<li>Enable developer mode</li>
<li>Visual Studio</li>
<li>Microsoft dev account (need <em>dev</em> account for Xbox dev and submission to store - one-time $99 fee for organization, or $19 for individual)</li>
</ul>
<h3><a class="header" href="#virtual-machine-optional" id="virtual-machine-optional">Virtual machine (optional)</a></h3>
<p>If on macOS, microsoft provides a virtual machine with visual studio installed and developer mode activated:</p>
<ul>
<li><a href="https://developer.microsoft.com/en-us/windows/downloads/virtual-machines">Download</a></li>
<li>Install virtualbox</li>
<li>Import machine into virtualbox
<ul>
<li>Extract contents of download</li>
<li>In virtualbox
<ul>
<li><code>File</code> &gt; <code>Import</code></li>
<li>Select the <code>.ovf</code> file</li>
<li>Select Import</li>
</ul>
</li>
</ul>
</li>
<li>Mount shared folder from host to guest according to <a href="https://stackoverflow.com/a/32534378/4713163">this stackoverflow answer</a></li>
</ul>
<h3><a class="header" href="#create-new-project" id="create-new-project">Create new project</a></h3>
<ul>
<li>Open Visual studio</li>
<li>Sign in to Microsoft account</li>
<li><code>File</code> &gt; <code>New</code> &gt; <code>Project</code>
<ul>
<li><code>Javascript</code> &gt; <code>Windows Universal</code> &gt; <code>Blank App (Universal Windows)</code></li>
<li>Enter name and click create</li>
<li>In dialog, leave target, but for <code>Minimum</code> &gt; <code>Build 14393</code></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#uwp-on-xbox" id="uwp-on-xbox">UWP on Xbox</a></h2>
<h3><a class="header" href="#setup" id="setup">Setup</a></h3>
<h4><a class="header" href="#activate-dev-mode-on-xbox" id="activate-dev-mode-on-xbox">Activate Dev Mode on Xbox</a></h4>
<ul>
<li>Download the Dev Mode Activation app on the xbox app store</li>
<li>Input the code displayed in the app in your dev account in the dev center</li>
<li>Restart the console in dev mode</li>
<li>Connect to network again</li>
<li>Sign in to Microsoft account. Must sign-in everytime console is power cycled on dev mode. App will not deploy if not signed in on xbox.</li>
<li>Note Xbox IP address</li>
</ul>
<h4><a class="header" href="#run-uwp-app-on-xbox" id="run-uwp-app-on-xbox">Run UWP app on Xbox</a></h4>
<ul>
<li>In Visual Studio, right click project in <code>Solution Explorer</code> &gt; <code>Properties</code> &gt; <code>Debugging</code></li>
<li><code>Debugger to launch:</code> &gt; <code>Remote Machine</code></li>
<li><code>Machine Name</code> &gt; Enter Xbox IP</li>
<li><code>Require Authentication</code> &gt; <code>Universal (Unecrypted Protocol)</code></li>
<li>Click <code>Apply</code> or <code>OK</code></li>
<li>In the top menu bar, select <code>x64</code> from the platform dropdown</li>
<li>Click green arrow to debug &gt; Enter pin from Xbox</li>
<li>App will launch on Xbox</li>
</ul>
<h3><a class="header" href="#debug-1" id="debug-1">Debug</a></h3>
<h4><a class="header" href="#visual-studio" id="visual-studio">Visual Studio</a></h4>
<h5><a class="header" href="#logging-1" id="logging-1">Logging</a></h5>
<p>When you debug the app from visual studio, the javascript console will we opened in visual studio. <code>console.log</code>s in your js will print here.</p>
<h5><a class="header" href="#dom-explorer" id="dom-explorer">DOM Explorer</a></h5>
<p>While debugging, you can explore the DOM (similar to chrome dev tools)</p>
<h5><a class="header" href="#breakpoint" id="breakpoint">Breakpoint</a></h5>
<p>You can also set breakpoints in your js code, and execution will pause there. Open a js file and click to the left of the line number to set a break point.</p>
<h4><a class="header" href="#windows-device-portal" id="windows-device-portal">Windows Device Portal</a></h4>
<p>From your browser you can access a portal that exposes debug information from the xbox:</p>
<ul>
<li>From dev home on Xbox, open <code>Remote Access Settings</code></li>
<li>Check <code>Enable Xbox Device Portal</code></li>
<li>Select <code>Set username and password</code></li>
<li>From a browser on the same network, go to <code>https://&lt;Xbox IP&gt;:11443</code></li>
<li>Proceed past cert error</li>
<li>Enter username and password to enter Xbox device portal</li>
</ul>
<h4><a class="header" href="#xbox-dev-mode-companion" id="xbox-dev-mode-companion">Xbox dev mode companion</a></h4>
<ul>
<li><a href="https://docs.microsoft.com/en-us/windows/uwp/xbox-apps/xbox-dev-mode-companion">Docs and download</a></li>
</ul>
<h3><a class="header" href="#dev" id="dev">Dev</a></h3>
<h4><a class="header" href="#windows-apis" id="windows-apis">Windows APIs</a></h4>
<p>The core UWP apis are exposed to the global scope in javascript as <code>Windows</code>. Checkout the uwp api namespace reference docs linked from the Links section below.</p>
<p>The only caveat is that casing needs to be changed when using the apis from js. Basically, methods and enum members need to be camelCased, but look at this <a href="https://docs.microsoft.com/en-us/scripting/jswinrt/using-the-windows-runtime-in-javascript">reference</a> for all the details.</p>
<h4><a class="header" href="#directional-navigation" id="directional-navigation">Directional Navigation</a></h4>
<p>Use the helper supplied by Microsoft:</p>
<ul>
<li><a href="https://github.com/Microsoft/TVHelpers/blob/master/tvjs/src/DirectionalNavigation/directionalnavigation-1.0.0.0.js">file</a></li>
<li><a href="https://github.com/Microsoft/TVHelpers">Repo</a></li>
</ul>
<p>Mouse mode will be enabled by default, but this helper will disable it. With the helper included, just use default focusable HTML elements, e.g. <code>button</code>, for out-of-the-box directional navigation. To focus any other element, just use <code>tabindex=&quot;0&quot;</code> attribute.</p>
<p>Mouse mode can also be disabled manually like so:</p>
<pre><code class="language-js">navigator.gamepadInputEmulation = 'gamepad';
</code></pre>
<h4><a class="header" href="#overscan" id="overscan">Overscan</a></h4>
<p>Some TVs use overscan, which zooms the content, cutting off the top, bottom, and sides. UWP apps display in TV-safe area by default. But apps should draw to edge of screen, and the developer should keep the app content within in the TV-safe area.</p>
<p>Disable overscan</p>
<pre><code class="language-js">Windows.UI.ViewManagement.ApplicationView.getForCurrentView().setDesiredBoundsMode(Windows.UI.ViewManagement.ApplicationViewBoundsMode.useCoreWindow);
</code></pre>
<p>Then apply this css to content container according to <a href="https://docs.microsoft.com/en-us/windows/uwp/design/devices/designing-for-tv#tv-safe-area">TV-safe area guide</a></p>
<pre><code class="language-css">margin: 27px 48px;
</code></pre>
<h4><a class="header" href="#scaling" id="scaling">Scaling</a></h4>
<p>By default, UWP apps (HTML) are scaled by 150%.</p>
<h4><a class="header" href="#accessibility" id="accessibility">Accessibility</a></h4>
<p>Use default focusable HTML elements for out-of-the-box screen reader support. The system reader, Narrator, will read button content and role when focus is gained.</p>
<h3><a class="header" href="#app-assets-incomplete" id="app-assets-incomplete">App assets (incomplete)</a></h3>
<p>Add app assets to the package from Visual Studio.</p>
<h2><a class="header" href="#store-submission" id="store-submission">Store submission</a></h2>
<h3><a class="header" href="#reserve-app-name" id="reserve-app-name">Reserve app name</a></h3>
<p>Create a new app in windows dev center. You need an app in dev center to associate your visual studio project with. Fill out submission in dev center. When you get to the upload package step, return to visual studio to package the app.</p>
<h3><a class="header" href="#package" id="package">Package</a></h3>
<h4><a class="header" href="#associate-project-with-store-app" id="associate-project-with-store-app">Associate project with store app</a></h4>
<ul>
<li>Right click the project in the solution explorer</li>
<li>Select <code>Store</code> &gt; <code>Associate app with store</code></li>
<li>Select app from list
This will populate fields from your app in dev center into the package manifest.</li>
</ul>
<h4><a class="header" href="#create-app-package" id="create-app-package">Create app package</a></h4>
<ul>
<li>Right click the project in the solution explorer</li>
<li>Select <code>Store</code> &gt; <code>Create app packages</code></li>
<li>Select app from list</li>
<li>Update version as needed</li>
<li>Adjust architectures as needed</li>
</ul>
<h4><a class="header" href="#windows-app-certification-kit-wack" id="windows-app-certification-kit-wack">Windows App Certification Kit (WACK)</a></h4>
<ul>
<li>After generating the package, visual studio will prompt to test the app with the WACK.</li>
<li>Microsoft will run this test as part of the store submission process, so run it now to catch any problems before submission.</li>
</ul>
<h3><a class="header" href="#submit-in-dev-center" id="submit-in-dev-center">Submit in dev center</a></h3>
<ul>
<li>Upload app package to store submission in dev center</li>
<li>Complete the submission and submit</li>
</ul>
<h2><a class="header" href="#hosted-web-apps" id="hosted-web-apps">Hosted web apps</a></h2>
<p>You can also package an app as a pointer to a hosted web app. You can even use the windows runtime api in your hosted web app code.</p>
<ul>
<li>[Docs](Hosted web apps: https://developer.microsoft.com/en-us/windows/bridges/hosted-web-apps)</li>
</ul>
<h2><a class="header" href="#troubleshooting-2" id="troubleshooting-2">Troubleshooting</a></h2>
<h3><a class="header" href="#app-fails-to-debug-on-xbox" id="app-fails-to-debug-on-xbox">App fails to debug on Xbox</a></h3>
<p>You will be logged out of Xbox when it power cycles in dev mode. Always log into your Microsoft account before attempting to debug.</p>
<h3><a class="header" href="#empty-dom-explorer-andor-console-when-debugging-in-visual-studio" id="empty-dom-explorer-andor-console-when-debugging-in-visual-studio">Empty DOM explorer and/or console when debugging in visual studio</a></h3>
<ul>
<li>Console might not print logs or errors and DOM explorer is empty.</li>
<li>Following messages might show in console:</li>
<li><code>Application is not currently attached to a script debug target that supports script diagnostics</code></li>
<li><code>You are not currently attached to a supported page or app.</code></li>
<li>Issue will be resolved in upcoming release: <a href="https://developercommunity.visualstudio.com/content/problem/168994/vs2017-dom-explorer-blank-when-deploying-js-projec.html">issue</a></li>
</ul>
<h1><a class="header" href="#version-control" id="version-control">Version Control</a></h1>
<p>tags: version-control</p>
<p>While there are multiple options for version control, no matter your choice, there
are a few things you must be able to accomplish:</p>
<ol>
<li>Keep track of changes to the code base</li>
<li>Keep track of the latest stable and semi stable versions of the code base</li>
<li>Keep track of feature sets</li>
<li>Manage the release workflow by being able to isolate code ready for realease</li>
<li>Quickly create new releases from (grab bag) mixtures of feature sets</li>
<li>Use version control to find the commit that broke the app</li>
<li>Reuse code in multiple projects</li>
</ol>
<p>This guide will cover how to achieve the above using git and gitflow.</p>
<h2><a class="header" href="#keeping-track-of-the-changes-in-the-code-base" id="keeping-track-of-the-changes-in-the-code-base">Keeping track of the changes in the code base</a></h2>
<p>This just means committing code. It is important to commit code often and in small
chunks. This makes it easier to debug and isolate later.</p>
<p>For example if you have a large commit of 30 files that breaks something.</p>
<h2><a class="header" href="#keep-track-of-the-latest-stable-and-semi-stable-versions-of-the-code-base" id="keep-track-of-the-latest-stable-and-semi-stable-versions-of-the-code-base">Keep track of the latest stable and semi stable versions of the code base</a></h2>
<p>The latest stable release should always be in master. The master branch itself
should be made up of a sequence of nothing but &quot;deploy&quot; commits - that is commits
that were actually deployed or used for a deploy.</p>
<p>This is important since it allows very easy &quot;undos.&quot; For example if the latest
code on master doesn't actually work, a quick <code>reset --hard HEAD~1</code> should guarantee
the previous thing that was on production.</p>
<p>The latest semi stable release should be on develop. This is essentially code that
you think should work but probably still has to get tested. Usually the staging
environment would contain the develop branch.</p>
<h2><a class="header" href="#keep-track-of-feature-sets" id="keep-track-of-feature-sets">Keep track of feature sets</a></h2>
<p>As you begin work on a feature set, you should branch from develop and work on the
feature: <code>get checkout -b feature/new-feature-set</code>. Code on feature branches are
not assumed to be &quot;working.&quot; When a feature set is complete it should be merged
back into <code>develop</code>:</p>
<pre><code>git merge --no-ff feature/new-feature-set
</code></pre>
<p>Using a <code>--no-ff</code> merge is very important. First it keeps working commits working.
Doing a fast forward merge may break working commits, by &quot;splicing&quot; a breaking
commit before it. Additionally a <code>--no-ff</code> merge keeps the main code for each
feature visually separated for inspection.</p>
<p>Here is an example that illustrates both points:</p>
<h3><a class="header" href="#the-original-code" id="the-original-code">The original code:</a></h3>
<pre><code>d develop HEAD
|
c
| b feature/new
|/
a
</code></pre>
<p>If we do a fast forward this is how things will look:</p>
<pre><code>d
|
c
|
b
|
a
</code></pre>
<p>The above doesn't preserve in the network graph (<code>git log --graph</code> or use Sourcetree)
that commit b was part of a feature branch. Additionally if commit <code>b</code> breaks things,
commit <code>c</code> and <code>d</code> has now gone from a working to a broken commit.</p>
<p>If we do a <code>--no-ff</code></p>
<pre><code>e
|\
d |
| |
c |
| b
|/
a
</code></pre>
<p>Here the network graph clearly shows that <code>b</code> is separate. Additionally commits
d and c don't break even if the newly created <code>e</code> commit is broken by <code>b</code>.</p>
<p>There are many customization you can do the <code>--graph</code> outpu to make, but probably
the easiest thing to do is to use a gui such as Sourcetree.</p>
<h1><a class="header" href="#git" id="git">Git</a></h1>
<p>tags: git</p>
<h2><a class="header" href="#pro-tips" id="pro-tips">Pro tips</a></h2>
<p>Change case of file or directory:</p>
<pre><code>git mv -f readme.txt README.txt
</code></pre>
<p>Get diff exclude path:</p>
<pre><code>git diff sha_old..sha_new -- . ':!path/to/exclude'
</code></pre>
<p>Checkout new local branch to track origin branch of same name:</p>
<pre><code>git checkout -t origin/branch-name
</code></pre>
<h1><a class="header" href="#gitflow" id="gitflow">Gitflow</a></h1>
<p>tags: git, gitflow</p>
<p>Gitflow is a way of organizing your workflow through branches.</p>
<p>The way branches are named and created is a statement of intent.</p>
<p>Initial gitflow might seem confusing, but it provides the structure needed to
easily problem solved deployment and debugging issues.</p>
<p>There are two main branches in gitflow and several important namespaces.</p>
<p>The two main long running branch are master and develop.</p>
<p>Each commit to master should represent a commit to the production environment. Master should always work.</p>
<p>Develop is where development happens, and it is often built to staging. Ideally develop should work, but it might not always. </p>
<p>When new features are being worked on they are branched from develop as feature branches. This allows the separation of 
individual features. If development on a feature stalls out or too many bugs are introduced, that feature can easily be 
isolated from the rest of develop, usually simply be not merging back in. But even if the feature branch is merged back in,
the merge commit can be reverted easily, since it is always just one merge commit.</p>
<p>Having a separate master an develop branch allows simple hotfixes. If there is a bug on production, branching a hotfix branch
from master will allow fixing the production bug without introducing any new features that are in ongoing development on develop.</p>
<p>We also use deploy branches. These are the branches that are on the actual servers, so <code>deploy/production</code> would be the branch on
the server that is built from <code>master</code>. Deploy branches allow a build step to happen followed by a cross branch commit. The 
commit message on the deploy branches always state which branch the deploy came from and also which SHA. The advantage of
having one commit per deploy on <code>master</code> / <code>deploy/production</code> is that quickly rolling back is possible using a simple <code>git reset --hard HEAD~1</code>.</p>
<p>The original gitflow article is located here:</p>
<p>http://nvie.com/posts/a-successful-git-branching-model/</p>
<h1><a class="header" href="#git-hooks" id="git-hooks">Git Hooks</a></h1>
<p>tags: git, hooks</p>
<p>All git hooks live in <code>.git/hooks</code>. That directory has several sample files. To try them out <code>mv</code> them to not
end in <code>.sample</code>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
